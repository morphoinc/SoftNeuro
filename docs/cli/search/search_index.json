{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Overview \u00b6 This manual explains how to compose various SoftNeuro commands. Index \u00b6 softneuro commands \uff1a explains various features that can be used with softneuro commands. Routine descriptor \uff1a explains the format of routine information. Tutorials : explains the tutorials that demonstrate the use of these commands.","title":"Overview"},{"location":"index.html#overview","text":"This manual explains how to compose various SoftNeuro commands.","title":"Overview"},{"location":"index.html#index","text":"softneuro commands \uff1a explains various features that can be used with softneuro commands. Routine descriptor \uff1a explains the format of routine information. Tutorials : explains the tutorials that demonstrate the use of these commands.","title":"Index"},{"location":"index.ja.html","text":"\u6982\u8981 \u00b6 \u672c\u30de\u30cb\u30e5\u30a2\u30eb\u3067\u306fSoftNeuro\u306e\u5404\u7a2e\u30b3\u30de\u30f3\u30c9\u64cd\u4f5c\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 \u76ee\u6b21 \u00b6 softneuro\u30b3\u30de\u30f3\u30c9 \uff1a softneuro\u30b3\u30de\u30f3\u30c9\u3067\u5229\u7528\u3067\u304d\u308b\u5404\u6a5f\u80fd\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\u3002 \u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf \uff1a\u30eb\u30fc\u30c1\u30f3\u60c5\u5831\u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\u3002 \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb : \u5404\u7a2e\u30b3\u30de\u30f3\u30c9\u3092\u5229\u7528\u3057\u305f\u64cd\u4f5c\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002","title":"\u6982\u8981"},{"location":"index.ja.html#_1","text":"\u672c\u30de\u30cb\u30e5\u30a2\u30eb\u3067\u306fSoftNeuro\u306e\u5404\u7a2e\u30b3\u30de\u30f3\u30c9\u64cd\u4f5c\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002","title":"\u6982\u8981"},{"location":"index.ja.html#_2","text":"softneuro\u30b3\u30de\u30f3\u30c9 \uff1a softneuro\u30b3\u30de\u30f3\u30c9\u3067\u5229\u7528\u3067\u304d\u308b\u5404\u6a5f\u80fd\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\u3002 \u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf \uff1a\u30eb\u30fc\u30c1\u30f3\u60c5\u5831\u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\u3002 \u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb : \u5404\u7a2e\u30b3\u30de\u30f3\u30c9\u3092\u5229\u7528\u3057\u305f\u64cd\u4f5c\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002","title":"\u76ee\u6b21"},{"location":"routine-descriptor.ja.html","text":"\u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf \u00b6 \u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf\u306f\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u64cd\u4f5c\u7b49\u3067\u5229\u7528\u3059\u308b\u30eb\u30fc\u30c1\u30f3\u60c5\u5831\u306e\u8868\u73fe\u65b9\u6cd5\u3067\u3059\u3002 \u4f7f\u3044\u65b9 usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX][@INDICES] \u5404\u9805\u76ee\u306e\u5185\u5bb9 \u5f15\u6570\u540d \u5185\u5bb9 DEVICE \u30c7\u30d0\u30a4\u30b9\u540d\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 cpu , opencl , cuda \u7b49\u304c\u3042\u308a\u307e\u3059\u3002 DTYPE \u30c7\u30fc\u30bf\u578b\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 float32 (\u30c7\u30d5\u30a9\u30eb\u30c8), float16 , qint8 \u7b49\u304c\u3042\u308a\u307e\u3059\u3002 CH \u30c6\u30f3\u30bd\u30eb\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u4f4d\u7f6e\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 chf (channels-first), chl (channels-last\uff1a\u30c7\u30d5\u30a9\u30eb\u30c8)\u304c\u3042\u308a\u307e\u3059\u3002 LEVEL \u30eb\u30fc\u30c1\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6700\u9069\u5316\u30ec\u30d9\u30eb\u3067\u3059\u3002 naive , fast (\u30c7\u30d5\u30a9\u30eb\u30c8), faster \u304c\u3042\u308a\u307e\u3059\u3002 AUX \u4e88\u5099\u60c5\u5831\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 LEVEL \u4ee5\u5916\u306e\u9805\u76ee\u306e\u60c5\u5831\u3092\u6301\u305f\u305b\u308b\u3053\u3068\u304c\u51fa\u304d\u307e\u3059\u3002 INDICES \u30ec\u30a4\u30e4\u30fc\u3092\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3067\u6307\u5b9a\u3059\u308b\u9805\u76ee\u3067\u3059\u3002 @1 \u306e\u3088\u3046\u306b\u4e00\u3064\u306e\u307f\u6307\u5b9a\u3057\u305f\u308a\u3001 @1,2 , @1..3 \u306e\u3088\u3046\u306b\u8907\u6570\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 \u8a18\u8ff0\u4f8b 'DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn' \u3092\u8868\u3057\u307e\u3059\u3002 cpu/faster/wg3x3_nxn DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX='' \u3092\u8868\u3057\u307e\u3059\u3002 opencl:float16 DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX='' \u3092\u8868\u3057\u307e\u3059\u3002 cpu:chf/naive \u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf\u3092\u5229\u7528\u3057\u305f\u30b3\u30de\u30f3\u30c9\u4f8b OpenCL\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306e run $ softneuro run --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn \u91cf\u5b50\u53168bit\u6574\u6570\u3092\u5229\u7528\u3057\u305fCPU\u3067\u306e tune $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn","title":"\u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf"},{"location":"routine-descriptor.ja.html#_1","text":"\u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf\u306f\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u64cd\u4f5c\u7b49\u3067\u5229\u7528\u3059\u308b\u30eb\u30fc\u30c1\u30f3\u60c5\u5831\u306e\u8868\u73fe\u65b9\u6cd5\u3067\u3059\u3002 \u4f7f\u3044\u65b9 usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX][@INDICES] \u5404\u9805\u76ee\u306e\u5185\u5bb9 \u5f15\u6570\u540d \u5185\u5bb9 DEVICE \u30c7\u30d0\u30a4\u30b9\u540d\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 cpu , opencl , cuda \u7b49\u304c\u3042\u308a\u307e\u3059\u3002 DTYPE \u30c7\u30fc\u30bf\u578b\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 float32 (\u30c7\u30d5\u30a9\u30eb\u30c8), float16 , qint8 \u7b49\u304c\u3042\u308a\u307e\u3059\u3002 CH \u30c6\u30f3\u30bd\u30eb\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u4f4d\u7f6e\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 chf (channels-first), chl (channels-last\uff1a\u30c7\u30d5\u30a9\u30eb\u30c8)\u304c\u3042\u308a\u307e\u3059\u3002 LEVEL \u30eb\u30fc\u30c1\u30f3\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u6700\u9069\u5316\u30ec\u30d9\u30eb\u3067\u3059\u3002 naive , fast (\u30c7\u30d5\u30a9\u30eb\u30c8), faster \u304c\u3042\u308a\u307e\u3059\u3002 AUX \u4e88\u5099\u60c5\u5831\u3092\u8868\u3059\u9805\u76ee\u3067\u3059\u3002 LEVEL \u4ee5\u5916\u306e\u9805\u76ee\u306e\u60c5\u5831\u3092\u6301\u305f\u305b\u308b\u3053\u3068\u304c\u51fa\u304d\u307e\u3059\u3002 INDICES \u30ec\u30a4\u30e4\u30fc\u3092\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3067\u6307\u5b9a\u3059\u308b\u9805\u76ee\u3067\u3059\u3002 @1 \u306e\u3088\u3046\u306b\u4e00\u3064\u306e\u307f\u6307\u5b9a\u3057\u305f\u308a\u3001 @1,2 , @1..3 \u306e\u3088\u3046\u306b\u8907\u6570\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 \u8a18\u8ff0\u4f8b 'DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn' \u3092\u8868\u3057\u307e\u3059\u3002 cpu/faster/wg3x3_nxn DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX='' \u3092\u8868\u3057\u307e\u3059\u3002 opencl:float16 DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX='' \u3092\u8868\u3057\u307e\u3059\u3002 cpu:chf/naive \u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf\u3092\u5229\u7528\u3057\u305f\u30b3\u30de\u30f3\u30c9\u4f8b OpenCL\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306e run $ softneuro run --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn \u91cf\u5b50\u53168bit\u6574\u6570\u3092\u5229\u7528\u3057\u305fCPU\u3067\u306e tune $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn","title":"\u30eb\u30fc\u30c1\u30f3\u30c7\u30a3\u30b9\u30af\u30ea\u30d7\u30bf"},{"location":"routine-descriptor.html","text":"Routine Descriptor \u00b6 The routine descriptor specifies the method of using command line options. Usage usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX][@INDICES] Content of each category Name Content DEVICE The name of the device family; cpu , opencl , cuda etc., can be used. DTYPE The data type; float32 (default), float16 , qint8 etc., can be used. CH The positioning of channels in the tensor; chf (channels-first), chl (channels-last\uff1adefault) are available. LEVEL Optimization level of routine algorithms; naive , fast (default), and faster are available. AUX Additional information; parameters other than LEVEL can be specified. INDICES Specifies the layers using indexes; specifying a single index (such as @1 ), or multiple indexes (as in @1,2 , @1..3 ) is possible. Examples specify 'DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn' cpu/faster/wg3x3_nxn specify DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX='' opencl:float16 Specify DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX='' cpu:chf/naive Example commands that use routine descriptors run on GPU using OpenCL $ softneuro run --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn tune on CPU with 8-bit quantization $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn","title":"Routine Descriptor"},{"location":"routine-descriptor.html#routine-descriptor","text":"The routine descriptor specifies the method of using command line options. Usage usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX][@INDICES] Content of each category Name Content DEVICE The name of the device family; cpu , opencl , cuda etc., can be used. DTYPE The data type; float32 (default), float16 , qint8 etc., can be used. CH The positioning of channels in the tensor; chf (channels-first), chl (channels-last\uff1adefault) are available. LEVEL Optimization level of routine algorithms; naive , fast (default), and faster are available. AUX Additional information; parameters other than LEVEL can be specified. INDICES Specifies the layers using indexes; specifying a single index (such as @1 ), or multiple indexes (as in @1,2 , @1..3 ) is possible. Examples specify 'DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn' cpu/faster/wg3x3_nxn specify DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX='' opencl:float16 Specify DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX='' cpu:chf/naive Example commands that use routine descriptors run on GPU using OpenCL $ softneuro run --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn tune on CPU with 8-bit quantization $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn","title":"Routine Descriptor"},{"location":"tutorial.ja.html","text":"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb \u00b6 \u5b66\u7fd2\u6e08\u307f\u306eKeras\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3092\u30b3\u30f3\u30d0\u30fc\u30c8\u3057\u3001\u753b\u50cf\u5206\u985e\u306e\u63a8\u8ad6\u5b9f\u884c\u53ca\u3073\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u3088\u308b\u9ad8\u901f\u5316\u3092\u884c\u3046\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 \u306a\u304a\u3001CLI\u30c4\u30fc\u30eb\u304a\u3088\u3073Python\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u3068\u74b0\u5883\u69cb\u7bc9\u306f\u5b8c\u4e86\u3057\u3066\u3044\u308b\u3082\u306e\u3068\u3057\u307e\u3059\u3002 Keras\u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30d0\u30fc\u30c8 \u00b6 CLI\u30c4\u30fc\u30eb\u306e import-tensorflow \u30b3\u30de\u30f3\u30c9\u3092\u5229\u7528\u3057\u3066\u3001\u30e2\u30c7\u30eb\u540d\u3092\u6307\u5b9a\u3057\u305fKeras\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u3078\u306e\u30b3\u30f3\u30d0\u30fc\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u30b3\u30f3\u30d0\u30fc\u30c8\u3067\u306f tf.keras.applications\u306eVGG16 \u3092DNN\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u30b3\u30f3\u30d0\u30fc\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 (softneuro)$ softneuro import-tensorflow --keras vgg16 vgg16.dnn \u5b9f\u884c\u74b0\u5883\u4e0a\u3067\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30fb\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0 \u00b6 \u30b3\u30f3\u30d0\u30fc\u30c8\u3067\u751f\u6210\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u3066\u3001\u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308b\u74b0\u5883\u4e0a\u3067\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u304a\u3088\u3073\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u884c\u3044\u307e\u3059\u3002 \u5404\u8a2d\u5b9a\u6642\u306e\u5b9f\u884c\u6642\u9593\u3092\u8a08\u6e2c\u30fb\u6bd4\u8f03\u3059\u308b\u3053\u3068\u3067\u6700\u9069\u306a\u8a2d\u5b9a\u5185\u5bb9\u3092\u6c7a\u5b9a\u3059\u308b\u306e\u3067\u3001 \u4e0d\u8981\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u7d42\u4e86\u3055\u305b\u305f\u72b6\u614b\u3067\u5b9f\u884c\u3059\u308b\u3053\u3068\u3092\u63a8\u5968\u3057\u307e\u3059\u3002 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u51e6\u7406\u306e\u5b8c\u4e86\u5f8c\u3001\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_tuned.dnn\u304c\u751f\u6210\u3055\u308c\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002 (softneuro)$ softneuro tune vgg16.dnn vgg16_tuned.dnn Profiling...100.0% [00:50] [preprocessor] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input (source) * cpu 1 premute (permute) * cpu 136 cpu/naive 2 madd (madd) * cpu 18 cpu/avx {\"ops_in_task\":16384} 3 output (sink) * cpu 4 ? () 154 [main] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input_1 (source) * cpu 1 block1_conv1 (conv2) * cpu 777 cpu/owc64_avx {\"cache\":8192,\"task_ops\":65536} 2 block1_conv2 (conv2) * cpu 5,680 cpu/wg2 {\"tile_size\":8} 3 block1_pool (max_pool2) * cpu 454 cpu/avx 4 block2_conv1 (conv2) * cpu 1,783 cpu/wg2 {\"tile_size\":8} 5 block2_conv2 (conv2) * cpu 2,930 cpu/wg2 {\"tile_size\":8} 6 block2_pool (max_pool2) * cpu 70 cpu/avx 7 block3_conv1 (conv2) * cpu 1,294 cpu/wg2 {\"tile_size\":8} 8 block3_conv2 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 9 block3_conv3 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 10 block3_pool (max_pool2) * cpu 45 cpu/avx 11 block4_conv1 (conv2) * cpu 1,362 cpu/wg2 {\"tile_size\":4} 12 block4_conv2 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 13 block4_conv3 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 14 block4_pool (max_pool2) * cpu 31 cpu/avx 15 block5_conv1 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 16 block5_conv2 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 17 block5_conv3 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 18 block5_pool (max_pool2) * cpu 22 cpu/avx 19 flatten (reshape) * cpu 0 cpu 20 fc1 (dense) * cpu 11,669 cpu/m1x1l_avx 21 fc2 (dense) * cpu 1,716 cpu/m1x1l_avx 22 predictions (dense) * cpu 210 cpu/avx {\"task_ops\":32} 23 predictions_softmax (softmax) * cpu 12 cpu/naive 24 sink_0 (sink) * cpu 25 ? () 41,229 SCHEMAS cpu TOTAL 41,383 \u307e\u305f\u3001 attr \u30b3\u30de\u30f3\u30c9\u3067 TUNE \u5c5e\u6027\u3067\u30b9\u30ad\u30fc\u30de\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002 (softneuro)$ softneuro attr -a vgg16_tuned.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned.dnn preprocessor 1x224x224x3 1x1000 30,953,174,639 cpu main cpu/naive \u306a\u304a\u3001\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u304c\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u6b8b\u308b\u3088\u3046\u624b\u52d5\u3067 init \u304b\u3089\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u624b\u9806\u3068\u306a\u308a\u307e\u3059\u3002 (softneuro)$ softneuro init mobilenet.prof mobilenet.dnn (softneuro)$ softneuro profile mobilenet.prof (softneuro)$ softneuro tune mobilenet.dnn mobilenet_tuned.dnn --prof mobilenet.prof \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u7d50\u679c\u306e\u78ba\u8a8d \u00b6 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d\u5f8c\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u753b\u50cf\u306b\u5bfe\u3059\u308b\u63a8\u8ad6\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u3053\u3053\u3067\u306f\u4f8b\u3068\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u306e\u753b\u50cf\u30d5\u30a1\u30a4\u30ebshovel.jpg\u306e\u63a8\u8ad6(\u753b\u50cf\u5206\u985e)\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u8868\u793a\u3055\u308c\u308b\u7d71\u8a08\u60c5\u5831(Statistics)\u306e\u63a8\u8ad6\u51e6\u7406(Dnn_forward())\u5b9f\u884c\u6642\u9593\u3092\u6bd4\u8f03\u3059\u308b\u3053\u3068\u3067\u3001 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u3088\u308b\u63a8\u8ad6\u9ad8\u901f\u5316\u306e\u52b9\u679c\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u901f\u5ea6\u6e2c\u5b9a\u7d50\u679c\u306e\u5b89\u5b9a\u5316\u306e\u305f\u3081\u306bd -loop \u30aa\u30d7\u30b7\u30e7\u30f3\u306e\u6307\u5b9a\u304c\u6709\u52b9\u3067\u3059\u3002 \u8a73\u7d30\u306f run\u30b3\u30de\u30f3\u30c9\u306e\u30aa\u30d7\u30b7\u30e7\u30f3 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u305f\u63a8\u8ad6\u5b9f\u884c (softneuro)$ softneuro run vgg16.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0017 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 326,679 326,679 326,679 1 Dnn_compile() 333,007 333,007 333,007 1 Dnn_forward() 199,992 199,992 199,992 1 Used memory: 1,140,817,920 Bytes \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u5f8c\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u305f\u63a8\u8ad6\u5b9f\u884c (softneuro)$ softneuro run vgg16_tuned.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0016 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 325,598 325,598 325,598 1 Dnn_compile() 446,959 446,959 446,959 1 Dnn_forward() 68,648 68,648 68,648 1 Used memory: 890,712,064 Bytes DNN\u30d5\u30a1\u30a4\u30eb\u306e\u6697\u53f7\u5316 \u00b6 cipher \u30b3\u30de\u30f3\u30c9\u3067DNN\u30d5\u30a1\u30a4\u30eb\u3092\u6697\u53f7\u5316\u3059\u308b\u3053\u3068\u3067\u8a2d\u5b9a\u5185\u5bb9\u3092\u79d8\u533f\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 cipher \u30b3\u30de\u30f3\u30c9\u5b8c\u4e86\u5f8c\u3001\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_tuned_enc.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306f CIPHER \u5c5e\u6027\u304c password \u3068\u306a\u308a\u307e\u3059\u3002 \u307e\u305f\u3001\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306f view \u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u305f\u969b\u306b\u60c5\u5831\u304c\u8868\u793a\u3055\u308c\u306a\u304f\u306a\u308a\u307e\u3059\u3002 (softneuro)$ softneuro cipher --new-pass 123456 vgg16_tuned.dnn vgg16_tuned_enc.dnn (softneuro)$ softneuro attr -a vgg16_tuned_enc.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned_enc.dnn ? password (invalid) (softneuro)$ softneuro view vgg16_tuned_enc.dnn mor_dnn.c:908:Error: Invalid password for dnn. (softneuro)$ softneuro run vgg16_tuned_enc.dnn -p 123456 --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 419,614 419,614 419,614 1 Dnn_compile() 860,013 860,013 860,013 1 Dnn_forward() 203,562 203,562 203,562 1 Used memory: 1,138,716,672 Bytes","title":"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb"},{"location":"tutorial.ja.html#_1","text":"\u5b66\u7fd2\u6e08\u307f\u306eKeras\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3092\u30b3\u30f3\u30d0\u30fc\u30c8\u3057\u3001\u753b\u50cf\u5206\u985e\u306e\u63a8\u8ad6\u5b9f\u884c\u53ca\u3073\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u3088\u308b\u9ad8\u901f\u5316\u3092\u884c\u3046\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 \u306a\u304a\u3001CLI\u30c4\u30fc\u30eb\u304a\u3088\u3073Python\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u3068\u74b0\u5883\u69cb\u7bc9\u306f\u5b8c\u4e86\u3057\u3066\u3044\u308b\u3082\u306e\u3068\u3057\u307e\u3059\u3002","title":"\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb"},{"location":"tutorial.ja.html#keras","text":"CLI\u30c4\u30fc\u30eb\u306e import-tensorflow \u30b3\u30de\u30f3\u30c9\u3092\u5229\u7528\u3057\u3066\u3001\u30e2\u30c7\u30eb\u540d\u3092\u6307\u5b9a\u3057\u305fKeras\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u3078\u306e\u30b3\u30f3\u30d0\u30fc\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u3053\u306e\u30c1\u30e5\u30fc\u30c8\u30ea\u30a2\u30eb\u306e\u30b3\u30f3\u30d0\u30fc\u30c8\u3067\u306f tf.keras.applications\u306eVGG16 \u3092DNN\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u30b3\u30f3\u30d0\u30fc\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 (softneuro)$ softneuro import-tensorflow --keras vgg16 vgg16.dnn","title":"Keras\u30e2\u30c7\u30eb\u306e\u30b3\u30f3\u30d0\u30fc\u30c8"},{"location":"tutorial.ja.html#_2","text":"\u30b3\u30f3\u30d0\u30fc\u30c8\u3067\u751f\u6210\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u3066\u3001\u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308b\u74b0\u5883\u4e0a\u3067\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u304a\u3088\u3073\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u884c\u3044\u307e\u3059\u3002 \u5404\u8a2d\u5b9a\u6642\u306e\u5b9f\u884c\u6642\u9593\u3092\u8a08\u6e2c\u30fb\u6bd4\u8f03\u3059\u308b\u3053\u3068\u3067\u6700\u9069\u306a\u8a2d\u5b9a\u5185\u5bb9\u3092\u6c7a\u5b9a\u3059\u308b\u306e\u3067\u3001 \u4e0d\u8981\u306a\u30a2\u30d7\u30ea\u30b1\u30fc\u30b7\u30e7\u30f3\u306f\u7d42\u4e86\u3055\u305b\u305f\u72b6\u614b\u3067\u5b9f\u884c\u3059\u308b\u3053\u3068\u3092\u63a8\u5968\u3057\u307e\u3059\u3002 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u51e6\u7406\u306e\u5b8c\u4e86\u5f8c\u3001\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_tuned.dnn\u304c\u751f\u6210\u3055\u308c\u305f\u3053\u3068\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002 (softneuro)$ softneuro tune vgg16.dnn vgg16_tuned.dnn Profiling...100.0% [00:50] [preprocessor] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input (source) * cpu 1 premute (permute) * cpu 136 cpu/naive 2 madd (madd) * cpu 18 cpu/avx {\"ops_in_task\":16384} 3 output (sink) * cpu 4 ? () 154 [main] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input_1 (source) * cpu 1 block1_conv1 (conv2) * cpu 777 cpu/owc64_avx {\"cache\":8192,\"task_ops\":65536} 2 block1_conv2 (conv2) * cpu 5,680 cpu/wg2 {\"tile_size\":8} 3 block1_pool (max_pool2) * cpu 454 cpu/avx 4 block2_conv1 (conv2) * cpu 1,783 cpu/wg2 {\"tile_size\":8} 5 block2_conv2 (conv2) * cpu 2,930 cpu/wg2 {\"tile_size\":8} 6 block2_pool (max_pool2) * cpu 70 cpu/avx 7 block3_conv1 (conv2) * cpu 1,294 cpu/wg2 {\"tile_size\":8} 8 block3_conv2 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 9 block3_conv3 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 10 block3_pool (max_pool2) * cpu 45 cpu/avx 11 block4_conv1 (conv2) * cpu 1,362 cpu/wg2 {\"tile_size\":4} 12 block4_conv2 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 13 block4_conv3 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 14 block4_pool (max_pool2) * cpu 31 cpu/avx 15 block5_conv1 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 16 block5_conv2 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 17 block5_conv3 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 18 block5_pool (max_pool2) * cpu 22 cpu/avx 19 flatten (reshape) * cpu 0 cpu 20 fc1 (dense) * cpu 11,669 cpu/m1x1l_avx 21 fc2 (dense) * cpu 1,716 cpu/m1x1l_avx 22 predictions (dense) * cpu 210 cpu/avx {\"task_ops\":32} 23 predictions_softmax (softmax) * cpu 12 cpu/naive 24 sink_0 (sink) * cpu 25 ? () 41,229 SCHEMAS cpu TOTAL 41,383 \u307e\u305f\u3001 attr \u30b3\u30de\u30f3\u30c9\u3067 TUNE \u5c5e\u6027\u3067\u30b9\u30ad\u30fc\u30de\u3092\u78ba\u8a8d\u3057\u307e\u3059\u3002 (softneuro)$ softneuro attr -a vgg16_tuned.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned.dnn preprocessor 1x224x224x3 1x1000 30,953,174,639 cpu main cpu/naive \u306a\u304a\u3001\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u304c\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u6b8b\u308b\u3088\u3046\u624b\u52d5\u3067 init \u304b\u3089\u5b9f\u884c\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u624b\u9806\u3068\u306a\u308a\u307e\u3059\u3002 (softneuro)$ softneuro init mobilenet.prof mobilenet.dnn (softneuro)$ softneuro profile mobilenet.prof (softneuro)$ softneuro tune mobilenet.dnn mobilenet_tuned.dnn --prof mobilenet.prof","title":"\u5b9f\u884c\u74b0\u5883\u4e0a\u3067\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30fb\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0"},{"location":"tutorial.ja.html#_3","text":"\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d\u5f8c\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u753b\u50cf\u306b\u5bfe\u3059\u308b\u63a8\u8ad6\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u3053\u3053\u3067\u306f\u4f8b\u3068\u3057\u3066\u30b5\u30f3\u30d7\u30eb\u306e\u753b\u50cf\u30d5\u30a1\u30a4\u30ebshovel.jpg\u306e\u63a8\u8ad6(\u753b\u50cf\u5206\u985e)\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u8868\u793a\u3055\u308c\u308b\u7d71\u8a08\u60c5\u5831(Statistics)\u306e\u63a8\u8ad6\u51e6\u7406(Dnn_forward())\u5b9f\u884c\u6642\u9593\u3092\u6bd4\u8f03\u3059\u308b\u3053\u3068\u3067\u3001 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u3088\u308b\u63a8\u8ad6\u9ad8\u901f\u5316\u306e\u52b9\u679c\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u901f\u5ea6\u6e2c\u5b9a\u7d50\u679c\u306e\u5b89\u5b9a\u5316\u306e\u305f\u3081\u306bd -loop \u30aa\u30d7\u30b7\u30e7\u30f3\u306e\u6307\u5b9a\u304c\u6709\u52b9\u3067\u3059\u3002 \u8a73\u7d30\u306f run\u30b3\u30de\u30f3\u30c9\u306e\u30aa\u30d7\u30b7\u30e7\u30f3 \u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u305f\u63a8\u8ad6\u5b9f\u884c (softneuro)$ softneuro run vgg16.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0017 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 326,679 326,679 326,679 1 Dnn_compile() 333,007 333,007 333,007 1 Dnn_forward() 199,992 199,992 199,992 1 Used memory: 1,140,817,920 Bytes \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u5f8c\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u305f\u63a8\u8ad6\u5b9f\u884c (softneuro)$ softneuro run vgg16_tuned.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0016 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 325,598 325,598 325,598 1 Dnn_compile() 446,959 446,959 446,959 1 Dnn_forward() 68,648 68,648 68,648 1 Used memory: 890,712,064 Bytes","title":"\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u7d50\u679c\u306e\u78ba\u8a8d"},{"location":"tutorial.ja.html#dnn","text":"cipher \u30b3\u30de\u30f3\u30c9\u3067DNN\u30d5\u30a1\u30a4\u30eb\u3092\u6697\u53f7\u5316\u3059\u308b\u3053\u3068\u3067\u8a2d\u5b9a\u5185\u5bb9\u3092\u79d8\u533f\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 cipher \u30b3\u30de\u30f3\u30c9\u5b8c\u4e86\u5f8c\u3001\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_tuned_enc.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306f CIPHER \u5c5e\u6027\u304c password \u3068\u306a\u308a\u307e\u3059\u3002 \u307e\u305f\u3001\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306f view \u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u305f\u969b\u306b\u60c5\u5831\u304c\u8868\u793a\u3055\u308c\u306a\u304f\u306a\u308a\u307e\u3059\u3002 (softneuro)$ softneuro cipher --new-pass 123456 vgg16_tuned.dnn vgg16_tuned_enc.dnn (softneuro)$ softneuro attr -a vgg16_tuned_enc.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned_enc.dnn ? password (invalid) (softneuro)$ softneuro view vgg16_tuned_enc.dnn mor_dnn.c:908:Error: Invalid password for dnn. (softneuro)$ softneuro run vgg16_tuned_enc.dnn -p 123456 --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 419,614 419,614 419,614 1 Dnn_compile() 860,013 860,013 860,013 1 Dnn_forward() 203,562 203,562 203,562 1 Used memory: 1,138,716,672 Bytes","title":"DNN\u30d5\u30a1\u30a4\u30eb\u306e\u6697\u53f7\u5316"},{"location":"tutorial.html","text":"Tutorial \u00b6 This tutorial demonstrates how you can: 1. convert a pretrained Keras model to SoftNeuro's DNN format 2. tune the converted model for speed optimization. 3. use the converted model for iimage classification 4. encrypt a DNN file It is assumed that SoftNeuro Python package and the CLI tool for the given platform have been properly installed. Keras model conversion \u00b6 Convert the Keras model to DNN format Using the import-tensorflow command of the CLI tool. In this tutorial, we convert the VGG16 model of keras.applications . (softneuro)$ softneuro import-tensorflow --keras vgg16 vgg16.dnn Tuning and Profiling for the target platform \u00b6 During this process, the model file will be tuned to achieve optimal performance for the target platform. Since the tool with calculating and comparing processing times for calculations under various settings, it is recommended that you close all non-essential applications during this task. When tuning is completed, the tuned model file vgg16_tuned.dnn will be saved to the current directory. (softneuro)$ softneuro tune vgg16.dnn vgg16_tuned.dnn Profiling...100.0% [00:50] [preprocessor] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input (source) * cpu 1 premute (permute) * cpu 136 cpu/naive 2 madd (madd) * cpu 18 cpu/avx {\"ops_in_task\":16384} 3 output (sink) * cpu 4 ? () 154 [main] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input_1 (source) * cpu 1 block1_conv1 (conv2) * cpu 777 cpu/owc64_avx {\"cache\":8192,\"task_ops\":65536} 2 block1_conv2 (conv2) * cpu 5,680 cpu/wg2 {\"tile_size\":8} 3 block1_pool (max_pool2) * cpu 454 cpu/avx 4 block2_conv1 (conv2) * cpu 1,783 cpu/wg2 {\"tile_size\":8} 5 block2_conv2 (conv2) * cpu 2,930 cpu/wg2 {\"tile_size\":8} 6 block2_pool (max_pool2) * cpu 70 cpu/avx 7 block3_conv1 (conv2) * cpu 1,294 cpu/wg2 {\"tile_size\":8} 8 block3_conv2 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 9 block3_conv3 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 10 block3_pool (max_pool2) * cpu 45 cpu/avx 11 block4_conv1 (conv2) * cpu 1,362 cpu/wg2 {\"tile_size\":4} 12 block4_conv2 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 13 block4_conv3 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 14 block4_pool (max_pool2) * cpu 31 cpu/avx 15 block5_conv1 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 16 block5_conv2 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 17 block5_conv3 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 18 block5_pool (max_pool2) * cpu 22 cpu/avx 19 flatten (reshape) * cpu 0 cpu 20 fc1 (dense) * cpu 11,669 cpu/m1x1l_avx 21 fc2 (dense) * cpu 1,716 cpu/m1x1l_avx 22 predictions (dense) * cpu 210 cpu/avx {\"task_ops\":32} 23 predictions_softmax (softmax) * cpu 12 cpu/naive 24 sink_0 (sink) * cpu 25 ? () 41,229 SCHEMAS cpu TOTAL 41,383 You can use attr command to check the status of tuning (see the TUNE column). (softneuro)$ softneuro attr -a vgg16_tuned.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned.dnn preprocessor 1x224x224x3 1x1000 30,953,174,639 cpu main cpu/naive If you want to save the profiling information, you manually initialize and execute the tuning process as follows. (softneuro)$ softneuro init mobilenet.prof mobilenet.dnn (softneuro)$ softneuro profile mobilenet.prof (softneuro)$ softneuro tune mobilenet.dnn mobilenet_tuned.dnn --prof mobilenet.prof Verifying the results of tuning \u00b6 We perform inference on the sample image shovel.jpg to compare the performance of models before and after tuning. Inference with the model before tuning (softneuro)$ softneuro run vgg16.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0017 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 326,679 326,679 326,679 1 Dnn_compile() 333,007 333,007 333,007 1 Dnn_forward() 199,992 199,992 199,992 1 Used memory: 1,140,817,920 Bytes Inference with the model after tuning (softneuro)$ softneuro run vgg16_tuned.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0016 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 325,598 325,598 325,598 1 Dnn_compile() 446,959 446,959 446,959 1 Dnn_forward() 68,648 68,648 68,648 1 Used memory: 890,712,064 Bytes You can compare the performance using the Statistics sections of the command line outputs. Note the reduction in inference time (Dnn_forward) and memory consumption (Used memory). For more stable statistics, you can use the -loop command option. Please refer to run command options for more details. DNN file encryption \u00b6 You can use the cipher command for encrypting a DNN file to secure its parameters. After completion the file vgg16_tuned_enc.dnn will be saved in the current directory. The password specified during encryption is required for inference. Further, the view command cannot be used to see model information of an encrypted DNN file. (softneuro)$ softneuro cipher --new-pass 123456 vgg16_tuned.dnn vgg16_tuned_enc.dnn (softneuro)$ softneuro attr -a vgg16_tuned_enc.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned_enc.dnn ? password (invalid) (softneuro)$ softneuro view vgg16_tuned_enc.dnn mor_dnn.c:908:Error: Invalid password for dnn. (softneuro)$ softneuro run vgg16_tuned_enc.dnn -p 123456 --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 419,614 419,614 419,614 1 Dnn_compile() 860,013 860,013 860,013 1 Dnn_forward() 203,562 203,562 203,562 1 Used memory: 1,138,716,672 Bytes","title":"Tutorial"},{"location":"tutorial.html#tutorial","text":"This tutorial demonstrates how you can: 1. convert a pretrained Keras model to SoftNeuro's DNN format 2. tune the converted model for speed optimization. 3. use the converted model for iimage classification 4. encrypt a DNN file It is assumed that SoftNeuro Python package and the CLI tool for the given platform have been properly installed.","title":"Tutorial"},{"location":"tutorial.html#keras-model-conversion","text":"Convert the Keras model to DNN format Using the import-tensorflow command of the CLI tool. In this tutorial, we convert the VGG16 model of keras.applications . (softneuro)$ softneuro import-tensorflow --keras vgg16 vgg16.dnn","title":"Keras model conversion"},{"location":"tutorial.html#tuning-and-profiling-for-the-target-platform","text":"During this process, the model file will be tuned to achieve optimal performance for the target platform. Since the tool with calculating and comparing processing times for calculations under various settings, it is recommended that you close all non-essential applications during this task. When tuning is completed, the tuned model file vgg16_tuned.dnn will be saved to the current directory. (softneuro)$ softneuro tune vgg16.dnn vgg16_tuned.dnn Profiling...100.0% [00:50] [preprocessor] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input (source) * cpu 1 premute (permute) * cpu 136 cpu/naive 2 madd (madd) * cpu 18 cpu/avx {\"ops_in_task\":16384} 3 output (sink) * cpu 4 ? () 154 [main] # NAME SCHEMA ATIME TIME DESC PARAMS 0 input_1 (source) * cpu 1 block1_conv1 (conv2) * cpu 777 cpu/owc64_avx {\"cache\":8192,\"task_ops\":65536} 2 block1_conv2 (conv2) * cpu 5,680 cpu/wg2 {\"tile_size\":8} 3 block1_pool (max_pool2) * cpu 454 cpu/avx 4 block2_conv1 (conv2) * cpu 1,783 cpu/wg2 {\"tile_size\":8} 5 block2_conv2 (conv2) * cpu 2,930 cpu/wg2 {\"tile_size\":8} 6 block2_pool (max_pool2) * cpu 70 cpu/avx 7 block3_conv1 (conv2) * cpu 1,294 cpu/wg2 {\"tile_size\":8} 8 block3_conv2 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 9 block3_conv3 (conv2) * cpu 2,280 cpu/wg2 {\"tile_size\":8} 10 block3_pool (max_pool2) * cpu 45 cpu/avx 11 block4_conv1 (conv2) * cpu 1,362 cpu/wg2 {\"tile_size\":4} 12 block4_conv2 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 13 block4_conv3 (conv2) * cpu 2,616 cpu/wg2 {\"tile_size\":4} 14 block4_pool (max_pool2) * cpu 31 cpu/avx 15 block5_conv1 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 16 block5_conv2 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 17 block5_conv3 (conv2) * cpu 1,127 cpu/wg2 {\"tile_size\":2} 18 block5_pool (max_pool2) * cpu 22 cpu/avx 19 flatten (reshape) * cpu 0 cpu 20 fc1 (dense) * cpu 11,669 cpu/m1x1l_avx 21 fc2 (dense) * cpu 1,716 cpu/m1x1l_avx 22 predictions (dense) * cpu 210 cpu/avx {\"task_ops\":32} 23 predictions_softmax (softmax) * cpu 12 cpu/naive 24 sink_0 (sink) * cpu 25 ? () 41,229 SCHEMAS cpu TOTAL 41,383 You can use attr command to check the status of tuning (see the TUNE column). (softneuro)$ softneuro attr -a vgg16_tuned.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned.dnn preprocessor 1x224x224x3 1x1000 30,953,174,639 cpu main cpu/naive If you want to save the profiling information, you manually initialize and execute the tuning process as follows. (softneuro)$ softneuro init mobilenet.prof mobilenet.dnn (softneuro)$ softneuro profile mobilenet.prof (softneuro)$ softneuro tune mobilenet.dnn mobilenet_tuned.dnn --prof mobilenet.prof","title":"Tuning and Profiling for the target platform"},{"location":"tutorial.html#verifying-the-results-of-tuning","text":"We perform inference on the sample image shovel.jpg to compare the performance of models before and after tuning. Inference with the model before tuning (softneuro)$ softneuro run vgg16.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0017 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 326,679 326,679 326,679 1 Dnn_compile() 333,007 333,007 333,007 1 Dnn_forward() 199,992 199,992 199,992 1 Used memory: 1,140,817,920 Bytes Inference with the model after tuning (softneuro)$ softneuro run vgg16_tuned.dnn shovel.jpg --top 5 --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9948 shovel 2 0.0016 hatchet 3 0.0012 swab 4 0.0011 broom 5 0.0007 hammer --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 325,598 325,598 325,598 1 Dnn_compile() 446,959 446,959 446,959 1 Dnn_forward() 68,648 68,648 68,648 1 Used memory: 890,712,064 Bytes You can compare the performance using the Statistics sections of the command line outputs. Note the reduction in inference time (Dnn_forward) and memory consumption (Used memory). For more stable statistics, you can use the -loop command option. Please refer to run command options for more details.","title":"Verifying the results of tuning"},{"location":"tutorial.html#dnn-file-encryption","text":"You can use the cipher command for encrypting a DNN file to secure its parameters. After completion the file vgg16_tuned_enc.dnn will be saved in the current directory. The password specified during encryption is required for inference. Further, the view command cannot be used to see model information of an encrypted DNN file. (softneuro)$ softneuro cipher --new-pass 123456 vgg16_tuned.dnn vgg16_tuned_enc.dnn (softneuro)$ softneuro attr -a vgg16_tuned_enc.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS vgg16_tuned_enc.dnn ? password (invalid) (softneuro)$ softneuro view vgg16_tuned_enc.dnn mor_dnn.c:908:Error: Invalid password for dnn. (softneuro)$ softneuro run vgg16_tuned_enc.dnn -p 123456 --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 419,614 419,614 419,614 1 Dnn_compile() 860,013 860,013 860,013 1 Dnn_forward() 203,562 203,562 203,562 1 Used memory: 1,138,716,672 Bytes","title":"DNN file encryption"},{"location":"commands/command-list.ja.html","text":"softneuro\u30b3\u30de\u30f3\u30c9\u4e00\u89a7 \u00b6 SoftNeuro\u306eCLI\u30c4\u30fc\u30eb\u304b\u3089\u306f\u3001\u5404\u7a2e\u64cd\u4f5c\u3092\u69d8\u3005\u306a\u30b3\u30de\u30f3\u30c9\u3092\u7528\u3044\u3066\u5b9f\u884c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4ee5\u4e0b\u306b\u305d\u306e\u4e00\u89a7\u3092\u8a18\u8f09\u3057\u307e\u3059\u3002 \u6700\u65b0\u306e\u30b3\u30de\u30f3\u30c9\u4e00\u89a7\u306f\u3001softneuro\u30b3\u30de\u30f3\u30c9\u3092\u5f15\u6570\u306a\u3057\u3067\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\u898b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4e00\u822c\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 help \uff1a \u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 version : SoftNeuro\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 license : \u30e9\u30a4\u30bb\u30f3\u30b9\u60c5\u5831\u306e\u78ba\u8a8d\u3068\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u8a2d\u5b9a\u3092\u884c\u3046\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 DNN\u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 \u60c5\u5831\u53c2\u7167\u7cfb \u00b6 attr : \u6697\u53f7\u5316\u306e\u6709\u7121\u3084\u30d5\u30a1\u30a4\u30eb\u540d\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 view : \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u5165\u51fa\u529b\u30b5\u30a4\u30ba\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306e\u8a73\u7d30\u306a\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 plot : DNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u69cb\u9020\u3092\u753b\u50cf\u3068\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002 DNN\u30d5\u30a1\u30a4\u30eb\u7de8\u96c6\u7cfb \u00b6 extract : DNN\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 archive : extract \u3067\u62bd\u51fa\u3055\u308c\u305f\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u518d\u5ea6DNN\u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u307e\u3059\u3002 refine : DNN\u30d5\u30a1\u30a4\u30eb\u306b\u9ad8\u901f\u5316\u306b\u6709\u52b9\u306a\u6700\u9069\u5316\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 compress : DNN\u30d5\u30a1\u30a4\u30eb\u306e\u91cd\u307f\u30c7\u30fc\u30bf\u306e\u8efd\u91cf\u5316\u3092\u884c\u3046\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 cipher : DNN\u30d5\u30a1\u30a4\u30eb\u306e\u6697\u53f7\u5316\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 calibrate : \u9759\u7684\u91cf\u5b50\u5316\u306e\u305f\u3081\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 decompose : Dnn \u30d5\u30a1\u30a4\u30eb\u306e\u30cd\u30c3\u30c8\u3092\u5206\u5272\u3057\u307e\u3059\u3002 \u30b3\u30f3\u30d0\u30fc\u30c8\u7cfb \u00b6 import-onnx : ONNX\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 import-tensorflow : TensorFlow\u307e\u305f\u306fKeras\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 import-ver3 : Ver3\u306eDNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089Ver5\u306e\u30d5\u30a1\u30a4\u30eb\u3078\u3068\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30fb\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u30b3\u30de\u30f3\u30c9 \u00b6 run : DNN\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u305f\u63a8\u8ad6\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 init : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u521d\u671f\u5316\u3092\u884c\u3044\u307e\u3059\u3002 add : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u306e\u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 rm : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u304b\u3089\u8a08\u6e2c\u7d50\u679c\u3092\u542b\u3080\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u60c5\u5831\u3092\u524a\u9664\u3057\u307e\u3059\u3002 reset : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u8a08\u6e2c\u7d50\u679c\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u3002 status : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u30fb\u8a08\u6e2c\u7d50\u679c\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 profile : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u305f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 tune : DNN\u30d5\u30a1\u30a4\u30eb\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u30ec\u30a4\u30e4\u30fc\u30fb\u30eb\u30fc\u30c1\u30f3\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 plugins : \u5b9f\u884c\u74b0\u5883\u3067\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 layers : \u5229\u7528\u53ef\u80fd\u306a\u30ec\u30a4\u30e4\u30fc\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 lparams : \u30ec\u30a4\u30e4\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 routine : \u5b9f\u884c\u74b0\u5883\u3067\u5229\u7528\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 rparams : \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 test : \u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306e\u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 numpy\u30c6\u30f3\u30bd\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 mknpy : \u63a8\u8ad6\u5b9f\u884c\u306e\u5165\u529b\u306b\u5229\u7528\u3067\u304d\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3057\u307e\u3059\u3002 attrnpy : \u30c7\u30fc\u30bf\u306e\u578b\u3084\u5024\u306e\u7bc4\u56f2\u306a\u3069\u3001numpy\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 viewnpy : numpy\u30d5\u30a1\u30a4\u306b\u4fdd\u5b58\u3055\u308c\u305f\u5024\u3092\u8868\u793a\u3057\u307e\u3059\u3002 cmpnpy : numpy\u30d5\u30a1\u30a4\u30eb\u540c\u58eb\u306e\u6bd4\u8f03\u3092\u884c\u3044\u307e\u3059\u3002","title":"softneuro\u30b3\u30de\u30f3\u30c9\u4e00\u89a7"},{"location":"commands/command-list.ja.html#softneuro","text":"SoftNeuro\u306eCLI\u30c4\u30fc\u30eb\u304b\u3089\u306f\u3001\u5404\u7a2e\u64cd\u4f5c\u3092\u69d8\u3005\u306a\u30b3\u30de\u30f3\u30c9\u3092\u7528\u3044\u3066\u5b9f\u884c\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4ee5\u4e0b\u306b\u305d\u306e\u4e00\u89a7\u3092\u8a18\u8f09\u3057\u307e\u3059\u3002 \u6700\u65b0\u306e\u30b3\u30de\u30f3\u30c9\u4e00\u89a7\u306f\u3001softneuro\u30b3\u30de\u30f3\u30c9\u3092\u5f15\u6570\u306a\u3057\u3067\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\u898b\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002","title":"softneuro\u30b3\u30de\u30f3\u30c9\u4e00\u89a7"},{"location":"commands/command-list.ja.html#_1","text":"help \uff1a \u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 version : SoftNeuro\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 license : \u30e9\u30a4\u30bb\u30f3\u30b9\u60c5\u5831\u306e\u78ba\u8a8d\u3068\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u8a2d\u5b9a\u3092\u884c\u3046\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002","title":"\u4e00\u822c\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/command-list.ja.html#dnn","text":"","title":"DNN\u30d5\u30a1\u30a4\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/command-list.ja.html#_2","text":"attr : \u6697\u53f7\u5316\u306e\u6709\u7121\u3084\u30d5\u30a1\u30a4\u30eb\u540d\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 view : \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u5165\u51fa\u529b\u30b5\u30a4\u30ba\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306e\u8a73\u7d30\u306a\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 plot : DNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u69cb\u9020\u3092\u753b\u50cf\u3068\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002","title":"\u60c5\u5831\u53c2\u7167\u7cfb"},{"location":"commands/command-list.ja.html#dnn_1","text":"extract : DNN\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 archive : extract \u3067\u62bd\u51fa\u3055\u308c\u305f\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u518d\u5ea6DNN\u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u307e\u3059\u3002 refine : DNN\u30d5\u30a1\u30a4\u30eb\u306b\u9ad8\u901f\u5316\u306b\u6709\u52b9\u306a\u6700\u9069\u5316\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 compress : DNN\u30d5\u30a1\u30a4\u30eb\u306e\u91cd\u307f\u30c7\u30fc\u30bf\u306e\u8efd\u91cf\u5316\u3092\u884c\u3046\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 cipher : DNN\u30d5\u30a1\u30a4\u30eb\u306e\u6697\u53f7\u5316\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 calibrate : \u9759\u7684\u91cf\u5b50\u5316\u306e\u305f\u3081\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 decompose : Dnn \u30d5\u30a1\u30a4\u30eb\u306e\u30cd\u30c3\u30c8\u3092\u5206\u5272\u3057\u307e\u3059\u3002","title":"DNN\u30d5\u30a1\u30a4\u30eb\u7de8\u96c6\u7cfb"},{"location":"commands/command-list.ja.html#_3","text":"import-onnx : ONNX\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 import-tensorflow : TensorFlow\u307e\u305f\u306fKeras\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 import-ver3 : Ver3\u306eDNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089Ver5\u306e\u30d5\u30a1\u30a4\u30eb\u3078\u3068\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002","title":"\u30b3\u30f3\u30d0\u30fc\u30c8\u7cfb"},{"location":"commands/command-list.ja.html#_4","text":"run : DNN\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u305f\u63a8\u8ad6\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 init : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u521d\u671f\u5316\u3092\u884c\u3044\u307e\u3059\u3002 add : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u306e\u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 rm : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u304b\u3089\u8a08\u6e2c\u7d50\u679c\u3092\u542b\u3080\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u60c5\u5831\u3092\u524a\u9664\u3057\u307e\u3059\u3002 reset : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u8a08\u6e2c\u7d50\u679c\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u3002 status : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u306e\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u30fb\u8a08\u6e2c\u7d50\u679c\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 profile : \u30d7\u30ed\u30d5\u30a1\u30a4\u30ea\u30f3\u30b0\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u305f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 tune : DNN\u30d5\u30a1\u30a4\u30eb\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002","title":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30fb\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u30b3\u30de\u30f3\u30c9"},{"location":"commands/command-list.ja.html#_5","text":"plugins : \u5b9f\u884c\u74b0\u5883\u3067\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 layers : \u5229\u7528\u53ef\u80fd\u306a\u30ec\u30a4\u30e4\u30fc\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 lparams : \u30ec\u30a4\u30e4\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 routine : \u5b9f\u884c\u74b0\u5883\u3067\u5229\u7528\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 rparams : \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 test : \u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306e\u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002","title":"\u30ec\u30a4\u30e4\u30fc\u30fb\u30eb\u30fc\u30c1\u30f3\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/command-list.ja.html#numpy","text":"mknpy : \u63a8\u8ad6\u5b9f\u884c\u306e\u5165\u529b\u306b\u5229\u7528\u3067\u304d\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u3092\u751f\u6210\u3057\u307e\u3059\u3002 attrnpy : \u30c7\u30fc\u30bf\u306e\u578b\u3084\u5024\u306e\u7bc4\u56f2\u306a\u3069\u3001numpy\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 viewnpy : numpy\u30d5\u30a1\u30a4\u306b\u4fdd\u5b58\u3055\u308c\u305f\u5024\u3092\u8868\u793a\u3057\u307e\u3059\u3002 cmpnpy : numpy\u30d5\u30a1\u30a4\u30eb\u540c\u58eb\u306e\u6bd4\u8f03\u3092\u884c\u3044\u307e\u3059\u3002","title":"numpy\u30c6\u30f3\u30bd\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/command-list.html","text":"SoftNeuro command list \u00b6 The SoftNeuro command line tool has a variety of uses, as listed below. It is possible to check all available commands by running the softneuro command without any arguments. General Operation Commands \u00b6 help : Shows basic command help. version : Shows version information. license : Handle/display license information. DNN File Operation Commands \u00b6 Model Information \u00b6 attr : Show DNN file information. view : Show detailed information on the model structure and layers. plot : Save a DNN file model architecture as an image. Model Editing \u00b6 extract : Extract weights and model data from a DNN file. archive : Archive weights and model data into a DNN file. refine : Optimize a DNN file for faster inference. compress : Reduce the DNN file weights data size. cipher : Encrypt a DNN file. calibrate : Calibrate a DNN file for static quantization. decompose : Decompose net of a DNN file. Model Conversion \u00b6 import-onnx : Convert an ONNX model into a DNN file. import-tensorflow : Convert a TensorFlow or Keras model into a DNN file. import-ver3 : Convert a SoftNeuro V3 DNN file into a V4 DNN file. Execution, Profiling and Tuning Commands \u00b6 run : Run inference using a DNN file. init : Init profiling data. add : Add layer routine settings to profiling data. rm : Remove routine information from profiling data. reset : Reset profiling information. status : Show profiling results information. profile : Run profiling using profiling data to generate profiling information. tune : Tune a DNN file. Layer/Routine Operation Commands \u00b6 plugins : Show available plugins, such as AVX and CUDA. layers : Shows available layers. lparams : Shows the parameters for a given layer. routine : Shows available routines. rparams : Shows the parameters for a given routine. test : Test runs a given layer. numpy Operation Commands \u00b6 mknpy : Create a numpy file that can be used as inference input. attrnpy : Show numpy file information such as data type and shape. viewnpy : Show the contents of a numpy file. cmpnpy : Compare similarity between numpy files.","title":"SoftNeuro command list"},{"location":"commands/command-list.html#softneuro-command-list","text":"The SoftNeuro command line tool has a variety of uses, as listed below. It is possible to check all available commands by running the softneuro command without any arguments.","title":"SoftNeuro command list"},{"location":"commands/command-list.html#general-operation-commands","text":"help : Shows basic command help. version : Shows version information. license : Handle/display license information.","title":"General Operation Commands"},{"location":"commands/command-list.html#dnn-file-operation-commands","text":"","title":"DNN File Operation Commands"},{"location":"commands/command-list.html#model-information","text":"attr : Show DNN file information. view : Show detailed information on the model structure and layers. plot : Save a DNN file model architecture as an image.","title":"Model Information"},{"location":"commands/command-list.html#model-editing","text":"extract : Extract weights and model data from a DNN file. archive : Archive weights and model data into a DNN file. refine : Optimize a DNN file for faster inference. compress : Reduce the DNN file weights data size. cipher : Encrypt a DNN file. calibrate : Calibrate a DNN file for static quantization. decompose : Decompose net of a DNN file.","title":"Model Editing"},{"location":"commands/command-list.html#model-conversion","text":"import-onnx : Convert an ONNX model into a DNN file. import-tensorflow : Convert a TensorFlow or Keras model into a DNN file. import-ver3 : Convert a SoftNeuro V3 DNN file into a V4 DNN file.","title":"Model Conversion"},{"location":"commands/command-list.html#execution-profiling-and-tuning-commands","text":"run : Run inference using a DNN file. init : Init profiling data. add : Add layer routine settings to profiling data. rm : Remove routine information from profiling data. reset : Reset profiling information. status : Show profiling results information. profile : Run profiling using profiling data to generate profiling information. tune : Tune a DNN file.","title":"Execution, Profiling and Tuning Commands"},{"location":"commands/command-list.html#layerroutine-operation-commands","text":"plugins : Show available plugins, such as AVX and CUDA. layers : Shows available layers. lparams : Shows the parameters for a given layer. routine : Shows available routines. rparams : Shows the parameters for a given routine. test : Test runs a given layer.","title":"Layer/Routine Operation Commands"},{"location":"commands/command-list.html#numpy-operation-commands","text":"mknpy : Create a numpy file that can be used as inference input. attrnpy : Show numpy file information such as data type and shape. viewnpy : Show the contents of a numpy file. cmpnpy : Compare similarity between numpy files.","title":"numpy Operation Commands"},{"location":"commands/dnn/converter.ja.html","text":"\u30b3\u30f3\u30d0\u30fc\u30c8\u7cfb \u00b6 \u5404\u7a2e\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u304b\u3089\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3092SoftNeuro\u3067\u6271\u3048\u308bDNN\u5f62\u5f0f\u306b\u30b3\u30f3\u30d0\u30fc\u30c8\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 preprocess, postprocess\u306b\u3064\u3044\u3066 \u00b6 SoftNeuroV4\u304b\u3089\u3001preprocess, postprocess\u306f main \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u524d\u5f8c\u306b\u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b preprocess , postprocess \u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u884c\u308f\u308c\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002 \u3053\u308c\u3089\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u60c5\u5831\u306fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u308b\u306e\u3067\u3001 io_params \u306e\u30d5\u30a1\u30a4\u30eb\u306f\u4e0d\u8981\u3068\u306a\u308a\u307e\u3057\u305f\u3002 \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306b\u542b\u307e\u308c\u306a\u3044preprocess, postprocess\u3092\u8ffd\u52a0\u3059\u308b\u5834\u5408\u306f\u30d7\u30ea\u30bb\u30c3\u30c8\u306ejson\u30d5\u30a1\u30a4\u30eb\u3092 converter\u306b\u4e0e\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u30d7\u30ea\u30bb\u30c3\u30c8\u306b\u5b58\u5728\u3057\u306a\u3044\u9806\u5e8f\u30fb\u8a2d\u5b9a\u306epreprocess, postprocess\u3092\u8ffd\u52a0\u3059\u308b\u5834\u5408\u306f\u30d7\u30ea\u30bb\u30c3\u30c8\u306ejson\u30d5\u30a1\u30a4\u30eb\u3092 \u66f8\u304d\u63db\u3048\u3066\u5229\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u73fe\u6642\u70b9\u3067 preprocess, postprocess \u3092\u8ffd\u52a0\u3059\u308b\u30aa\u30d7\u30b7\u30e7\u30f3\u306f import-onnx , import-tensorflow \u3067\u306e\u307f\u5229\u7528\u53ef\u80fd\u3067\u3001 import-ver3 \u3067\u306f\u672a\u5bfe\u5fdc\u3067\u3059\u3002 preprocess\u8a18\u8ff0\u4ed5\u69d8 \u00b6 preprocess\u3067\u306f\u753b\u50cf\u306e\u30ea\u30b5\u30a4\u30ba\u3001\u30ea\u30b5\u30a4\u30ba\u65b9\u5f0f\u306e\u6307\u5b9a\u3001\u8272\u7a7a\u9593\u306e\u6307\u5b9a\u3001\u30c7\u30fc\u30bf\u306e\u6b63\u898f\u5316\u306a\u3069\u3092\u884c\u3044\u307e\u3059\u3002 preprocess\u5185\u306e\u5404\u8981\u7d20\u306b\u95a2\u3059\u308b\u8aac\u660e\u3092\u4e0b\u8a18\u306b\u8a18\u8f09\u3057\u307e\u3059\u3002 layers \u00b6 \u5404\u30ec\u30a4\u30e4\u306f\u3001\u30ec\u30a4\u30e4\u306e\u30bf\u30a4\u30d7\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u30a6\u30a7\u30a4\u30c8\u3001\u30a2\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\u306e4\u3064\u306e\u8981\u7d20\u304b\u3089\u69cb\u6210\u3055\u308c\u307e\u3059\u3002 Properties Required Description Type Example type \u5fc5\u9808 \u30ec\u30a4\u30e4\u306e\u7a2e\u985e\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002source, sink, madd, permute \u7b49\u304c\u6307\u5b9a\u53ef\u80fd\u3002 String \"madd\" params \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b weights \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30a6\u30a7\u30a4\u30c8\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b attrs \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u4ed8\u52a0\u60c5\u5831\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b Source Layer \u00b6 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30ec\u30a4\u30e4\u3002 params Properties Required Description Type Example shape \u5fc5\u9808 \u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b21\u5143\u6570\u3092\u6307\u5b9a\u3059\u308b\u6574\u6570\u914d\u5217\u3002 Array of Integer [224, 224, 3] weights: None attrs Properties Required Description Type Example format \u30aa\u30d7\u30b7\u30e7\u30f3 \u5165\u529b\u753b\u50cf\u306e\u8272\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002\"rgb\" \u306e\u307f\u6307\u5b9a\u53ef\u80fd\u3002 String \"rgb\" resize_mode \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ea\u30b5\u30a4\u30ba\u65b9\u5f0f\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002\"bilinear\" (\u30c7\u30d5\u30a9\u30eb\u30c8) \u3068 \"nearest\" \u3092\u6307\u5b9a\u53ef\u3002 String \"bilinear\" keep_ar \u30aa\u30d7\u30b7\u30e7\u30f3 \u753b\u50cf\u7e2e\u5c0f\u306e\u969b\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3059\u308b\u304b\u3092\u6307\u5b9a\u3059\u308b\u771f\u507d\u5024\u3002\uff08\u30c7\u30d5\u30a9\u30eb\u30c8 false\uff09 Boolean true padding_color \u30aa\u30d7\u30b7\u30e7\u30f3 \u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3057\u305f\u7e2e\u5c0f\u306e\u969b\u306b\u751f\u3058\u308b\u7a7a\u9593\u3092\u57cb\u3081\u308b\u30d1\u30c7\u30a3\u30f3\u30b0\u306e\u8272\u3092\u6307\u5b9a\u3059\u308b\u6570\u5024\u914d\u5217\u3002 Array of Numbers [255, 255, 255] Sink Layer \u00b6 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u30ec\u30a4\u30e4\u3002 params: None weights: None attrs: None Permute Layer \u00b6 axis \u3092\u6307\u5b9a\u3057\u3066 axis \u5185\u306e\u30c7\u30fc\u30bf\u306e\u9806\u5e8f\u3092\u5165\u308c\u66ff\u3048\u308b\u30ec\u30a4\u30e4\u3002\u30c1\u30e3\u30f3\u30cd\u30eb\u30b9\u30ef\u30c3\u30d7\u3067\u5229\u7528\u3002 params Properties Required Description Type Example axis \u5fc5\u9808 \u5165\u308c\u66ff\u3048\u3092\u884c\u3046\u8ef8\u3092\u6307\u5b9a\u3059\u308b\u6574\u6570\u3002 Integer 2 order \u5fc5\u9808 \u5165\u308c\u66ff\u3048\u524d\u306e\u9806\u5e8f\u3092\u5165\u308c\u66ff\u3048\u5f8c\u306e\u9806\u5e8f\u3067\u4e26\u3079\u305f\u6574\u6570\u914d\u5217\u3002 Array of Integer [2, 1, 0] weights: None attrs: None Madd Layer \u00b6 Multiply add (scale * x + bias) \u3092\u884c\u3046\u30ec\u30a4\u30e4\u3002\u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b63\u898f\u5316\u3001\u5e73\u5747\u5024\u306e\u6e1b\u7b97\u306a\u3069\u3092\u4e00\u62ec\u3067\u884c\u3046\u3002 params Properties Required Description Type Example has_relu \u30aa\u30d7\u30b7\u30e7\u30f3 \u51fa\u529b\u306b\u5bfe\u3057\u3066 Relu activation \u3092\u884c\u3046\u304b\u3092\u6307\u5b9a\u3059\u308b\u771f\u507d\u5024\u3002\u30c7\u30d5\u30a9\u30eb\u30c8 False\u3002 Boolean False relu_max_value \u30aa\u30d7\u30b7\u30e7\u30f3 Relu activation \u3092\u884c\u3046\u969b\u306e\u51fa\u529b\u306e\u6700\u5927\u5024\u3002 has_relu \u304c True \u306e\u3068\u304d\u306e\u307f\u6709\u52b9\u3002 Number 6.0 weights Properties Required Description Type Example scale \u5fc5\u9808 \u5165\u529b\u306b\u5bfe\u3057\u3066\u4e57\u7b97\u3055\u308c\u308b\u6570\u5024\u3001\u307e\u305f\u306f\u6570\u5024\u914d\u5217\u3002\u30c1\u30e3\u30f3\u30cd\u30eb\u3054\u3068\u306b\u7570\u306a\u308b\u5024\u3092\u6307\u5b9a\u3059\u308b\u5834\u5408\u306f\u914d\u5217\u3068\u3059\u308b\u3002bias \u3068\u540c\u3058\u8981\u7d20\u6570\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002 Number or Array of Number [0.01712475383, 0.0175070028, 0.01742919389] bias \u5fc5\u9808 \u5165\u529b\u306b\u5bfe\u3057\u3066\u52a0\u7b97\u3055\u308c\u308b\u6570\u5024\u3001\u307e\u305f\u306f\u6570\u5024\u914d\u5217\u3002\u30c1\u30e3\u30f3\u30cd\u30eb\u3054\u3068\u306b\u7570\u306a\u308b\u5024\u3092\u6307\u5b9a\u3059\u308b\u5834\u5408\u306f\u914d\u5217\u3068\u3059\u308b\u3002scale \u3068\u540c\u3058\u8981\u7d20\u6570\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002 Number or Array of Number [2.11790393013, 2.03571428571, 1.80444444444] attrs: None preprocess example \u00b6 [ { \"name\": \"preprocess\", \"layers\": [ { \"type\": \"source\", \"params\": { \"shape\": [ 1, 320, 320, 3 ] }, \"attrs\": { \"format\": \"rgb\", \"attrs\": { \"format\": \"rgb\", \"resize_mode\": \"bilinear\", \"keep_ar\": true, \"padding_clor\": [ 0, 0, 0 ] } } }, { \"type\": \"permute\", \"params\": { \"axis\": 3, \"dims\": [ 2, 1, 0 ] } }, { \"type\": \"madd\", \"weights\": { \"scale\": [ 0.0135694, 0.0143123, 0.0141064 ], \"bias\": [ -1.41176, -1.63139, -1.69065 ] } }, { \"type\": \"sink\" } ] } ] postprocess\u8a18\u8ff0\u4ed5\u69d8 \u00b6 postprocess\u3067\u306f\u51fa\u529b\u306b\u30e9\u30d9\u30eb\u540d\uff08\u6587\u5b57\u5217\uff09\u3092\u4ed8\u4e0e\u3057\u305f\u308a\u3001\u4e3b\u306bObject Detection\u30bf\u30b9\u30af\u3067\u6700\u7d42\u6bb5\u306e\u30c7\u30b3\u30fc\u30c9\u51e6\u7406\u306e\u65b9\u5f0f\u3092\u6307\u5b9a\u3057\u305f\u308a\u3057\u307e\u3059\u3002 postprocess\u5185\u306e\u5404\u8981\u7d20\u306b\u95a2\u3059\u308b\u8aac\u660e\u3092\u4e0b\u8a18\u306b\u8a18\u8f09\u3057\u307e\u3059\u3002 layers \u00b6 \u5404\u30ec\u30a4\u30e4\u306f\u3001\u30ec\u30a4\u30e4\u306e\u30bf\u30a4\u30d7\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u30a6\u30a7\u30a4\u30c8\u3001\u30a2\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\u306e4\u3064\u306e\u8981\u7d20\u304b\u3089\u69cb\u6210\u3055\u308c\u307e\u3059\u3002 Properties Required Description Type Example type \u5fc5\u9808 \u30ec\u30a4\u30e4\u306e\u7a2e\u985e\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002source, sink, decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 \u7b49\u304c\u6307\u5b9a\u53ef\u80fd\u3002 String \"decode_ssd\" params \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b weights \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30a6\u30a7\u30a4\u30c8\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b attrs \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u4ed8\u52a0\u60c5\u5831\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b Source Layer \u00b6 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30ec\u30a4\u30e4\u3002 params Properties Required Description Type Example shape \u5fc5\u9808 \u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b21\u5143\u6570\u3092\u6307\u5b9a\u3059\u308b\u6574\u6570\u914d\u5217\u3002 Array of Integer [224, 224, 3] weights: None attrs: None Sink Layer \u00b6 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u30ec\u30a4\u30e4\u3002 params: None weights: None attrs Properties Required Description Type Example label_list \u30aa\u30d7\u30b7\u30e7\u30f3 \u5b66\u7fd2\u3057\u305f\u30e9\u30d9\u30eb\u306e\u6587\u5b57\u5217\u914d\u5217 Array of String [\"cat\", \"dog\", \"bird\"] Decode Layer \u00b6 Object Detection\u30bf\u30b9\u30af\u3067\u6700\u7d42\u6bb5\u306e\u30c7\u30b3\u30fc\u30c9\u51e6\u7406\u3092\u884c\u3044\u307e\u3059\u3002type\u306f decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 \u304c\u6307\u5b9a\u53ef\u80fd\u3067\u3059\u3002 params Properties Required Description Type Example keep_top_k centernet, pelee, ssd, yolov3, yolov4 \u51fa\u529b\u3059\u308b\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u500b\u6570\u3092\u6307\u5b9a\u3059\u308b\u3002\uff08\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306f\u30b9\u30b3\u30a2\u306e\u9ad8\u3044\u9806\u306b\u9078\u3070\u308c\u308b\uff09\u30c7\u30d5\u30a9\u30eb\u30c8: 300 Integer 300 do_nms centernet, pelee, ssd, yolov3, yolov4 \u51fa\u529b\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306bNMS (Non-Maximum Suppression) \u51e6\u7406\u3092\u3059\u308b\u304b\u5426\u304b\u3092\u6307\u5b9a\u3059\u308b\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: true Boolean true nms_thresh centernet, pelee, ssd, yolov3, yolov4 NMS\u51e6\u7406\u3092\u3059\u308b\u969b\u306eIoU\u95be\u5024\u3092\u6307\u5b9a\u3059\u308b\u3002 Float 0.5 conf_thresh centernet, pelee, ssd, yolov3, yolov4 \u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u691c\u51fa\u306e\u30b3\u30f3\u30d5\u30a3\u30c7\u30f3\u30b9\u95be\u5024\u3092\u6307\u5b9a\u3059\u308b\u3002 Float 0.3 background_label_id pelee, ssd \u80cc\u666f\u30e9\u30d9\u30eb\u306b\u5bfe\u3059\u308b\u30e9\u30d9\u30eb\u756a\u53f7\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: 0 Integer 0 img_width yolov3 \u5165\u529b\u753b\u50cf\u306e\u5e45 Integer 416 img_height yolov3 \u5165\u529b\u753b\u50cf\u306e\u9ad8\u3055 Integer 416 num_anchors_per_out yolov3 1\u3064\u306e\u30b0\u30ea\u30c3\u30c9\u30bb\u30eb\u306b\u5bfe\u3059\u308b\u30a2\u30f3\u30ab\u30fc\u30dc\u30c3\u30af\u30b9\u306e\u6570\u3002 Integer 3 anchors yolov3 \u30a2\u30f3\u30ab\u30fc\u30dc\u30c3\u30af\u30b9\u306e\u30b5\u30a4\u30ba\u3092\u8868\u3059\u914d\u5217\u3002[w1, h1, w2, w3, ...] Float array [10,13, 16,30] weights: None attrs: None postprocess example \u00b6 [ { \"name\": \"postprocess\", \"layers\": [ { \"name\": \"input\", \"type\": \"source\", \"params\": { \"shape\":[1, 300, 15] } }, { \"name\": \"decode\", \"type\": \"decode_ssd\", \"params\": { \"keep_top_k\" : 300, \"background_label_id\" : 0, \"nms_thresh\" : 0.45, \"conf_thresh\" : 0.01 } }, { \"name\": \"output\", \"type\": \"sink\" } ] } ] import-onnx \u00b6 ONNX\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro import-onnx [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT ONNX\u5f62\u5f0f\u306e\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u30b3\u30f3\u30d0\u30fc\u30c8\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 extract\u30aa\u30d7\u30b7\u30e7\u30f3\u5229\u7528\u6642\u306fextract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306b\u306a\u308a\u307e\u3059\u3002 --preprocess_json PREPROCESS_JSON preprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 --postprocess_json POSTPROCESS_JSON postprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --naive FuseRelu\u7b49\u306e\u6700\u9069\u5316\u3092\u884c\u308f\u305a\u306bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u5834\u5408\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --extract \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 --help \u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30b3\u30f3\u30d0\u30fc\u30c8\u51e6\u7406\u5b8c\u4e86\u5f8c\u306b\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bmobilenet_v2.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 $ softneuro import-onnx mobilenet_v2.onnx mobilenet_v2.dnn import model converting initializers: done converting nodes: done rectify model optimize model save model import-tensorflow \u00b6 TensorFlow\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro import-tensorflow [-h] [--keras] [--list-keras] [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--output_attrs OUTPUT_ATTRS] [--input_node [INPUT_NODE_NAME]] [--input_shape [INPUT_SHAPE]] [--output_node [OUTPUT_NODE_NAME]] [--fix_shape_inf] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT protocol buffer(.pb)\u5f62\u5f0f\u307e\u305f\u306fhdf5\u5f62\u5f0f\u306e\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 hdf5\u5f62\u5f0f\u306e\u5834\u5408\u306f\u91cd\u307f\u3060\u3051\u3067\u306f\u306a\u304f\u30e2\u30c7\u30eb\u69cb\u9020\u306e\u60c5\u5831\u3082\u542b\u3093\u3060\u3082\u306e\u3092\u3054\u7528\u610f\u304f\u3060\u3055\u3044\u3002 OUTPUT \u30b3\u30f3\u30d0\u30fc\u30c8\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 extract\u30aa\u30d7\u30b7\u30e7\u30f3\u5229\u7528\u6642\u306fextract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306b\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u5185\u5bb9 --keras tf.keras.applications\u306e\u30e2\u30c7\u30eb\u540d\u3067\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u4e3b\u8981\u306a\u30e2\u30c7\u30eb\u3092DNN\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3067\u304d\u307e\u3059\u3002 \u5bfe\u8c61\u306e\u30e2\u30c7\u30eb\u306b\u95a2\u3059\u308b\u306e\u8a73\u7d30\u306a\u60c5\u5831\u306f keras\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8 \u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002 --list-keras --keras \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u5229\u7528\u53ef\u80fd\u306a\u30e2\u30c7\u30eb\u540d\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --naive FuseRelu\u7b49\u306e\u6700\u9069\u5316\u3092\u884c\u308f\u305a\u306bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u5834\u5408\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --extract \u3000 \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 --preprocess_json PREPROCESS_JSON preprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 --postprocess_json POSTPROCESS_JSON postprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 --output_attrs OUTPUT_ATTRS \u51fa\u529b\u30a2\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\uff08\u51fa\u529b\u30e9\u30d9\u30eb\uff09\u60c5\u5831\u3092\u542b\u3080 JSON \u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306f\u30d7\u30ea\u30bb\u30c3\u30c8\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 --input_node [INPUT_NODE] \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30ce\u30fc\u30c9\u540d\u3067\u3059\u3002 --input_shape [SHAPE] \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30b7\u30a7\u30a4\u30d7\u3067\u3059\u3002 --output_node [OUTPUT_NODE] \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u30ce\u30fc\u30c9\u540d\u3067\u3059\u3002 --fix_shape_inf \u30a4\u30f3\u30dd\u30fc\u30c8\u6642\u306b\u30b7\u30a7\u30a4\u30d7\u3092\u56fa\u5b9a\u3057\u307e\u3059\u3002 -h, --help \u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30b3\u30f3\u30d0\u30fc\u30c8\u51e6\u7406\u5b8c\u4e86\u5f8c\u306b\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 softneuro import-tensorflow vgg16.pb vgg16.dnn import-ver3 \u00b6 Ver3\u306eDNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089Ver5\u306eDNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro import-ver3 [--naive] [--extract] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT ver3\u5f62\u5f0f\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u30b3\u30f3\u30d0\u30fc\u30c8\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bver5\u5f62\u5f0f\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 extract\u30aa\u30d7\u30b7\u30e7\u30f3\u5229\u7528\u6642\u306fextract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306b\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u5185\u5bb9 --naive FuseRelu\u7b49\u306e\u6700\u9069\u5316\u3092\u884c\u308f\u305a\u306bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u5834\u5408\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --extract \u3000 \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 -h, --help \u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30b3\u30f3\u30d0\u30fc\u30c8\u51e6\u7406\u5b8c\u4e86\u5f8c\u306b\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_v5.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 softneuro import-ver3 vgg16_v3.dnn vgg16_v5.dnn import model rectify model optimize model save model","title":"\u30b3\u30f3\u30d0\u30fc\u30c8\u7cfb"},{"location":"commands/dnn/converter.ja.html#_1","text":"\u5404\u7a2e\u30d5\u30ec\u30fc\u30e0\u30ef\u30fc\u30af\u304b\u3089\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3092SoftNeuro\u3067\u6271\u3048\u308bDNN\u5f62\u5f0f\u306b\u30b3\u30f3\u30d0\u30fc\u30c8\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002","title":"\u30b3\u30f3\u30d0\u30fc\u30c8\u7cfb"},{"location":"commands/dnn/converter.ja.html#preprocess-postprocess","text":"SoftNeuroV4\u304b\u3089\u3001preprocess, postprocess\u306f main \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u524d\u5f8c\u306b\u63a5\u7d9a\u3055\u308c\u3066\u3044\u308b preprocess , postprocess \u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u884c\u308f\u308c\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3057\u305f\u3002 \u3053\u308c\u3089\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u60c5\u5831\u306fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u308b\u306e\u3067\u3001 io_params \u306e\u30d5\u30a1\u30a4\u30eb\u306f\u4e0d\u8981\u3068\u306a\u308a\u307e\u3057\u305f\u3002 \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306b\u542b\u307e\u308c\u306a\u3044preprocess, postprocess\u3092\u8ffd\u52a0\u3059\u308b\u5834\u5408\u306f\u30d7\u30ea\u30bb\u30c3\u30c8\u306ejson\u30d5\u30a1\u30a4\u30eb\u3092 converter\u306b\u4e0e\u3048\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u30d7\u30ea\u30bb\u30c3\u30c8\u306b\u5b58\u5728\u3057\u306a\u3044\u9806\u5e8f\u30fb\u8a2d\u5b9a\u306epreprocess, postprocess\u3092\u8ffd\u52a0\u3059\u308b\u5834\u5408\u306f\u30d7\u30ea\u30bb\u30c3\u30c8\u306ejson\u30d5\u30a1\u30a4\u30eb\u3092 \u66f8\u304d\u63db\u3048\u3066\u5229\u7528\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \u73fe\u6642\u70b9\u3067 preprocess, postprocess \u3092\u8ffd\u52a0\u3059\u308b\u30aa\u30d7\u30b7\u30e7\u30f3\u306f import-onnx , import-tensorflow \u3067\u306e\u307f\u5229\u7528\u53ef\u80fd\u3067\u3001 import-ver3 \u3067\u306f\u672a\u5bfe\u5fdc\u3067\u3059\u3002","title":"preprocess, postprocess\u306b\u3064\u3044\u3066"},{"location":"commands/dnn/converter.ja.html#preprocess","text":"preprocess\u3067\u306f\u753b\u50cf\u306e\u30ea\u30b5\u30a4\u30ba\u3001\u30ea\u30b5\u30a4\u30ba\u65b9\u5f0f\u306e\u6307\u5b9a\u3001\u8272\u7a7a\u9593\u306e\u6307\u5b9a\u3001\u30c7\u30fc\u30bf\u306e\u6b63\u898f\u5316\u306a\u3069\u3092\u884c\u3044\u307e\u3059\u3002 preprocess\u5185\u306e\u5404\u8981\u7d20\u306b\u95a2\u3059\u308b\u8aac\u660e\u3092\u4e0b\u8a18\u306b\u8a18\u8f09\u3057\u307e\u3059\u3002","title":"preprocess\u8a18\u8ff0\u4ed5\u69d8"},{"location":"commands/dnn/converter.ja.html#layers","text":"\u5404\u30ec\u30a4\u30e4\u306f\u3001\u30ec\u30a4\u30e4\u306e\u30bf\u30a4\u30d7\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u30a6\u30a7\u30a4\u30c8\u3001\u30a2\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\u306e4\u3064\u306e\u8981\u7d20\u304b\u3089\u69cb\u6210\u3055\u308c\u307e\u3059\u3002 Properties Required Description Type Example type \u5fc5\u9808 \u30ec\u30a4\u30e4\u306e\u7a2e\u985e\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002source, sink, madd, permute \u7b49\u304c\u6307\u5b9a\u53ef\u80fd\u3002 String \"madd\" params \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b weights \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30a6\u30a7\u30a4\u30c8\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b attrs \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u4ed8\u52a0\u60c5\u5831\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b","title":"layers"},{"location":"commands/dnn/converter.ja.html#source-layer","text":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30ec\u30a4\u30e4\u3002 params Properties Required Description Type Example shape \u5fc5\u9808 \u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b21\u5143\u6570\u3092\u6307\u5b9a\u3059\u308b\u6574\u6570\u914d\u5217\u3002 Array of Integer [224, 224, 3] weights: None attrs Properties Required Description Type Example format \u30aa\u30d7\u30b7\u30e7\u30f3 \u5165\u529b\u753b\u50cf\u306e\u8272\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002\"rgb\" \u306e\u307f\u6307\u5b9a\u53ef\u80fd\u3002 String \"rgb\" resize_mode \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ea\u30b5\u30a4\u30ba\u65b9\u5f0f\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002\"bilinear\" (\u30c7\u30d5\u30a9\u30eb\u30c8) \u3068 \"nearest\" \u3092\u6307\u5b9a\u53ef\u3002 String \"bilinear\" keep_ar \u30aa\u30d7\u30b7\u30e7\u30f3 \u753b\u50cf\u7e2e\u5c0f\u306e\u969b\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3059\u308b\u304b\u3092\u6307\u5b9a\u3059\u308b\u771f\u507d\u5024\u3002\uff08\u30c7\u30d5\u30a9\u30eb\u30c8 false\uff09 Boolean true padding_color \u30aa\u30d7\u30b7\u30e7\u30f3 \u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3057\u305f\u7e2e\u5c0f\u306e\u969b\u306b\u751f\u3058\u308b\u7a7a\u9593\u3092\u57cb\u3081\u308b\u30d1\u30c7\u30a3\u30f3\u30b0\u306e\u8272\u3092\u6307\u5b9a\u3059\u308b\u6570\u5024\u914d\u5217\u3002 Array of Numbers [255, 255, 255]","title":"Source Layer"},{"location":"commands/dnn/converter.ja.html#sink-layer","text":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u30ec\u30a4\u30e4\u3002 params: None weights: None attrs: None","title":"Sink Layer"},{"location":"commands/dnn/converter.ja.html#permute-layer","text":"axis \u3092\u6307\u5b9a\u3057\u3066 axis \u5185\u306e\u30c7\u30fc\u30bf\u306e\u9806\u5e8f\u3092\u5165\u308c\u66ff\u3048\u308b\u30ec\u30a4\u30e4\u3002\u30c1\u30e3\u30f3\u30cd\u30eb\u30b9\u30ef\u30c3\u30d7\u3067\u5229\u7528\u3002 params Properties Required Description Type Example axis \u5fc5\u9808 \u5165\u308c\u66ff\u3048\u3092\u884c\u3046\u8ef8\u3092\u6307\u5b9a\u3059\u308b\u6574\u6570\u3002 Integer 2 order \u5fc5\u9808 \u5165\u308c\u66ff\u3048\u524d\u306e\u9806\u5e8f\u3092\u5165\u308c\u66ff\u3048\u5f8c\u306e\u9806\u5e8f\u3067\u4e26\u3079\u305f\u6574\u6570\u914d\u5217\u3002 Array of Integer [2, 1, 0] weights: None attrs: None","title":"Permute Layer"},{"location":"commands/dnn/converter.ja.html#madd-layer","text":"Multiply add (scale * x + bias) \u3092\u884c\u3046\u30ec\u30a4\u30e4\u3002\u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b63\u898f\u5316\u3001\u5e73\u5747\u5024\u306e\u6e1b\u7b97\u306a\u3069\u3092\u4e00\u62ec\u3067\u884c\u3046\u3002 params Properties Required Description Type Example has_relu \u30aa\u30d7\u30b7\u30e7\u30f3 \u51fa\u529b\u306b\u5bfe\u3057\u3066 Relu activation \u3092\u884c\u3046\u304b\u3092\u6307\u5b9a\u3059\u308b\u771f\u507d\u5024\u3002\u30c7\u30d5\u30a9\u30eb\u30c8 False\u3002 Boolean False relu_max_value \u30aa\u30d7\u30b7\u30e7\u30f3 Relu activation \u3092\u884c\u3046\u969b\u306e\u51fa\u529b\u306e\u6700\u5927\u5024\u3002 has_relu \u304c True \u306e\u3068\u304d\u306e\u307f\u6709\u52b9\u3002 Number 6.0 weights Properties Required Description Type Example scale \u5fc5\u9808 \u5165\u529b\u306b\u5bfe\u3057\u3066\u4e57\u7b97\u3055\u308c\u308b\u6570\u5024\u3001\u307e\u305f\u306f\u6570\u5024\u914d\u5217\u3002\u30c1\u30e3\u30f3\u30cd\u30eb\u3054\u3068\u306b\u7570\u306a\u308b\u5024\u3092\u6307\u5b9a\u3059\u308b\u5834\u5408\u306f\u914d\u5217\u3068\u3059\u308b\u3002bias \u3068\u540c\u3058\u8981\u7d20\u6570\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002 Number or Array of Number [0.01712475383, 0.0175070028, 0.01742919389] bias \u5fc5\u9808 \u5165\u529b\u306b\u5bfe\u3057\u3066\u52a0\u7b97\u3055\u308c\u308b\u6570\u5024\u3001\u307e\u305f\u306f\u6570\u5024\u914d\u5217\u3002\u30c1\u30e3\u30f3\u30cd\u30eb\u3054\u3068\u306b\u7570\u306a\u308b\u5024\u3092\u6307\u5b9a\u3059\u308b\u5834\u5408\u306f\u914d\u5217\u3068\u3059\u308b\u3002scale \u3068\u540c\u3058\u8981\u7d20\u6570\u3067\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002 Number or Array of Number [2.11790393013, 2.03571428571, 1.80444444444] attrs: None","title":"Madd Layer"},{"location":"commands/dnn/converter.ja.html#preprocess-example","text":"[ { \"name\": \"preprocess\", \"layers\": [ { \"type\": \"source\", \"params\": { \"shape\": [ 1, 320, 320, 3 ] }, \"attrs\": { \"format\": \"rgb\", \"attrs\": { \"format\": \"rgb\", \"resize_mode\": \"bilinear\", \"keep_ar\": true, \"padding_clor\": [ 0, 0, 0 ] } } }, { \"type\": \"permute\", \"params\": { \"axis\": 3, \"dims\": [ 2, 1, 0 ] } }, { \"type\": \"madd\", \"weights\": { \"scale\": [ 0.0135694, 0.0143123, 0.0141064 ], \"bias\": [ -1.41176, -1.63139, -1.69065 ] } }, { \"type\": \"sink\" } ] } ]","title":"preprocess example"},{"location":"commands/dnn/converter.ja.html#postprocess","text":"postprocess\u3067\u306f\u51fa\u529b\u306b\u30e9\u30d9\u30eb\u540d\uff08\u6587\u5b57\u5217\uff09\u3092\u4ed8\u4e0e\u3057\u305f\u308a\u3001\u4e3b\u306bObject Detection\u30bf\u30b9\u30af\u3067\u6700\u7d42\u6bb5\u306e\u30c7\u30b3\u30fc\u30c9\u51e6\u7406\u306e\u65b9\u5f0f\u3092\u6307\u5b9a\u3057\u305f\u308a\u3057\u307e\u3059\u3002 postprocess\u5185\u306e\u5404\u8981\u7d20\u306b\u95a2\u3059\u308b\u8aac\u660e\u3092\u4e0b\u8a18\u306b\u8a18\u8f09\u3057\u307e\u3059\u3002","title":"postprocess\u8a18\u8ff0\u4ed5\u69d8"},{"location":"commands/dnn/converter.ja.html#layers_1","text":"\u5404\u30ec\u30a4\u30e4\u306f\u3001\u30ec\u30a4\u30e4\u306e\u30bf\u30a4\u30d7\u3001\u30d1\u30e9\u30e1\u30fc\u30bf\u3001\u30a6\u30a7\u30a4\u30c8\u3001\u30a2\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\u306e4\u3064\u306e\u8981\u7d20\u304b\u3089\u69cb\u6210\u3055\u308c\u307e\u3059\u3002 Properties Required Description Type Example type \u5fc5\u9808 \u30ec\u30a4\u30e4\u306e\u7a2e\u985e\u3092\u6307\u5b9a\u3059\u308b\u6587\u5b57\u5217\u3002source, sink, decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 \u7b49\u304c\u6307\u5b9a\u53ef\u80fd\u3002 String \"decode_ssd\" params \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b weights \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u30a6\u30a7\u30a4\u30c8\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b attrs \u30aa\u30d7\u30b7\u30e7\u30f3 \u30ec\u30a4\u30e4\u306e\u4ed8\u52a0\u60c5\u5831\u3092\u6307\u5b9a\u3059\u308b JSON \u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002 Object \u8a18\u8ff0\u4f8b","title":"layers"},{"location":"commands/dnn/converter.ja.html#source-layer_1","text":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30ec\u30a4\u30e4\u3002 params Properties Required Description Type Example shape \u5fc5\u9808 \u5165\u529b\u30c7\u30fc\u30bf\u306e\u6b21\u5143\u6570\u3092\u6307\u5b9a\u3059\u308b\u6574\u6570\u914d\u5217\u3002 Array of Integer [224, 224, 3] weights: None attrs: None","title":"Source Layer"},{"location":"commands/dnn/converter.ja.html#sink-layer_1","text":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u30ec\u30a4\u30e4\u3002 params: None weights: None attrs Properties Required Description Type Example label_list \u30aa\u30d7\u30b7\u30e7\u30f3 \u5b66\u7fd2\u3057\u305f\u30e9\u30d9\u30eb\u306e\u6587\u5b57\u5217\u914d\u5217 Array of String [\"cat\", \"dog\", \"bird\"]","title":"Sink Layer"},{"location":"commands/dnn/converter.ja.html#decode-layer","text":"Object Detection\u30bf\u30b9\u30af\u3067\u6700\u7d42\u6bb5\u306e\u30c7\u30b3\u30fc\u30c9\u51e6\u7406\u3092\u884c\u3044\u307e\u3059\u3002type\u306f decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 \u304c\u6307\u5b9a\u53ef\u80fd\u3067\u3059\u3002 params Properties Required Description Type Example keep_top_k centernet, pelee, ssd, yolov3, yolov4 \u51fa\u529b\u3059\u308b\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u500b\u6570\u3092\u6307\u5b9a\u3059\u308b\u3002\uff08\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306f\u30b9\u30b3\u30a2\u306e\u9ad8\u3044\u9806\u306b\u9078\u3070\u308c\u308b\uff09\u30c7\u30d5\u30a9\u30eb\u30c8: 300 Integer 300 do_nms centernet, pelee, ssd, yolov3, yolov4 \u51fa\u529b\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306bNMS (Non-Maximum Suppression) \u51e6\u7406\u3092\u3059\u308b\u304b\u5426\u304b\u3092\u6307\u5b9a\u3059\u308b\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: true Boolean true nms_thresh centernet, pelee, ssd, yolov3, yolov4 NMS\u51e6\u7406\u3092\u3059\u308b\u969b\u306eIoU\u95be\u5024\u3092\u6307\u5b9a\u3059\u308b\u3002 Float 0.5 conf_thresh centernet, pelee, ssd, yolov3, yolov4 \u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u691c\u51fa\u306e\u30b3\u30f3\u30d5\u30a3\u30c7\u30f3\u30b9\u95be\u5024\u3092\u6307\u5b9a\u3059\u308b\u3002 Float 0.3 background_label_id pelee, ssd \u80cc\u666f\u30e9\u30d9\u30eb\u306b\u5bfe\u3059\u308b\u30e9\u30d9\u30eb\u756a\u53f7\u3002\u30c7\u30d5\u30a9\u30eb\u30c8: 0 Integer 0 img_width yolov3 \u5165\u529b\u753b\u50cf\u306e\u5e45 Integer 416 img_height yolov3 \u5165\u529b\u753b\u50cf\u306e\u9ad8\u3055 Integer 416 num_anchors_per_out yolov3 1\u3064\u306e\u30b0\u30ea\u30c3\u30c9\u30bb\u30eb\u306b\u5bfe\u3059\u308b\u30a2\u30f3\u30ab\u30fc\u30dc\u30c3\u30af\u30b9\u306e\u6570\u3002 Integer 3 anchors yolov3 \u30a2\u30f3\u30ab\u30fc\u30dc\u30c3\u30af\u30b9\u306e\u30b5\u30a4\u30ba\u3092\u8868\u3059\u914d\u5217\u3002[w1, h1, w2, w3, ...] Float array [10,13, 16,30] weights: None attrs: None","title":"Decode Layer"},{"location":"commands/dnn/converter.ja.html#postprocess-example","text":"[ { \"name\": \"postprocess\", \"layers\": [ { \"name\": \"input\", \"type\": \"source\", \"params\": { \"shape\":[1, 300, 15] } }, { \"name\": \"decode\", \"type\": \"decode_ssd\", \"params\": { \"keep_top_k\" : 300, \"background_label_id\" : 0, \"nms_thresh\" : 0.45, \"conf_thresh\" : 0.01 } }, { \"name\": \"output\", \"type\": \"sink\" } ] } ]","title":"postprocess example"},{"location":"commands/dnn/converter.ja.html#import-onnx","text":"ONNX\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro import-onnx [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT ONNX\u5f62\u5f0f\u306e\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u30b3\u30f3\u30d0\u30fc\u30c8\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 extract\u30aa\u30d7\u30b7\u30e7\u30f3\u5229\u7528\u6642\u306fextract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306b\u306a\u308a\u307e\u3059\u3002 --preprocess_json PREPROCESS_JSON preprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 --postprocess_json POSTPROCESS_JSON postprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --naive FuseRelu\u7b49\u306e\u6700\u9069\u5316\u3092\u884c\u308f\u305a\u306bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u5834\u5408\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --extract \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 --help \u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30b3\u30f3\u30d0\u30fc\u30c8\u51e6\u7406\u5b8c\u4e86\u5f8c\u306b\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bmobilenet_v2.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 $ softneuro import-onnx mobilenet_v2.onnx mobilenet_v2.dnn import model converting initializers: done converting nodes: done rectify model optimize model save model","title":"import-onnx"},{"location":"commands/dnn/converter.ja.html#import-tensorflow","text":"TensorFlow\u30e2\u30c7\u30eb\u304b\u3089DNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro import-tensorflow [-h] [--keras] [--list-keras] [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--output_attrs OUTPUT_ATTRS] [--input_node [INPUT_NODE_NAME]] [--input_shape [INPUT_SHAPE]] [--output_node [OUTPUT_NODE_NAME]] [--fix_shape_inf] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT protocol buffer(.pb)\u5f62\u5f0f\u307e\u305f\u306fhdf5\u5f62\u5f0f\u306e\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 hdf5\u5f62\u5f0f\u306e\u5834\u5408\u306f\u91cd\u307f\u3060\u3051\u3067\u306f\u306a\u304f\u30e2\u30c7\u30eb\u69cb\u9020\u306e\u60c5\u5831\u3082\u542b\u3093\u3060\u3082\u306e\u3092\u3054\u7528\u610f\u304f\u3060\u3055\u3044\u3002 OUTPUT \u30b3\u30f3\u30d0\u30fc\u30c8\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 extract\u30aa\u30d7\u30b7\u30e7\u30f3\u5229\u7528\u6642\u306fextract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306b\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u5185\u5bb9 --keras tf.keras.applications\u306e\u30e2\u30c7\u30eb\u540d\u3067\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u4e3b\u8981\u306a\u30e2\u30c7\u30eb\u3092DNN\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3067\u304d\u307e\u3059\u3002 \u5bfe\u8c61\u306e\u30e2\u30c7\u30eb\u306b\u95a2\u3059\u308b\u306e\u8a73\u7d30\u306a\u60c5\u5831\u306f keras\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8 \u3092\u3054\u53c2\u7167\u304f\u3060\u3055\u3044\u3002 --list-keras --keras \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u5229\u7528\u53ef\u80fd\u306a\u30e2\u30c7\u30eb\u540d\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --naive FuseRelu\u7b49\u306e\u6700\u9069\u5316\u3092\u884c\u308f\u305a\u306bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u5834\u5408\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --extract \u3000 \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 --preprocess_json PREPROCESS_JSON preprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 --postprocess_json POSTPROCESS_JSON postprocess\u3092\u30e2\u30c7\u30eb\u306b\u8ffd\u52a0\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308bjson\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 --output_attrs OUTPUT_ATTRS \u51fa\u529b\u30a2\u30c8\u30ea\u30d3\u30e5\u30fc\u30c8\uff08\u51fa\u529b\u30e9\u30d9\u30eb\uff09\u60c5\u5831\u3092\u542b\u3080 JSON \u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306f\u30d7\u30ea\u30bb\u30c3\u30c8\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 --input_node [INPUT_NODE] \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30ce\u30fc\u30c9\u540d\u3067\u3059\u3002 --input_shape [SHAPE] \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5165\u529b\u30b7\u30a7\u30a4\u30d7\u3067\u3059\u3002 --output_node [OUTPUT_NODE] \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u51fa\u529b\u30ce\u30fc\u30c9\u540d\u3067\u3059\u3002 --fix_shape_inf \u30a4\u30f3\u30dd\u30fc\u30c8\u6642\u306b\u30b7\u30a7\u30a4\u30d7\u3092\u56fa\u5b9a\u3057\u307e\u3059\u3002 -h, --help \u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30b3\u30f3\u30d0\u30fc\u30c8\u51e6\u7406\u5b8c\u4e86\u5f8c\u306b\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 softneuro import-tensorflow vgg16.pb vgg16.dnn","title":"import-tensorflow"},{"location":"commands/dnn/converter.ja.html#import-ver3","text":"Ver3\u306eDNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089Ver5\u306eDNN\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3078\u306e\u5909\u63db\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro import-ver3 [--naive] [--extract] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT ver3\u5f62\u5f0f\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u30b3\u30f3\u30d0\u30fc\u30c8\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bver5\u5f62\u5f0f\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 extract\u30aa\u30d7\u30b7\u30e7\u30f3\u5229\u7528\u6642\u306fextract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u306b\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u5185\u5bb9 --naive FuseRelu\u7b49\u306e\u6700\u9069\u5316\u3092\u884c\u308f\u305a\u306bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u4fdd\u5b58\u3059\u308b\u5834\u5408\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --extract \u3000 \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 -h, --help \u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30b3\u30f3\u30d0\u30fc\u30c8\u51e6\u7406\u5b8c\u4e86\u5f8c\u306b\u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_v5.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 softneuro import-ver3 vgg16_v3.dnn vgg16_v5.dnn import model rectify model optimize model save model","title":"import-ver3"},{"location":"commands/dnn/converter.html","text":"Model Conversion \u00b6 Commands for converting model files from various frameworks into the SoftNeuro DNN file format. About preprocess, postprocess \u00b6 In SoftNeuro preprocess and postprocess are separate networks attached to the beginning and to the end of the main network, respectively. These networks can be attached as a json file when converting a model. There's a preset json file, but it can be changed for custom settings. Currently, adding preprocess and postprocess networks is only available for import-onnx and import-tensorflow , and not available for import-ver3 . Preprocess specification \u00b6 The preprocess network can be used for resizing images, specifying resize mode, specifying color format, normalizing data, and so on. Descriptions of each element in preprocess is below. layers \u00b6 Each layer consists of four elements: type, params, weights, and attrs. Properties Required Description Type Example type Mandatory String specifying the layer type. source, sink, madd, permute, can be specified. String \"madd\" params Optional JSON object specifying layer parameters. Object example weights Optional JSON object specifying leyer weights. Object example attrs Optional JSON object specifying layer attributes. Object example Source Layer \u00b6 Input layer of the network. params Properties Required Description Type Example shape Mandatory Array of integer specifying the shape of the input data. Array of Integer [224, 224, 3] weights: None attrs Properties Required Description Type Example format Optional String specifying the color format of the input image. Only \"rgb\" can be specified. String \"rgb\" resize_mode Optional String specifying the resize mode. \"bilinear\" (default) or \"nearest\" can be specified. String \"bilinear\" keep_ar Optional Boolean specifying whether or not to keep aspect ratio when resizing. Default is false. Boolean true padding_color Optional Array of numbers specifying the padding color filling the margin space when resizing. Array of Numbers [255, 255, 255] Sink Layer \u00b6 Output layer of the network. params: None weights: None attrs: None Permute Layer \u00b6 Permutes the data order in the specified axis. Commonly used for channel-swapping. params Properties Required Description Type Example axis Mandatory Integer specifying the axis to be permuted. Integer 2 order Mandatory Array of integers containing the original positions ordered by their new indexes. Array of Integer [2, 1, 0] weights: None attrs: None Madd Layer \u00b6 Multiply add (scale * x + bias) layer. Commonly used for normalization of input data, subtraction of mean, and so on. params Properties Required Description Type Example has_relu Optional Boolean specifying whether or not to execute Relu activation. Default is False. Boolean False relu_max_value Optional Max output value after Relu activation. Only valid when has_relu is True. Number 6.0 weights Properties Required Description Type Example scale Mandatory Number or array of numbers by which the input data is multiplied. Must be array if different value is specified for each channel. Must have the same number of elements as bias. Number or Array of Number [0.01712475383, 0.0175070028, 0.01742919389] bias Mandatory Number or array of numbers, to be added to the input data. Must be array if different value is specified for each channel. Must have the same number of elements as scale. Number or Array of Number [2.11790393013, 2.03571428571, 1.80444444444] attrs: None preprocess example \u00b6 [ { \"name\": \"preprocess\", \"layers\": [ { \"type\": \"source\", \"params\": { \"shape\": [ 1, 320, 320, 3 ] }, \"attrs\": { \"format\": \"rgb\", \"attrs\": { \"format\": \"rgb\", \"resize_mode\": \"bilinear\", \"keep_ar\": true, \"padding_clor\": [ 0, 0, 0 ] } } }, { \"type\": \"permute\", \"params\": { \"axis\": 3, \"dims\": [ 2, 1, 0 ] } }, { \"type\": \"madd\", \"weights\": { \"scale\": [ 0.0135694, 0.0143123, 0.0141064 ], \"bias\": [ -1.41176, -1.63139, -1.69065 ] } }, { \"type\": \"sink\" } ] } ] Postprocess specification \u00b6 The postprocess network can be used for labeling outputs, specifying the decoding type for tasks such as Object detection, and so on. Descriptions of each element in postprocess is below. layers \u00b6 Each layer consists of four elements, type, params, weights, and attrs. Properties Required Description Type Example type Mandatory String specifying the layer type. source, sink, decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 can be specified. String \"decode_ssd\" params Optional JSON object specifying layer parameters. Object example weights Optional JSON object specifying leyer weights. Object example attrs Optional JSON object specifying layer attributes. Object example Source Layer \u00b6 Input layer of the network. params Properties Required Description Type Example shape Mandatory Array of integers specifying the shape of the input data. Array of Integer [224, 224, 3] weights: None attrs: None Sink Layer \u00b6 Output layer of the network. params: None weights: None attrs Properties Required Description Type Example label_list Optional Array of strings representing output labels. Array of String [\"cat\", \"dog\", \"bird\"] Decode Layer \u00b6 Executes decode operation for Object Detection task. decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 can be specified for type. params Properties Required Description Type Example keep_top_k centernet, pelee, ssd, yolov3, yolov4 Integer specifying the number of bounding boxes. Bounding box is selected in descending order of score. Default is 300. Integer 300 do_nms centernet, pelee, ssd, yolov3, yolov4 Boolean specifying whether or not to execute NMS (Non-Maximum Suppression). Default is true. Boolean true nms_thresh centernet, pelee, ssd, yolov3, yolov4 IoU threshold for NMS. Float 0.5 conf_thresh centernet, pelee, ssd, yolov3, yolov4 Confidence threshold for detecting bounding boxes. Float 0.3 background_label_id pelee, ssd Label number of background. Default is 0. Integer 0 img_width yolov3 Width of input image. Integer 416 img_height yolov3 Height of input image. Integer 416 num_anchors_per_out yolov3 Number of anchor boxes for each grid cell. Integer 3 anchors yolov3 Array of numbers representing the size of anchor boxes. [w1, h1, w2, w3, ...] Float array [10,13, 16,30] weights: None attrs: None postprocess example \u00b6 [ { \"name\": \"postprocess\", \"layers\": [ { \"name\": \"input\", \"type\": \"source\", \"params\": { \"shape\":[1, 300, 15] } }, { \"name\": \"decode\", \"type\": \"decode_ssd\", \"params\": { \"keep_top_k\" : 300, \"background_label_id\" : 0, \"nms_thresh\" : 0.45, \"conf_thresh\" : 0.01 } }, { \"name\": \"output\", \"type\": \"sink\" } ] } ] import-onnx \u00b6 Convert an ONNX model to DNN. Usage softneuro import-onnx [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--help] INPUT OUTPUT Arguments Argument Description INPUT ONNX model file to be converted. OUTPUT Resulting DNN file path. If the extract flag is used, this is the folder where the model JSON will be saved. --preprocess_json PREPROCESS_JSON A json file specified when preprocess is added to DNN model. --postprocess_json POSTPROCESS_JSON A json file specified when postprocess is added to DNN model. Flags Flag Description --naive Save the DNN file without FuseRelu-type optimization. --extract Save the model information as a JSON file. --help \u3000 Shows the command help. Example After the model is converted the mobilenet_v2.dnn file will be created. $ softneuro import-onnx mobilenet_v2.onnx mobilenet_v2.dnn import model converting initializers: done converting nodes: done rectify model optimize model save model import-tensorflow \u00b6 Convert a TensorFlow model to DNN. Usage softneuro import-tensorflow [-h] [--keras] [--list-keras] [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--output_attrs OUTPUT_ATTRS] [--input_node [INPUT_NODE_NAME]] [--input_shape [INPUT_SHAPE]] [--output_node [OUTPUT_NODE_NAME]] [--fix_shape_inf] INPUT OUTPUT Arguments Argument Description INPUT Protocol buffer(.pb) or hdf5 format model file. For hdf5, not only weights but also the model structure is needed. OUTPUT Resulting DNN file path. If the extract flag is used, this is the folder where the model JSON will be saved. Flags Flag Description --keras It's possible to convert a model from tf.keras.applications pretrained models by inputting the model name. --list-keras Show the list of avalilable model names for --keras option. --naive Save the DNN file without FuseRelu-type optimization. --extract Save the model information as a JSON file. --preprocess_json PREPROCESS_JSON A json file containing a preprocess network definition to be added to the DNN model. --postprocess_json POSTPROCESS_JSON A json file containing a postprocess network definition to be added to the DNN model. --output_attrs OUTPUT_ATTRS A JSON containing the output attributes (output labels), or a preset name. --input_node [INPUT_NODE] Model input node name. --input_shape [SHAPE] Model input shape. --output_node [OUTPUT_NODE] Model output node name. --fix_shape_inf turn off shape inference -h, --help \u3000 Shows the command help. Example After the model is converted the vgg16.dnn file will be created. softneuro import-tensorflow vgg16.pb vgg16.dnn import-ver3 \u00b6 Convert a SoftNeuro V3 DNN model file to a SoftNeuro V5 DNN model file. Usage softneuro import-ver3 [--naive] [--extract] [--help] INPUT OUTPUT Arguments Argument Description INPUT V3 DNN file. OUTPUT Resulting DNN file path. If the extract flag is used, this is the folder where the model JSON will be saved. Flags Flag Description --naive Save the DNN file without FuseRelu-type optimization. --extract Save the model information as a JSON file. --help \u3000 Shows the command help. Example After the model is converted the vgg16_v5 file will be created. softneuro import-ver3 vgg16_v3.dnn vgg16_v5.dnn import model rectify model optimize model save model","title":"Model Conversion"},{"location":"commands/dnn/converter.html#model-conversion","text":"Commands for converting model files from various frameworks into the SoftNeuro DNN file format.","title":"Model Conversion"},{"location":"commands/dnn/converter.html#about-preprocess-postprocess","text":"In SoftNeuro preprocess and postprocess are separate networks attached to the beginning and to the end of the main network, respectively. These networks can be attached as a json file when converting a model. There's a preset json file, but it can be changed for custom settings. Currently, adding preprocess and postprocess networks is only available for import-onnx and import-tensorflow , and not available for import-ver3 .","title":"About preprocess, postprocess"},{"location":"commands/dnn/converter.html#preprocess-specification","text":"The preprocess network can be used for resizing images, specifying resize mode, specifying color format, normalizing data, and so on. Descriptions of each element in preprocess is below.","title":"Preprocess specification"},{"location":"commands/dnn/converter.html#layers","text":"Each layer consists of four elements: type, params, weights, and attrs. Properties Required Description Type Example type Mandatory String specifying the layer type. source, sink, madd, permute, can be specified. String \"madd\" params Optional JSON object specifying layer parameters. Object example weights Optional JSON object specifying leyer weights. Object example attrs Optional JSON object specifying layer attributes. Object example","title":"layers"},{"location":"commands/dnn/converter.html#source-layer","text":"Input layer of the network. params Properties Required Description Type Example shape Mandatory Array of integer specifying the shape of the input data. Array of Integer [224, 224, 3] weights: None attrs Properties Required Description Type Example format Optional String specifying the color format of the input image. Only \"rgb\" can be specified. String \"rgb\" resize_mode Optional String specifying the resize mode. \"bilinear\" (default) or \"nearest\" can be specified. String \"bilinear\" keep_ar Optional Boolean specifying whether or not to keep aspect ratio when resizing. Default is false. Boolean true padding_color Optional Array of numbers specifying the padding color filling the margin space when resizing. Array of Numbers [255, 255, 255]","title":"Source Layer"},{"location":"commands/dnn/converter.html#sink-layer","text":"Output layer of the network. params: None weights: None attrs: None","title":"Sink Layer"},{"location":"commands/dnn/converter.html#permute-layer","text":"Permutes the data order in the specified axis. Commonly used for channel-swapping. params Properties Required Description Type Example axis Mandatory Integer specifying the axis to be permuted. Integer 2 order Mandatory Array of integers containing the original positions ordered by their new indexes. Array of Integer [2, 1, 0] weights: None attrs: None","title":"Permute Layer"},{"location":"commands/dnn/converter.html#madd-layer","text":"Multiply add (scale * x + bias) layer. Commonly used for normalization of input data, subtraction of mean, and so on. params Properties Required Description Type Example has_relu Optional Boolean specifying whether or not to execute Relu activation. Default is False. Boolean False relu_max_value Optional Max output value after Relu activation. Only valid when has_relu is True. Number 6.0 weights Properties Required Description Type Example scale Mandatory Number or array of numbers by which the input data is multiplied. Must be array if different value is specified for each channel. Must have the same number of elements as bias. Number or Array of Number [0.01712475383, 0.0175070028, 0.01742919389] bias Mandatory Number or array of numbers, to be added to the input data. Must be array if different value is specified for each channel. Must have the same number of elements as scale. Number or Array of Number [2.11790393013, 2.03571428571, 1.80444444444] attrs: None","title":"Madd Layer"},{"location":"commands/dnn/converter.html#preprocess-example","text":"[ { \"name\": \"preprocess\", \"layers\": [ { \"type\": \"source\", \"params\": { \"shape\": [ 1, 320, 320, 3 ] }, \"attrs\": { \"format\": \"rgb\", \"attrs\": { \"format\": \"rgb\", \"resize_mode\": \"bilinear\", \"keep_ar\": true, \"padding_clor\": [ 0, 0, 0 ] } } }, { \"type\": \"permute\", \"params\": { \"axis\": 3, \"dims\": [ 2, 1, 0 ] } }, { \"type\": \"madd\", \"weights\": { \"scale\": [ 0.0135694, 0.0143123, 0.0141064 ], \"bias\": [ -1.41176, -1.63139, -1.69065 ] } }, { \"type\": \"sink\" } ] } ]","title":"preprocess example"},{"location":"commands/dnn/converter.html#postprocess-specification","text":"The postprocess network can be used for labeling outputs, specifying the decoding type for tasks such as Object detection, and so on. Descriptions of each element in postprocess is below.","title":"Postprocess specification"},{"location":"commands/dnn/converter.html#layers_1","text":"Each layer consists of four elements, type, params, weights, and attrs. Properties Required Description Type Example type Mandatory String specifying the layer type. source, sink, decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 can be specified. String \"decode_ssd\" params Optional JSON object specifying layer parameters. Object example weights Optional JSON object specifying leyer weights. Object example attrs Optional JSON object specifying layer attributes. Object example","title":"layers"},{"location":"commands/dnn/converter.html#source-layer_1","text":"Input layer of the network. params Properties Required Description Type Example shape Mandatory Array of integers specifying the shape of the input data. Array of Integer [224, 224, 3] weights: None attrs: None","title":"Source Layer"},{"location":"commands/dnn/converter.html#sink-layer_1","text":"Output layer of the network. params: None weights: None attrs Properties Required Description Type Example label_list Optional Array of strings representing output labels. Array of String [\"cat\", \"dog\", \"bird\"]","title":"Sink Layer"},{"location":"commands/dnn/converter.html#decode-layer","text":"Executes decode operation for Object Detection task. decode_centernet, decode_pelee, decode_ssd, decode_yolov3, decode_yolov4 can be specified for type. params Properties Required Description Type Example keep_top_k centernet, pelee, ssd, yolov3, yolov4 Integer specifying the number of bounding boxes. Bounding box is selected in descending order of score. Default is 300. Integer 300 do_nms centernet, pelee, ssd, yolov3, yolov4 Boolean specifying whether or not to execute NMS (Non-Maximum Suppression). Default is true. Boolean true nms_thresh centernet, pelee, ssd, yolov3, yolov4 IoU threshold for NMS. Float 0.5 conf_thresh centernet, pelee, ssd, yolov3, yolov4 Confidence threshold for detecting bounding boxes. Float 0.3 background_label_id pelee, ssd Label number of background. Default is 0. Integer 0 img_width yolov3 Width of input image. Integer 416 img_height yolov3 Height of input image. Integer 416 num_anchors_per_out yolov3 Number of anchor boxes for each grid cell. Integer 3 anchors yolov3 Array of numbers representing the size of anchor boxes. [w1, h1, w2, w3, ...] Float array [10,13, 16,30] weights: None attrs: None","title":"Decode Layer"},{"location":"commands/dnn/converter.html#postprocess-example","text":"[ { \"name\": \"postprocess\", \"layers\": [ { \"name\": \"input\", \"type\": \"source\", \"params\": { \"shape\":[1, 300, 15] } }, { \"name\": \"decode\", \"type\": \"decode_ssd\", \"params\": { \"keep_top_k\" : 300, \"background_label_id\" : 0, \"nms_thresh\" : 0.45, \"conf_thresh\" : 0.01 } }, { \"name\": \"output\", \"type\": \"sink\" } ] } ]","title":"postprocess example"},{"location":"commands/dnn/converter.html#import-onnx","text":"Convert an ONNX model to DNN. Usage softneuro import-onnx [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--help] INPUT OUTPUT Arguments Argument Description INPUT ONNX model file to be converted. OUTPUT Resulting DNN file path. If the extract flag is used, this is the folder where the model JSON will be saved. --preprocess_json PREPROCESS_JSON A json file specified when preprocess is added to DNN model. --postprocess_json POSTPROCESS_JSON A json file specified when postprocess is added to DNN model. Flags Flag Description --naive Save the DNN file without FuseRelu-type optimization. --extract Save the model information as a JSON file. --help \u3000 Shows the command help. Example After the model is converted the mobilenet_v2.dnn file will be created. $ softneuro import-onnx mobilenet_v2.onnx mobilenet_v2.dnn import model converting initializers: done converting nodes: done rectify model optimize model save model","title":"import-onnx"},{"location":"commands/dnn/converter.html#import-tensorflow","text":"Convert a TensorFlow model to DNN. Usage softneuro import-tensorflow [-h] [--keras] [--list-keras] [--naive] [--extract] [--preprocess_json PREPROCESS_JSON] [--postprocess_json POSTPROCESS_JSON] [--output_attrs OUTPUT_ATTRS] [--input_node [INPUT_NODE_NAME]] [--input_shape [INPUT_SHAPE]] [--output_node [OUTPUT_NODE_NAME]] [--fix_shape_inf] INPUT OUTPUT Arguments Argument Description INPUT Protocol buffer(.pb) or hdf5 format model file. For hdf5, not only weights but also the model structure is needed. OUTPUT Resulting DNN file path. If the extract flag is used, this is the folder where the model JSON will be saved. Flags Flag Description --keras It's possible to convert a model from tf.keras.applications pretrained models by inputting the model name. --list-keras Show the list of avalilable model names for --keras option. --naive Save the DNN file without FuseRelu-type optimization. --extract Save the model information as a JSON file. --preprocess_json PREPROCESS_JSON A json file containing a preprocess network definition to be added to the DNN model. --postprocess_json POSTPROCESS_JSON A json file containing a postprocess network definition to be added to the DNN model. --output_attrs OUTPUT_ATTRS A JSON containing the output attributes (output labels), or a preset name. --input_node [INPUT_NODE] Model input node name. --input_shape [SHAPE] Model input shape. --output_node [OUTPUT_NODE] Model output node name. --fix_shape_inf turn off shape inference -h, --help \u3000 Shows the command help. Example After the model is converted the vgg16.dnn file will be created. softneuro import-tensorflow vgg16.pb vgg16.dnn","title":"import-tensorflow"},{"location":"commands/dnn/converter.html#import-ver3","text":"Convert a SoftNeuro V3 DNN model file to a SoftNeuro V5 DNN model file. Usage softneuro import-ver3 [--naive] [--extract] [--help] INPUT OUTPUT Arguments Argument Description INPUT V3 DNN file. OUTPUT Resulting DNN file path. If the extract flag is used, this is the folder where the model JSON will be saved. Flags Flag Description --naive Save the DNN file without FuseRelu-type optimization. --extract Save the model information as a JSON file. --help \u3000 Shows the command help. Example After the model is converted the vgg16_v5 file will be created. softneuro import-ver3 vgg16_v3.dnn vgg16_v5.dnn import model rectify model optimize model save model","title":"import-ver3"},{"location":"commands/dnn/editor.ja.html","text":"DNN\u30d5\u30a1\u30a4\u30eb\u7de8\u96c6\u7cfb \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u306b\u5404\u7a2e\u5909\u66f4\u3092\u52a0\u3048\u308b\u969b\u306b\u4f7f\u7528\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 extract \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3001\u91cd\u307f\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro extract [--help] DNN OUTDIR \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u62bd\u51fa\u5bfe\u8c61\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTDIR extract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u6307\u5b9a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(vgg16_extract)\u5185\u306b model.json \u3001 weights.json \u3001numpy\u5f62\u5f0f\u3067\u30a6\u30a7\u30a4\u30c8\u3092\u66f8\u304d\u51fa\u3057\u305f weights \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203bextract\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro extract vgg16.dnn vgg16_extract $ ls vgg16_extract model.json weights weights.json archive \u00b6 extract \u30b3\u30de\u30f3\u30c9\u3067\u62bd\u51fa\u3055\u308c\u305f\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u518d\u5ea6DNN\u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro archive [--help] SRCDIR DNN \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 SRCDIR extract \u30b3\u30de\u30f3\u30c9\u3067\u51fa\u529b\u3057\u305f\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u4fdd\u5b58\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002 DNN \u30d5\u30a1\u30a4\u30eb\u5909\u63db\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_archive.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203barchive\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro archive vgg16_extract vgg16_archive.dnn $ ls vgg16_extract vgg16_archive.dnn refine \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u306b\u9ad8\u901f\u5316\u306b\u6709\u52b9\u306a\u6700\u9069\u5316\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u6700\u9069\u5316\u306e\u51e6\u7406\u5185\u5bb9\u306f\u57fa\u672c\u7684\u306b\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3092dnn\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\u3068\u304d\u306b\u9069\u7528\u3055\u308c\u308b\u3082\u306e\u3067\u3059\u3002 \u5909\u63db\u6642\u306b\u9069\u7528\u3057\u306a\u3044\u3088\u3046\u30aa\u30d7\u30b7\u30e7\u30f3\u6307\u5b9a\u3057\u3066\u3044\u305f\u5834\u5408\u3001 refine \u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3046\u3053\u3068\u3067\u5f8c\u304b\u3089\u6700\u9069\u5316\u51e6\u7406\u3092\u65bd\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro refine [--batch-norm-to-madd] [--fuse-dropout] [--fuse-transpose] [--fuse-madd] [--fuse-relu] [--fuse-padding] [--swap-act-pool] [--strip-constant] [--strip-immutable] [--strip-layer] [--strip-net] [--norm-weight] [--dedup-weight] [--strip-weight][--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u5165\u529bDNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u51fa\u529bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u672c\u30b3\u30de\u30f3\u30c9\u3067\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u5229\u7528\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u6700\u9069\u5316\u51e6\u7406\u306e\u307f\u3092\u884c\u3046\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002(help\u3092\u9664\u304f) \u4f8b\u3048\u3070 --batch_norm_to_madd \u306e\u307f\u3092\u6709\u52b9\u306b\u3059\u308b\u3068\u305d\u308c\u4ee5\u5916\u306e\u6700\u9069\u5316\u51e6\u7406\u306f\u884c\u308f\u308c\u307e\u305b\u3093\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --batch-norm-to-madd batch normalization \u51e6\u7406\u3092 madd \u30ec\u30a4\u30e4\u30fc\u306b\u5909\u63db\u3057\u307e\u3059\u3002 --fuse-dropout dropout \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-transpose transpose \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-madd multiply-add \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-relu relu \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-padding zero padding \u51e6\u7406\u3092\u4e00\u3064\u5f8c\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --swap-act-pool activation-pooling \u51e6\u7406\u3092 pooling activation \u51e6\u7406\u306b\u5909\u63db\u3057\u307e\u3059\u3002 --strip-constant \u30b3\u30f3\u30b9\u30bf\u30f3\u30c8\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-immutable \u4e0d\u5909\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-layer \u4e0d\u8981\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-net \u30ec\u30a4\u30e4\u30fc\u3092\u6301\u305f\u306a\u3044\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-weight \u3069\u306e\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u3082\u53c2\u7167\u3055\u308c\u3066\u3044\u306a\u3044\u91cd\u307f\u60c5\u5831\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --dedup-weight\u3000\u3000\u3000\u3000\u3000 \u91cd\u8907\u306a\u91cd\u307f\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --norm-weight \u91cd\u307f\u306b\u542b\u307e\u308c\u308b subnormal , nan , inf \u5024\u3092\u6b63\u898f\u5316\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b Pose_small.dnn\u306e\u91cd\u8907\u306a\u91cd\u307f\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 $ softneuro refine --dedup-weight Pose_small.dnn Pose_small_refined.dnn ------------------------------------------------------------------ Deduplicate Weights ------------------------------------------------------------------ 'weight_7_0' is deduplicated to 'weight_4_0' (SNR: inf). 'weight_10_0' is deduplicated to 'weight_3_0' (SNR: inf). 'weight_13_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_14_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_15_0' is deduplicated to 'weight_2_0' (SNR: inf). 5 weights are deduplicated. compress \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u306e\u91cd\u307f\u30c7\u30fc\u30bf\u306e\u8efd\u91cf\u5316\u3092\u884c\u3046\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro compress [--dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES]]... [--pass PASSWORD] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u30c7\u30fc\u30bf\u578b\u5909\u63db\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u30c7\u30fc\u30bf\u578b\u5909\u63db\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES] \u4fdd\u5b58\u3059\u308b\u91cd\u307f\u306e\u30c7\u30fc\u30bf\u578b\u3092\u6307\u5b9a\u3059\u308b\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u3059\u3002DTYPE\u306b\u306ffloat16, qint8\u304c\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u91cd\u307f\u306f\u3059\u3079\u3066qint8\u3068\u3057\u3066\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002LTYPE\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u30bf\u30a4\u30d7\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u91cd\u307f\u306e\u307fDTYPE\u3067\u6307\u5b9a\u3057\u305f\u578b\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002WNAME\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u30a6\u30a7\u30a4\u30c8\u540d\u306e\u91cd\u307f\u306e\u307fDTYPE\u3067\u6307\u5b9a\u3057\u305f\u578b\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002LAYER_INDICES\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u91cd\u307f\u306e\u307fDTYPE\u3067\u6307\u5b9a\u3057\u305f\u578b\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002 LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --pass PASSWORD \u6697\u53f7\u5316\u306e\u969b\u306b\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u91cd\u307f\u60c5\u5831\u304cqint8\u5f62\u5f0f\u3067\u4fdd\u5b58\u3055\u308c\u305fvgg16_qint8.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203bcompress\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro compress vgg16.dnn vgg16_qint8.dnn $ ls -lh -rw-rw-r-- 1 user user 528M 1\u6708 1 10:00 vgg16.dnn -rw-rw-r-- 1 user user 133M 1\u6708 1 10:00 vgg16_qint8.dnn cipher \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u3092\u6697\u53f7\u5316\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro cipher [--pass PASSWORD] [--new-pass PASSWORD] [--secret] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u6697\u53f7\u5316\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u6697\u53f7\u5316\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -p PASSWORD, --pass PASSWORD INPUT\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 --new-pass PASSWORD OUTPUT\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001INPUT\u3068\u540c\u3058\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u7a7a(\"\")\u3092\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001 \u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000INPUT\u306e\u5fa9\u53f7\u5316\u3092\u884c\u3044\u3001OUTPUT\u306f\u6697\u53f7\u5316\u3055\u308c\u306a\u3044\u72b6\u614b\u3068\u306a\u308a\u307e\u3059\u3002 --secret secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306f\u30e2\u30c7\u30eb\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u304f\u306a\u308a\u307e\u3059\u3002\u307e\u305f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3059\u308b\u5404\u7a2e\u64cd\u4f5c\u3082\u57fa\u672c\u7684\u306b\u306f\u4e0d\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_enc.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203bcipher\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro cipher --new-pass 4u9pnza vgg16.dnn vgg16_enc.dnn $ ls vgg16.dnn vgg16_enc.dnn $ softneuro run vgg16_enc.dnn mor_dnn.c:921:Error: Invalid password for dnn. softneuro:Error: Load error. $ softneuro run vgg16_enc.dnn -p 4u9pnza --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 36,055 36,055 36,055 1 Dnn_compile() 727,957 727,957 727,957 1 Dnn_forward() 1,080,363 1,080,363 1,080,363 1 Used memory: 1,140,400,128 Bytes calibrate \u00b6 \u9759\u7684\u91cf\u5b50\u5316\u306e\u305f\u3081\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3068\u306f\u3001\u4e88\u3081\u7528\u610f\u3057\u305f\u5165\u529b\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u3066\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u51fa\u529b\u6700\u5927\u5024\u3068\u6700\u5c0f\u5024\u3092\u6c42\u3081\u3001\u91cf\u5b50\u5316\u306e\u30ec\u30f3\u30b8\u3092\u56fa\u5b9a\u3059\u308b\u64cd\u4f5c\u3067\u3059\u3002 \u3053\u306e\u64cd\u4f5c\u306b\u3088\u3063\u3066\u4e00\u90e8\u306e\u91cf\u5b50\u5316\u30eb\u30fc\u30c1\u30f3\u3067\u52d5\u7684\u306a\u91cf\u5b50\u5316\u30ec\u30f3\u30b8\u8a08\u7b97\u304c\u4e0d\u8981\u306b\u306a\u308a\u3001\u9ad8\u901f\u5316\u304c\u898b\u8fbc\u3081\u307e\u3059\u3002 tune\u306a\u3069\u306b\u3088\u3063\u3066\u91cf\u5b50\u5316\u30eb\u30fc\u30c1\u30f3\u3092\u5229\u7528\u3059\u308b\u8a2d\u5b9a\u3067\u3042\u308b\u5834\u5408\u306b\u306e\u307f\u52b9\u679c\u304c\u898b\u8fbc\u3081\u308b\u3053\u3068\u306b\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002 \u307e\u305f\u3001\u63a8\u8ad6\u6642\u306e\u5b9f\u30c7\u30fc\u30bf\u3068\u5927\u304d\u304f\u7570\u306a\u308b\u30c7\u30fc\u30bf\u3067\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046\u3068\u7cbe\u5ea6\u304c\u4f4e\u4e0b\u3059\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro calibrate [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE][--pass PASSWORD] [--reset] [--trunc RATIO] [--help] IDNN ODNN [INPUT]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 IDNN \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 ODNN \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 INPUT \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u5165\u529b\u30d5\u30a1\u30a4\u30eb\u3002\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u3001\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u3001\u307e\u305f\u306f\u305d\u308c\u3089\u304c\u5165\u3063\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u6307\u5b9a\u53ef\u80fd\u3002\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3059\u308b\u5834\u5408\u306f\u8907\u6570\u6307\u5b9a\u53ef\u80fd\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --keep_img_ar PADDINGCOLOR \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306b\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3055\u305b\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3057\u307e\u305b\u3093\u3002\u30ea\u30b5\u30a4\u30ba\u524d\u5f8c\u3067\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u306e\u9055\u3044\u306b\u3088\u3063\u3066\u751f\u3058\u308b\u30b9\u30da\u30fc\u30b9\u3092\u3001PADDINGCOLOR\u3067\u6307\u5b9a\u3057\u305f\u8272\u3067\u57cb\u3081\u307e\u3059\u3002PADDINGCOLOR\u306f\u4f8b\u3048\u3070 '0, 0, 0' \u306e\u3088\u3046\u306bRGB\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002 --img_resize_mode RESIZEMODE \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306e\u65b9\u5f0f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 'bilinear' \u307e\u305f\u306f\u3000'nearest' \u3092\u6307\u5b9a\u53ef\u80fd\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f 'bilinear' \u3067\u3059\u3002 -p, --pass PASSWORD \u6697\u53f7\u5316\u306e\u969b\u306b\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 --reset \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u60c5\u5831\uff08\u6700\u5927\u5024\u30fb\u6700\u5c0f\u5024\uff09\u3092\u30ea\u30bb\u30c3\u30c8\u3057\u307e\u3059\u3002 --trunc RATIO \u6700\u5927\u5024\u30fb\u6700\u5c0f\u5024\u3092\u6c42\u3081\u308b\u969b\u306b\u3001RATIO\u3067\u6307\u5b9a\u3057\u305f\u6bd4\u7387\u5206\u306e\u4e0a\u4f4d\u30c7\u30fc\u30bf\u3068\u4e0b\u4f4d\u30c7\u30fc\u30bf\u3092\u5916\u308c\u5024\u3068\u898b\u306a\u3057\u3066\u30ab\u30c3\u30c8\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070 RATIO=0.02 \u3068\u3057\u305f\u5834\u5408\u3001\u4e0a\u4e0b2%\u306e\u30c7\u30fc\u30bf\u304c\u30ab\u30c3\u30c8\u3055\u308c\u305f\u4e0a\u3067\u6700\u5927\u5024\u30fb\u6700\u5c0f\u5024\u304c\u5b9a\u3081\u3089\u308c\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f RATIO=0 \u3067\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_calib.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b tune \u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u8a2d\u5b9a\u3055\u308c\u305f\u30ec\u30a4\u30e4\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5229\u7528\u3057\u305f\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u304c\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002 \u203bcalibrate\u30b3\u30de\u30f3\u30c9\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro calibrate vgg16.dnn vgg16_calib.dnn input0.jpg input1.jpg input2.jpg $ softneuro tune vgg16_calib.dnn vgg16_calib_tuned.dnn decompose \u00b6 DNN\u30cd\u30c3\u30c8\u3092\u5206\u5272\u30fb\u5727\u7e2e\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 HNN\u306a\u3069\u306e\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306fDNN\u5185\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7279\u6b8a\u306a\u30ec\u30a4\u30e4\u30fc\u306b\u5727\u7e2e\u3057\u3066\u63a8\u8ad6\u51e6\u7406\u3092\u5b9f\u884c\u3055\u305b\u308b\u3053\u3068\u306b\u306a\u308b\u305f\u3081\u3001 \u5206\u5272\u30fb\u5727\u7e2e\u306b\u3088\u308bDNN\u306e\u7de8\u96c6\u306f\u4e3b\u306b\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro decompose [--pass PASSWORD] [--split SPLIT] [--compress COMPRESS] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u5206\u5272\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u5206\u5272\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -p PASSWORD, --pass PASSWORD INPUT\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 -s SPLIT, --split SPLIT \u30ec\u30a4\u30e4\u30fc\u3092\u6307\u5b9a\u3057\u3066\u3001\u305d\u3053\u304b\u3089\u30cd\u30c3\u30c8\u3092\u5206\u5272\u3059\u308b\u3002 -c COMPRESS, --compress COMPRESS \u5727\u7e2e\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b conv_pw_1\u30ec\u30a4\u30e4\u30fc\u304b\u3089ssd.dnn\u306e\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4e8c\u3064\u306e\u30b5\u30d6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u5206\u5272\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002 $ softneuro decompose -s conv_pw_1 ssd.dnn ssd_dcp.dnn [0] from input_1 to conv_pw_1 [1] from conv_dw_2 to sink_0 \u307e\u305f\u3001vgg16.dnn\u306e\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4e00\u3064\u306e\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\u51e6\u7406\u30ec\u30a4\u30e4\u306b\u5727\u7e2e\u3057\u3001\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\uff08\u3053\u306e\u5834\u5408Qualcomm\u306eHTA\uff09\u3067\u63a8\u8ad6\u3059\u308b\u3088\u3046tune\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002 $ softneuro decompose -c main vgg16.dnn vgg16_decomposed.dnn $ softneuro tune vgg16_decomposed.dnn vgg16_decomposed_tuned.dnn --routine cpu/faster/hta","title":"DNN\u30d5\u30a1\u30a4\u30eb\u7de8\u96c6\u7cfb"},{"location":"commands/dnn/editor.ja.html#dnn","text":"DNN\u30d5\u30a1\u30a4\u30eb\u306b\u5404\u7a2e\u5909\u66f4\u3092\u52a0\u3048\u308b\u969b\u306b\u4f7f\u7528\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002","title":"DNN\u30d5\u30a1\u30a4\u30eb\u7de8\u96c6\u7cfb"},{"location":"commands/dnn/editor.ja.html#extract","text":"DNN\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u30e2\u30c7\u30eb\u60c5\u5831\u3001\u91cd\u307f\u60c5\u5831\u3092\u62bd\u51fa\u3057\u3066JSON\u30d5\u30a1\u30a4\u30eb\u7b49\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro extract [--help] DNN OUTDIR \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u62bd\u51fa\u5bfe\u8c61\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTDIR extract\u3067\u751f\u6210\u3055\u308c\u308bJSON\u7b49\u306e\u4fdd\u5b58\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u6307\u5b9a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(vgg16_extract)\u5185\u306b model.json \u3001 weights.json \u3001numpy\u5f62\u5f0f\u3067\u30a6\u30a7\u30a4\u30c8\u3092\u66f8\u304d\u51fa\u3057\u305f weights \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203bextract\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro extract vgg16.dnn vgg16_extract $ ls vgg16_extract model.json weights weights.json","title":"extract"},{"location":"commands/dnn/editor.ja.html#archive","text":"extract \u30b3\u30de\u30f3\u30c9\u3067\u62bd\u51fa\u3055\u308c\u305f\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u518d\u5ea6DNN\u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro archive [--help] SRCDIR DNN \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 SRCDIR extract \u30b3\u30de\u30f3\u30c9\u3067\u51fa\u529b\u3057\u305f\u30e2\u30c7\u30eb\u60c5\u5831\u3092\u4fdd\u5b58\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002 DNN \u30d5\u30a1\u30a4\u30eb\u5909\u63db\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_archive.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203barchive\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro archive vgg16_extract vgg16_archive.dnn $ ls vgg16_extract vgg16_archive.dnn","title":"archive"},{"location":"commands/dnn/editor.ja.html#refine","text":"DNN\u30d5\u30a1\u30a4\u30eb\u306b\u9ad8\u901f\u5316\u306b\u6709\u52b9\u306a\u6700\u9069\u5316\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u6700\u9069\u5316\u306e\u51e6\u7406\u5185\u5bb9\u306f\u57fa\u672c\u7684\u306b\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u3092dnn\u5f62\u5f0f\u306b\u5909\u63db\u3059\u308b\u3068\u304d\u306b\u9069\u7528\u3055\u308c\u308b\u3082\u306e\u3067\u3059\u3002 \u5909\u63db\u6642\u306b\u9069\u7528\u3057\u306a\u3044\u3088\u3046\u30aa\u30d7\u30b7\u30e7\u30f3\u6307\u5b9a\u3057\u3066\u3044\u305f\u5834\u5408\u3001 refine \u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3046\u3053\u3068\u3067\u5f8c\u304b\u3089\u6700\u9069\u5316\u51e6\u7406\u3092\u65bd\u3059\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro refine [--batch-norm-to-madd] [--fuse-dropout] [--fuse-transpose] [--fuse-madd] [--fuse-relu] [--fuse-padding] [--swap-act-pool] [--strip-constant] [--strip-immutable] [--strip-layer] [--strip-net] [--norm-weight] [--dedup-weight] [--strip-weight][--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u5165\u529bDNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u51fa\u529bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u672c\u30b3\u30de\u30f3\u30c9\u3067\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u5229\u7528\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u6700\u9069\u5316\u51e6\u7406\u306e\u307f\u3092\u884c\u3046\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002(help\u3092\u9664\u304f) \u4f8b\u3048\u3070 --batch_norm_to_madd \u306e\u307f\u3092\u6709\u52b9\u306b\u3059\u308b\u3068\u305d\u308c\u4ee5\u5916\u306e\u6700\u9069\u5316\u51e6\u7406\u306f\u884c\u308f\u308c\u307e\u305b\u3093\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --batch-norm-to-madd batch normalization \u51e6\u7406\u3092 madd \u30ec\u30a4\u30e4\u30fc\u306b\u5909\u63db\u3057\u307e\u3059\u3002 --fuse-dropout dropout \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-transpose transpose \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-madd multiply-add \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-relu relu \u51e6\u7406\u3092\u4e00\u3064\u524d\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --fuse-padding zero padding \u51e6\u7406\u3092\u4e00\u3064\u5f8c\u306e\u30ec\u30a4\u30e4\u30fc\u51e6\u7406\u306b\u7d44\u307f\u8fbc\u307f\u307e\u3059\u3002 --swap-act-pool activation-pooling \u51e6\u7406\u3092 pooling activation \u51e6\u7406\u306b\u5909\u63db\u3057\u307e\u3059\u3002 --strip-constant \u30b3\u30f3\u30b9\u30bf\u30f3\u30c8\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-immutable \u4e0d\u5909\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-layer \u4e0d\u8981\u306a\u30ec\u30a4\u30e4\u30fc\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-net \u30ec\u30a4\u30e4\u30fc\u3092\u6301\u305f\u306a\u3044\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --strip-weight \u3069\u306e\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u3082\u53c2\u7167\u3055\u308c\u3066\u3044\u306a\u3044\u91cd\u307f\u60c5\u5831\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --dedup-weight\u3000\u3000\u3000\u3000\u3000 \u91cd\u8907\u306a\u91cd\u307f\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 --norm-weight \u91cd\u307f\u306b\u542b\u307e\u308c\u308b subnormal , nan , inf \u5024\u3092\u6b63\u898f\u5316\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b Pose_small.dnn\u306e\u91cd\u8907\u306a\u91cd\u307f\u3092\u9664\u53bb\u3057\u307e\u3059\u3002 $ softneuro refine --dedup-weight Pose_small.dnn Pose_small_refined.dnn ------------------------------------------------------------------ Deduplicate Weights ------------------------------------------------------------------ 'weight_7_0' is deduplicated to 'weight_4_0' (SNR: inf). 'weight_10_0' is deduplicated to 'weight_3_0' (SNR: inf). 'weight_13_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_14_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_15_0' is deduplicated to 'weight_2_0' (SNR: inf). 5 weights are deduplicated.","title":"refine"},{"location":"commands/dnn/editor.ja.html#compress","text":"DNN\u30d5\u30a1\u30a4\u30eb\u306e\u91cd\u307f\u30c7\u30fc\u30bf\u306e\u8efd\u91cf\u5316\u3092\u884c\u3046\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro compress [--dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES]]... [--pass PASSWORD] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u30c7\u30fc\u30bf\u578b\u5909\u63db\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u30c7\u30fc\u30bf\u578b\u5909\u63db\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES] \u4fdd\u5b58\u3059\u308b\u91cd\u307f\u306e\u30c7\u30fc\u30bf\u578b\u3092\u6307\u5b9a\u3059\u308b\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u3059\u3002DTYPE\u306b\u306ffloat16, qint8\u304c\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002\u3053\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u91cd\u307f\u306f\u3059\u3079\u3066qint8\u3068\u3057\u3066\u4fdd\u5b58\u3055\u308c\u307e\u3059\u3002LTYPE\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u30bf\u30a4\u30d7\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u91cd\u307f\u306e\u307fDTYPE\u3067\u6307\u5b9a\u3057\u305f\u578b\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002WNAME\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u30a6\u30a7\u30a4\u30c8\u540d\u306e\u91cd\u307f\u306e\u307fDTYPE\u3067\u6307\u5b9a\u3057\u305f\u578b\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002LAYER_INDICES\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u6307\u5b9a\u3057\u305f\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u306e\u30ec\u30a4\u30e4\u30fc\u306e\u91cd\u307f\u306e\u307fDTYPE\u3067\u6307\u5b9a\u3057\u305f\u578b\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002 LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --pass PASSWORD \u6697\u53f7\u5316\u306e\u969b\u306b\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u91cd\u307f\u60c5\u5831\u304cqint8\u5f62\u5f0f\u3067\u4fdd\u5b58\u3055\u308c\u305fvgg16_qint8.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203bcompress\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro compress vgg16.dnn vgg16_qint8.dnn $ ls -lh -rw-rw-r-- 1 user user 528M 1\u6708 1 10:00 vgg16.dnn -rw-rw-r-- 1 user user 133M 1\u6708 1 10:00 vgg16_qint8.dnn","title":"compress"},{"location":"commands/dnn/editor.ja.html#cipher","text":"DNN\u30d5\u30a1\u30a4\u30eb\u3092\u6697\u53f7\u5316\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro cipher [--pass PASSWORD] [--new-pass PASSWORD] [--secret] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u6697\u53f7\u5316\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u6697\u53f7\u5316\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -p PASSWORD, --pass PASSWORD INPUT\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 --new-pass PASSWORD OUTPUT\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001INPUT\u3068\u540c\u3058\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u7a7a(\"\")\u3092\u4e0e\u3048\u3089\u308c\u305f\u5834\u5408\u3001 \u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000\u3000INPUT\u306e\u5fa9\u53f7\u5316\u3092\u884c\u3044\u3001OUTPUT\u306f\u6697\u53f7\u5316\u3055\u308c\u306a\u3044\u72b6\u614b\u3068\u306a\u308a\u307e\u3059\u3002 --secret secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306f\u30e2\u30c7\u30eb\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u69cb\u9020\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u304f\u306a\u308a\u307e\u3059\u3002\u307e\u305f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3059\u308b\u5404\u7a2e\u64cd\u4f5c\u3082\u57fa\u672c\u7684\u306b\u306f\u4e0d\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_enc.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203bcipher\u30b3\u30de\u30f3\u30c9\u306e\u5b9f\u884c\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro cipher --new-pass 4u9pnza vgg16.dnn vgg16_enc.dnn $ ls vgg16.dnn vgg16_enc.dnn $ softneuro run vgg16_enc.dnn mor_dnn.c:921:Error: Invalid password for dnn. softneuro:Error: Load error. $ softneuro run vgg16_enc.dnn -p 4u9pnza --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 36,055 36,055 36,055 1 Dnn_compile() 727,957 727,957 727,957 1 Dnn_forward() 1,080,363 1,080,363 1,080,363 1 Used memory: 1,140,400,128 Bytes","title":"cipher"},{"location":"commands/dnn/editor.ja.html#calibrate","text":"\u9759\u7684\u91cf\u5b50\u5316\u306e\u305f\u3081\u306e\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3068\u306f\u3001\u4e88\u3081\u7528\u610f\u3057\u305f\u5165\u529b\u30d5\u30a1\u30a4\u30eb\u3092\u7528\u3044\u3066\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u51fa\u529b\u6700\u5927\u5024\u3068\u6700\u5c0f\u5024\u3092\u6c42\u3081\u3001\u91cf\u5b50\u5316\u306e\u30ec\u30f3\u30b8\u3092\u56fa\u5b9a\u3059\u308b\u64cd\u4f5c\u3067\u3059\u3002 \u3053\u306e\u64cd\u4f5c\u306b\u3088\u3063\u3066\u4e00\u90e8\u306e\u91cf\u5b50\u5316\u30eb\u30fc\u30c1\u30f3\u3067\u52d5\u7684\u306a\u91cf\u5b50\u5316\u30ec\u30f3\u30b8\u8a08\u7b97\u304c\u4e0d\u8981\u306b\u306a\u308a\u3001\u9ad8\u901f\u5316\u304c\u898b\u8fbc\u3081\u307e\u3059\u3002 tune\u306a\u3069\u306b\u3088\u3063\u3066\u91cf\u5b50\u5316\u30eb\u30fc\u30c1\u30f3\u3092\u5229\u7528\u3059\u308b\u8a2d\u5b9a\u3067\u3042\u308b\u5834\u5408\u306b\u306e\u307f\u52b9\u679c\u304c\u898b\u8fbc\u3081\u308b\u3053\u3068\u306b\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002 \u307e\u305f\u3001\u63a8\u8ad6\u6642\u306e\u5b9f\u30c7\u30fc\u30bf\u3068\u5927\u304d\u304f\u7570\u306a\u308b\u30c7\u30fc\u30bf\u3067\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046\u3068\u7cbe\u5ea6\u304c\u4f4e\u4e0b\u3059\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro calibrate [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE][--pass PASSWORD] [--reset] [--trunc RATIO] [--help] IDNN ODNN [INPUT]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 IDNN \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 ODNN \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 INPUT \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u5165\u529b\u30d5\u30a1\u30a4\u30eb\u3002\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u3001\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u3001\u307e\u305f\u306f\u305d\u308c\u3089\u304c\u5165\u3063\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u6307\u5b9a\u53ef\u80fd\u3002\u30d5\u30a1\u30a4\u30eb\u3092\u6307\u5b9a\u3059\u308b\u5834\u5408\u306f\u8907\u6570\u6307\u5b9a\u53ef\u80fd\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --keep_img_ar PADDINGCOLOR \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306b\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3055\u305b\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3057\u307e\u305b\u3093\u3002\u30ea\u30b5\u30a4\u30ba\u524d\u5f8c\u3067\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u306e\u9055\u3044\u306b\u3088\u3063\u3066\u751f\u3058\u308b\u30b9\u30da\u30fc\u30b9\u3092\u3001PADDINGCOLOR\u3067\u6307\u5b9a\u3057\u305f\u8272\u3067\u57cb\u3081\u307e\u3059\u3002PADDINGCOLOR\u306f\u4f8b\u3048\u3070 '0, 0, 0' \u306e\u3088\u3046\u306bRGB\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002 --img_resize_mode RESIZEMODE \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306e\u65b9\u5f0f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 'bilinear' \u307e\u305f\u306f\u3000'nearest' \u3092\u6307\u5b9a\u53ef\u80fd\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f 'bilinear' \u3067\u3059\u3002 -p, --pass PASSWORD \u6697\u53f7\u5316\u306e\u969b\u306b\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 --reset \u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u60c5\u5831\uff08\u6700\u5927\u5024\u30fb\u6700\u5c0f\u5024\uff09\u3092\u30ea\u30bb\u30c3\u30c8\u3057\u307e\u3059\u3002 --trunc RATIO \u6700\u5927\u5024\u30fb\u6700\u5c0f\u5024\u3092\u6c42\u3081\u308b\u969b\u306b\u3001RATIO\u3067\u6307\u5b9a\u3057\u305f\u6bd4\u7387\u5206\u306e\u4e0a\u4f4d\u30c7\u30fc\u30bf\u3068\u4e0b\u4f4d\u30c7\u30fc\u30bf\u3092\u5916\u308c\u5024\u3068\u898b\u306a\u3057\u3066\u30ab\u30c3\u30c8\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070 RATIO=0.02 \u3068\u3057\u305f\u5834\u5408\u3001\u4e0a\u4e0b2%\u306e\u30c7\u30fc\u30bf\u304c\u30ab\u30c3\u30c8\u3055\u308c\u305f\u4e0a\u3067\u6700\u5927\u5024\u30fb\u6700\u5c0f\u5024\u304c\u5b9a\u3081\u3089\u308c\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f RATIO=0 \u3067\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_calib.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b tune \u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u8a2d\u5b9a\u3055\u308c\u305f\u30ec\u30a4\u30e4\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u5229\u7528\u3057\u305f\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u304c\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002 \u203bcalibrate\u30b3\u30de\u30f3\u30c9\u306b\u3088\u308b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro calibrate vgg16.dnn vgg16_calib.dnn input0.jpg input1.jpg input2.jpg $ softneuro tune vgg16_calib.dnn vgg16_calib_tuned.dnn","title":"calibrate"},{"location":"commands/dnn/editor.ja.html#decompose","text":"DNN\u30cd\u30c3\u30c8\u3092\u5206\u5272\u30fb\u5727\u7e2e\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 HNN\u306a\u3069\u306e\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\u3092\u5229\u7528\u3059\u308b\u5834\u5408\u306fDNN\u5185\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7279\u6b8a\u306a\u30ec\u30a4\u30e4\u30fc\u306b\u5727\u7e2e\u3057\u3066\u63a8\u8ad6\u51e6\u7406\u3092\u5b9f\u884c\u3055\u305b\u308b\u3053\u3068\u306b\u306a\u308b\u305f\u3081\u3001 \u5206\u5272\u30fb\u5727\u7e2e\u306b\u3088\u308bDNN\u306e\u7de8\u96c6\u306f\u4e3b\u306b\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro decompose [--pass PASSWORD] [--split SPLIT] [--compress COMPRESS] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u5206\u5272\u3092\u884c\u3046DNN\u30d5\u30a1\u30a4\u30eb\u3002 OUTPUT \u5206\u5272\u306e\u7d50\u679c\u751f\u6210\u3055\u308c\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -p PASSWORD, --pass PASSWORD INPUT\u306e\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 -s SPLIT, --split SPLIT \u30ec\u30a4\u30e4\u30fc\u3092\u6307\u5b9a\u3057\u3066\u3001\u305d\u3053\u304b\u3089\u30cd\u30c3\u30c8\u3092\u5206\u5272\u3059\u308b\u3002 -c COMPRESS, --compress COMPRESS \u5727\u7e2e\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b conv_pw_1\u30ec\u30a4\u30e4\u30fc\u304b\u3089ssd.dnn\u306e\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4e8c\u3064\u306e\u30b5\u30d6\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u5206\u5272\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002 $ softneuro decompose -s conv_pw_1 ssd.dnn ssd_dcp.dnn [0] from input_1 to conv_pw_1 [1] from conv_dw_2 to sink_0 \u307e\u305f\u3001vgg16.dnn\u306e\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4e00\u3064\u306e\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\u51e6\u7406\u30ec\u30a4\u30e4\u306b\u5727\u7e2e\u3057\u3001\u5916\u90e8\u63a8\u8ad6\u30a8\u30f3\u30b8\u30f3\uff08\u3053\u306e\u5834\u5408Qualcomm\u306eHTA\uff09\u3067\u63a8\u8ad6\u3059\u308b\u3088\u3046tune\u3059\u308b\u5834\u5408\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002 $ softneuro decompose -c main vgg16.dnn vgg16_decomposed.dnn $ softneuro tune vgg16_decomposed.dnn vgg16_decomposed_tuned.dnn --routine cpu/faster/hta","title":"decompose"},{"location":"commands/dnn/editor.html","text":"Model Editing \u00b6 Commands for editing DNN file contents. extract \u00b6 Extract weights and model architecture information from a DNN file into JSON and numpy files. Usage usage: softneuro extract [--help] DNN OUTDIR Arguments Argument Description DNN DNN file to be extracted. OUTDIR Output directory where the data will be extracted to. Flags Flag Description -h, --help Shows the command help. Example Running this command will create, in the vgg16_extract folder, model.json , weights.json and a directory containing numpy format files with weights data in a weights directory. \u203bThere's no terminal output $ softneuro extract vgg16.dnn vgg16_extract $ ls vgg16_extract model.json weights weights.json archive \u00b6 Pack the files in the same format as what the extract command outputs into a DNN model file. Usage usage: softneuro archive [--help] SRCDIR DNN Arguments Argument Description SRCDIR Directory with contents in the same format as the extract command output. DNN DNN file to be outputed. Flags Flag Description -h, --help Shows the command help. Example This command will generate a vgg16_archive.dnn file. \u203bThere's no terminal output $ softneuro archive vgg16_extract vgg16_archive.dnn $ ls vgg16_extract vgg16_archive.dnn refine \u00b6 Refine a DNN file for faster inference times. Generally, the processing used for optimizations is the same as that for converting a model to DNN format. When optimization has not been applied during model conversion, it can be performed later using refine . Usage usage: softneuro refine [--batch-norm-to-madd] [--fuse-dropout] [--fuse-transpose] [--fuse-madd] [--fuse-relu] [--fuse-padding] [--swap-act-pool] [--strip-constant] [--strip-immutable] [--strip-layer] [--strip-net] [--norm-weight] [--dedup-weight] [--strip-weight][--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be refined. OUTPUT Refined DNN file output. Flags If a flag is set only that specific optimization will be done. For instance, if --batch-norm-to-madd is set, other optimizations like relu fuse won't be done. Flags Description --batch-norm-to-madd Transforms batch normalization into madd layers. --fuse-dropout Fuses dropout into the previous layer. --fuse-transpose Fuses transpose into the previous layer.\u3002 --fuse-madd Fuses multiply-add into the previous layer. --fuse-relu Fuses relu into the previous layer. --fuse-padding Fuses zero padding into the previous layer. --swap-act-pool Transforms activation-pooling into pooling activation . --strip-constant Removes layers which are constant\u3002 --strip-immutable Removes layers which are immutable\u3002 --strip-layer Removes unnecessary layers. --strip-net Removes sub-nets without layers. --strip-weight Removes weights not referenced by any layer. --dedup-weight\u3000\u3000\u3000\u3000\u3000 Deduplicates weights. --norm-weight Normalizes subnormal , nan , inf weight values. -h, --help Shows the command help. Example Refine a dnn file by deduplicating weights. $ softneuro refine --dedup-weight Pose_small.dnn Pose_small_refined.dnn ------------------------------------------------------------------ Deduplicate Weights ------------------------------------------------------------------ 'weight_7_0' is deduplicated to 'weight_4_0' (SNR: inf). 'weight_10_0' is deduplicated to 'weight_3_0' (SNR: inf). 'weight_13_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_14_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_15_0' is deduplicated to 'weight_2_0' (SNR: inf). 5 weights are deduplicated. compress \u00b6 Reduces the DNN file weights data size. Usage usage: softneuro compress [--dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES]]... [--pass PASSWORD] [--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be compressed. OUTPUT Compressed DNN file output. Flags Flag Description --dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES] Select what data type will be used to save the weights. The available DTYPE options are float16 or qint8. If this flag isn't set, all main network layer weights will be saved as qint8. If LTYPE is set, only layers of that type will have their weights converted. If WNAME is set, only the weight with that name will be converted. If LAYER_INDICES is set, only the layers at the given indices will have their weights converted. For more information on layer indices, use the softneuro help layer_indices command. --pass PASSWORD Set an encryption password. -h, --help Shows the command help. Example This command creates a vgg16_qint8.dnn file with qint8 weights. \u203bThere's no terminal output $ softneuro compress vgg16.dnn vgg16_qint8.dnn $ ls -lh -rw-rw-r-- 1 user user 528M 1\u6708 1 10:00 vgg16.dnn -rw-rw-r-- 1 user user 133M 1\u6708 1 10:00 vgg16_qint8.dnn cipher \u00b6 Encrypts a DNN file. Usage usage: softneuro cipher [--pass PASSWORD] [--new-pass PASSWORD] [--secret] [--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be encrypted. OUTPUT Output encrypted DNN file. Flags Flag Description -p PASSWORD, --pass PASSWORD Password for input dnn. --new-pass PASSWORD New password for OUTPUT. If not given, the password does not change from INPUT. If empty ('') is given, decrypt INPUT and write it to OUTPUT without password encryption. --secret Encrypts to a secret dnn. -h, --help Shows the command help. Example This command creates a vgg16_enc.dnn encrypted DNN file. \u203bThere's no terminal output $ softneuro cipher --new-pass 4u9pnza vgg16.dnn vgg16_enc.dnn $ ls vgg16.dnn vgg16_enc.dnn $ softneuro run vgg16_enc.dnn mor_dnn.c:921:Error: Invalid password for dnn. softneuro:Error: Load error. $ softneuro run vgg16_enc.dnn -p 4u9pnza --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 36,055 36,055 36,055 1 Dnn_compile() 727,957 727,957 727,957 1 Dnn_forward() 1,080,363 1,080,363 1,080,363 1 Used memory: 1,140,400,128 Bytes calibrate \u00b6 Calibrate a DNN file for static quantization. Calibrate operation fixes the quantization range by calculating max/min outputs of each layer, using prepared inputs. Usage usage: softneuro calibrate [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE][--pass PASSWORD] [--reset] [-trunc RATIO] [--help] IDNN ODNN [INPUT]... Arguments Argument Description IDNN DNN file to be calibrated. ODNN Calibrated DNN file output. INPUT Required input files for calibration. Image files, numpy files, or a directory containing those files, can be specified. Flags Flag Description --keep_img_ar PADDINGCOLOR Keeps aspect ratio when resizing input image. The aspect ratio is not kept by default. Margin space is filled with the color specified by PADDINGCOLOR. PADDINGCOLOR can be specified by RGB value, for example, '0, 0, 0'. --img_resize_mode RESIZEMODE Specifies the resizing mode. 'bilinear' or 'nearest' can be specified. Default is 'bilinear'. -p, --pass PASSWORD Encryption password. --reset Resets the calibration information (max/min). --trunc RATIO Removes the top and bottom data as outliers, specified by 'RATIO' ratio. When RATIO is 0.02, top/bottom 2% data are removed, the min/max values are calculated by the remaining 96% data. Default RATIO is 0. -h, --help Shows the command help. Example This command creates a vgg16_calib.dnn calibrated DNN file. \u203bThere's no terminal output $ softneuro calibrate vgg16.dnn vgg16_calib.dnn input0.jpg input1.jpg input2.jpg $ softneuro tune vgg16_calib.dnn vgg16_calib_tuned.dnn decompose \u00b6 Decompose a net of dnn file into two subnets. Usage usage: softneuro decompose [--pass PASSWORD] [--split SPLIT] [--compress COMPRESS] [--help] INPUT OUTPUT Arguments Argument Description INPUT Input dnn file. OUTPUT Output dnn file Flags Flag Description -p PASSWORD, --pass PASSWORD Password for input file. -s SPLIT, --split SPLIT Set layer to be split from -c COMPRESS, --compress COMPRESS Set net to compress\u3002 -h, --help Show the command help\u3002 Example Split main net of ssd.dnn from conv_pw_1 layer. $ softneuro decompose -s conv_pw_1 ssd.dnn ssd_dcp.dnn [0] from input_1 to conv_pw_1 [1] from conv_dw_2 to sink_0 In the case of decomposing the main network of vgg16.dnn, and then tuning it for an external engine (Qualcomm HTA), the commands are as follows: $ softneuro decompose -c main vgg16.dnn vgg16_decomposed.dnn $ softneuro tune vgg16_decomposed.dnn vgg16_decomposed_tuned.dnn --routine cpu/faster/hta","title":"Model Editing"},{"location":"commands/dnn/editor.html#model-editing","text":"Commands for editing DNN file contents.","title":"Model Editing"},{"location":"commands/dnn/editor.html#extract","text":"Extract weights and model architecture information from a DNN file into JSON and numpy files. Usage usage: softneuro extract [--help] DNN OUTDIR Arguments Argument Description DNN DNN file to be extracted. OUTDIR Output directory where the data will be extracted to. Flags Flag Description -h, --help Shows the command help. Example Running this command will create, in the vgg16_extract folder, model.json , weights.json and a directory containing numpy format files with weights data in a weights directory. \u203bThere's no terminal output $ softneuro extract vgg16.dnn vgg16_extract $ ls vgg16_extract model.json weights weights.json","title":"extract"},{"location":"commands/dnn/editor.html#archive","text":"Pack the files in the same format as what the extract command outputs into a DNN model file. Usage usage: softneuro archive [--help] SRCDIR DNN Arguments Argument Description SRCDIR Directory with contents in the same format as the extract command output. DNN DNN file to be outputed. Flags Flag Description -h, --help Shows the command help. Example This command will generate a vgg16_archive.dnn file. \u203bThere's no terminal output $ softneuro archive vgg16_extract vgg16_archive.dnn $ ls vgg16_extract vgg16_archive.dnn","title":"archive"},{"location":"commands/dnn/editor.html#refine","text":"Refine a DNN file for faster inference times. Generally, the processing used for optimizations is the same as that for converting a model to DNN format. When optimization has not been applied during model conversion, it can be performed later using refine . Usage usage: softneuro refine [--batch-norm-to-madd] [--fuse-dropout] [--fuse-transpose] [--fuse-madd] [--fuse-relu] [--fuse-padding] [--swap-act-pool] [--strip-constant] [--strip-immutable] [--strip-layer] [--strip-net] [--norm-weight] [--dedup-weight] [--strip-weight][--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be refined. OUTPUT Refined DNN file output. Flags If a flag is set only that specific optimization will be done. For instance, if --batch-norm-to-madd is set, other optimizations like relu fuse won't be done. Flags Description --batch-norm-to-madd Transforms batch normalization into madd layers. --fuse-dropout Fuses dropout into the previous layer. --fuse-transpose Fuses transpose into the previous layer.\u3002 --fuse-madd Fuses multiply-add into the previous layer. --fuse-relu Fuses relu into the previous layer. --fuse-padding Fuses zero padding into the previous layer. --swap-act-pool Transforms activation-pooling into pooling activation . --strip-constant Removes layers which are constant\u3002 --strip-immutable Removes layers which are immutable\u3002 --strip-layer Removes unnecessary layers. --strip-net Removes sub-nets without layers. --strip-weight Removes weights not referenced by any layer. --dedup-weight\u3000\u3000\u3000\u3000\u3000 Deduplicates weights. --norm-weight Normalizes subnormal , nan , inf weight values. -h, --help Shows the command help. Example Refine a dnn file by deduplicating weights. $ softneuro refine --dedup-weight Pose_small.dnn Pose_small_refined.dnn ------------------------------------------------------------------ Deduplicate Weights ------------------------------------------------------------------ 'weight_7_0' is deduplicated to 'weight_4_0' (SNR: inf). 'weight_10_0' is deduplicated to 'weight_3_0' (SNR: inf). 'weight_13_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_14_0' is deduplicated to 'weight_2_0' (SNR: inf). 'weight_15_0' is deduplicated to 'weight_2_0' (SNR: inf). 5 weights are deduplicated.","title":"refine"},{"location":"commands/dnn/editor.html#compress","text":"Reduces the DNN file weights data size. Usage usage: softneuro compress [--dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES]]... [--pass PASSWORD] [--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be compressed. OUTPUT Compressed DNN file output. Flags Flag Description --dtype [[LTYPE][.WNAME]=]DTYPE[@LAYER_INDICES] Select what data type will be used to save the weights. The available DTYPE options are float16 or qint8. If this flag isn't set, all main network layer weights will be saved as qint8. If LTYPE is set, only layers of that type will have their weights converted. If WNAME is set, only the weight with that name will be converted. If LAYER_INDICES is set, only the layers at the given indices will have their weights converted. For more information on layer indices, use the softneuro help layer_indices command. --pass PASSWORD Set an encryption password. -h, --help Shows the command help. Example This command creates a vgg16_qint8.dnn file with qint8 weights. \u203bThere's no terminal output $ softneuro compress vgg16.dnn vgg16_qint8.dnn $ ls -lh -rw-rw-r-- 1 user user 528M 1\u6708 1 10:00 vgg16.dnn -rw-rw-r-- 1 user user 133M 1\u6708 1 10:00 vgg16_qint8.dnn","title":"compress"},{"location":"commands/dnn/editor.html#cipher","text":"Encrypts a DNN file. Usage usage: softneuro cipher [--pass PASSWORD] [--new-pass PASSWORD] [--secret] [--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be encrypted. OUTPUT Output encrypted DNN file. Flags Flag Description -p PASSWORD, --pass PASSWORD Password for input dnn. --new-pass PASSWORD New password for OUTPUT. If not given, the password does not change from INPUT. If empty ('') is given, decrypt INPUT and write it to OUTPUT without password encryption. --secret Encrypts to a secret dnn. -h, --help Shows the command help. Example This command creates a vgg16_enc.dnn encrypted DNN file. \u203bThere's no terminal output $ softneuro cipher --new-pass 4u9pnza vgg16.dnn vgg16_enc.dnn $ ls vgg16.dnn vgg16_enc.dnn $ softneuro run vgg16_enc.dnn mor_dnn.c:921:Error: Invalid password for dnn. softneuro:Error: Load error. $ softneuro run vgg16_enc.dnn -p 4u9pnza --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 36,055 36,055 36,055 1 Dnn_compile() 727,957 727,957 727,957 1 Dnn_forward() 1,080,363 1,080,363 1,080,363 1 Used memory: 1,140,400,128 Bytes","title":"cipher"},{"location":"commands/dnn/editor.html#calibrate","text":"Calibrate a DNN file for static quantization. Calibrate operation fixes the quantization range by calculating max/min outputs of each layer, using prepared inputs. Usage usage: softneuro calibrate [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE][--pass PASSWORD] [--reset] [-trunc RATIO] [--help] IDNN ODNN [INPUT]... Arguments Argument Description IDNN DNN file to be calibrated. ODNN Calibrated DNN file output. INPUT Required input files for calibration. Image files, numpy files, or a directory containing those files, can be specified. Flags Flag Description --keep_img_ar PADDINGCOLOR Keeps aspect ratio when resizing input image. The aspect ratio is not kept by default. Margin space is filled with the color specified by PADDINGCOLOR. PADDINGCOLOR can be specified by RGB value, for example, '0, 0, 0'. --img_resize_mode RESIZEMODE Specifies the resizing mode. 'bilinear' or 'nearest' can be specified. Default is 'bilinear'. -p, --pass PASSWORD Encryption password. --reset Resets the calibration information (max/min). --trunc RATIO Removes the top and bottom data as outliers, specified by 'RATIO' ratio. When RATIO is 0.02, top/bottom 2% data are removed, the min/max values are calculated by the remaining 96% data. Default RATIO is 0. -h, --help Shows the command help. Example This command creates a vgg16_calib.dnn calibrated DNN file. \u203bThere's no terminal output $ softneuro calibrate vgg16.dnn vgg16_calib.dnn input0.jpg input1.jpg input2.jpg $ softneuro tune vgg16_calib.dnn vgg16_calib_tuned.dnn","title":"calibrate"},{"location":"commands/dnn/editor.html#decompose","text":"Decompose a net of dnn file into two subnets. Usage usage: softneuro decompose [--pass PASSWORD] [--split SPLIT] [--compress COMPRESS] [--help] INPUT OUTPUT Arguments Argument Description INPUT Input dnn file. OUTPUT Output dnn file Flags Flag Description -p PASSWORD, --pass PASSWORD Password for input file. -s SPLIT, --split SPLIT Set layer to be split from -c COMPRESS, --compress COMPRESS Set net to compress\u3002 -h, --help Show the command help\u3002 Example Split main net of ssd.dnn from conv_pw_1 layer. $ softneuro decompose -s conv_pw_1 ssd.dnn ssd_dcp.dnn [0] from input_1 to conv_pw_1 [1] from conv_dw_2 to sink_0 In the case of decomposing the main network of vgg16.dnn, and then tuning it for an external engine (Qualcomm HTA), the commands are as follows: $ softneuro decompose -c main vgg16.dnn vgg16_decomposed.dnn $ softneuro tune vgg16_decomposed.dnn vgg16_decomposed_tuned.dnn --routine cpu/faster/hta","title":"decompose"},{"location":"commands/dnn/referer.ja.html","text":"\u60c5\u5831\u53c2\u7167\u7cfb \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u5404\u7a2e\u60c5\u5831\u3092\u53c2\u7167\u3059\u308b\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 attr \u00b6 \u6697\u53f7\u5316\u306e\u6709\u7121\u3084\u30d5\u30a1\u30a4\u30eb\u540d\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u5c5e\u6027\u60c5\u5831\u3068\u306f\u4ee5\u4e0b\u306e\u3082\u306e\u3092\u6307\u3057\u307e\u3059\u3002 NAME : \u30d5\u30a1\u30a4\u30eb\u540d NET : \u30cd\u30c3\u30c8\u60c5\u5831 INPUT : \u5165\u529b\u6b21\u5143\u6570 OUTPUT : \u51fa\u529b\u6b21\u5143\u6570 #OPS : \u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u6570 CIPHER : \u6697\u53f7\u5316\u306e\u6709\u7121 COMPRESS : \u30b3\u30f3\u30d7\u30ec\u30b9\u306e\u6709\u7121 TUNE : \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u6709\u7121\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u6642\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u30b9\u30ad\u30fc\u30de #THR : \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u6642\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u30b9\u30ec\u30c3\u30c9\u6570 AFFMASKS : \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u6642\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af \u4f7f\u3044\u65b9 softneuro attr [-pass PASSWORD] [-help] DNN... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002\u8907\u6570\u6307\u5b9a\u3057\u3066\u540c\u6642\u306b\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u3000\u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -p, --pass PASSWORD\u3000 \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u5834\u5408\u306b\u5165\u529b\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002 --net \u30cd\u30c3\u30c8\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u4f8b\uff1a\u30cd\u30c3\u30c8\u306e\u540d\u524d\u3001\u5165\u51fa\u529b\u6b21\u5143\u6570\u3001\u30aa\u30da\u30ec\u30fc\u30bf\u30fc\u6570\u306a\u3069\u3002\u3000\u3000 --cipher \u6697\u53f7\u5316\u306e\u6709\u7121\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000\u3000\u3000 --compress \u30b3\u30f3\u30d7\u30ec\u30b9\u306e\u6709\u7121\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000 --tune \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000 -a, --all \u3059\u3079\u3066\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000\u3000\u3000\u3000 \u4f7f\u7528\u4f8b $ softneuro attr -a -p password ssd_tuned_ciphered_compressed.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS ssd_tuned_ciphered_compressed.dnn preprocess 1x300x300x3 1x300x6 2,286,418,064 password qint8 cpu 4 0x2 main cpu/naive 0x2 postprocess 0x2 0x2 view \u00b6 \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u5165\u51fa\u529b\u30b5\u30a4\u30ba\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u305f\u8a73\u7d30\u306a\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro view [--help] [--password] [--param] [--routine] [--size] [--all] [-name NAME]... [-type TYPE]... DNN \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u30ec\u30a4\u30e4\u30fc\u60c5\u5831\u3092\u8868\u793a\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u5834\u5408\u306b\u5165\u529b\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002 -P, --param \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u5165\u529b\u30fb\u51fa\u529b\u30fb\u91cd\u307f\u30fb\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -r, --routine \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u30eb\u30fc\u30c1\u30f3\u3068\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -s, --size \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba\u3068\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u6570\u3092\u8868\u793a\u3057\u307e\u3059 -a, --all --param , --routine , --size \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u305f\u969b\u306b\u8868\u793a\u3055\u308c\u308b\u60c5\u5831\u3092\u3059\u3079\u3066\u8868\u793a\u3057\u307e\u3059\u3002 --name NAME \u8868\u793a\u3059\u308b\u60c5\u5831\u3092\u30ec\u30a4\u30e4\u30fc\u540d\u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002 \u5165\u529b\u3057\u305f\u6587\u5b57\u5217\u3092\u542b\u3080\u30ec\u30a4\u30e4\u30fc\u540d\u3067\u3042\u308c\u3070\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --type TYPE \u8868\u793a\u3059\u308b\u60c5\u5831\u3092\u30ec\u30a4\u30e4\u30fc\u306e\u7a2e\u985e\u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002 \u4e00\u81f4\u3057\u305f\u7a2e\u985e\u306e\u30ec\u30a4\u30e4\u30fc\u60c5\u5831\u306e\u307f\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro view ssd.dnn [preprocess] # NAME TYPE 0 ? source 1 ? resize 2 ? madd 3 ? sink [main] # NAME TYPE 0 input_1 source 1 conv1 conv2 2 conv_dw_1 depthwise_conv2 3 conv_pw_1 conv2 4 conv_dw_2 depthwise_conv2 5 conv_pw_2 conv2 6 conv_dw_3 depthwise_conv2 7 conv_pw_3 conv2 8 conv_dw_4 depthwise_conv2 9 conv_pw_4 conv2 10 conv_dw_5 depthwise_conv2 11 conv_pw_5 conv2 12 conv_dw_6 depthwise_conv2 13 conv_pw_6 conv2 14 conv_dw_7 depthwise_conv2 15 conv_pw_7 conv2 16 conv_dw_8 depthwise_conv2 17 conv_pw_8 conv2 18 conv_dw_9 depthwise_conv2 19 conv_pw_9 conv2 20 conv_dw_10 depthwise_conv2 21 conv_pw_10 conv2 22 conv_dw_11 depthwise_conv2 23 conv_pw_11 conv2 24 conv_dw_12 depthwise_conv2 25 conv_pw_12 conv2 26 conv_dw_13 depthwise_conv2 27 conv_pw_13 conv2 28 conv14_1 conv2 29 conv14_2 conv2 30 conv15_1 conv2 31 conv15_2 conv2 32 conv16_1 conv2 33 conv16_2 conv2 34 conv17_1 conv2 35 conv17_2 conv2 36 conv17_mbox_conf_2 conv2 37 conv17_mbox_conf_2_flat reshape 38 conv5_mbox_conf_2 conv2 39 conv5_mbox_conf_2_flat reshape 40 conv5_mbox_loc conv2 41 conv5_mbox_loc_flat reshape 42 conv5_mbox_priorbox priorbox 43 conv11_mbox_conf_2 conv2 44 conv11_mbox_conf_2_flat reshape 45 conv11_mbox_loc conv2 46 conv11_mbox_loc_flat reshape 47 conv11_mbox_priorbox priorbox 48 conv13_mbox_conf_2 conv2 49 conv13_mbox_conf_2_flat reshape 50 conv13_mbox_loc conv2 51 conv13_mbox_loc_flat reshape 52 conv13_mbox_priorbox priorbox 53 conv14_mbox_conf_2 conv2 54 conv14_mbox_conf_2_flat reshape 55 conv14_mbox_loc conv2 56 conv14_mbox_loc_flat reshape 57 conv14_mbox_priorbox priorbox 58 conv15_mbox_conf_2 conv2 59 conv15_mbox_conf_2_flat reshape 60 conv15_mbox_loc conv2 61 conv15_mbox_loc_flat reshape 62 conv15_mbox_priorbox priorbox 63 conv16_mbox_conf_2 conv2 64 conv16_mbox_conf_2_flat reshape 65 conv16_mbox_loc conv2 66 conv16_mbox_loc_flat reshape 67 conv16_mbox_priorbox priorbox 68 conv17_mbox_loc conv2 69 conv17_mbox_loc_flat reshape 70 conv17_mbox_priorbox priorbox 71 mbox_priorbox concat 72 mbox_conf concat 73 mbox_conf_logits reshape 74 activation_36 softmax 75 mbox_loc concat 76 mbox_loc_final reshape 77 predictions concat 78 sink_0 sink [postprocess] # NAME TYPE 0 source_1 source 1 decode decode_ssd 2 sink sink plot \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u69cb\u9020\u3092\u753b\u50cf\u3068\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro plot [--help] [--net NET] [--bg-color BG_COLOR] [--fg-color FG_COLOR] [--font-color FONT_COLOR] [--font-size SIZE] [--format FORMAT] DNN OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u56f3\u3092\u51fa\u529b\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u51fa\u529b\u7d50\u679c\u3068\u306a\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --net NET \u753b\u50cf\u51fa\u529b\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u3059\u3002(preprocess, main \u306a\u3069) \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fmain\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u9078\u3073\u307e\u3059\u3002 --bg-color BG_COLOR \u753b\u50cf\u306e\u80cc\u666f\u8272\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f white \u3067\u3059\u3002 --fg-color FG_COLOR \u753b\u50cf\u5185\u306e\u56f3\u5f62\u306e\u8272\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f black \u3067\u3059\u3002 --font-color FONT_COLOR \u753b\u50cf\u5185\u306e\u6587\u5b57\u5217\u306e\u8272\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f black \u3067\u3059\u3002 --font-size SIZE \u753b\u50cf\u5185\u306e\u6587\u5b57\u5217\u306e\u30b5\u30a4\u30ba\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f14\u3067\u3059\u3002 --format FORMAT \u51fa\u529b\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u3067\u3059\u3002auto, png, svg, gif, jpeg, pdf, dot\u5f62\u5f0f\u304c\u9078\u3079\u307e\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fauto(OUTPUT\u306e\u62e1\u5f35\u5b50)\u3092\u5229\u7528\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4e0b\u56f3\u306e\u3088\u3046\u306ainception.png\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 softneuro plot inception.dnn inceptinon.png inception.png","title":"\u60c5\u5831\u53c2\u7167\u7cfb"},{"location":"commands/dnn/referer.ja.html#_1","text":"DNN\u30d5\u30a1\u30a4\u30eb\u5404\u7a2e\u60c5\u5831\u3092\u53c2\u7167\u3059\u308b\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002","title":"\u60c5\u5831\u53c2\u7167\u7cfb"},{"location":"commands/dnn/referer.ja.html#attr","text":"\u6697\u53f7\u5316\u306e\u6709\u7121\u3084\u30d5\u30a1\u30a4\u30eb\u540d\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u5c5e\u6027\u60c5\u5831\u3068\u306f\u4ee5\u4e0b\u306e\u3082\u306e\u3092\u6307\u3057\u307e\u3059\u3002 NAME : \u30d5\u30a1\u30a4\u30eb\u540d NET : \u30cd\u30c3\u30c8\u60c5\u5831 INPUT : \u5165\u529b\u6b21\u5143\u6570 OUTPUT : \u51fa\u529b\u6b21\u5143\u6570 #OPS : \u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u6570 CIPHER : \u6697\u53f7\u5316\u306e\u6709\u7121 COMPRESS : \u30b3\u30f3\u30d7\u30ec\u30b9\u306e\u6709\u7121 TUNE : \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u6709\u7121\u3068\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u6642\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u30b9\u30ad\u30fc\u30de #THR : \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u6642\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u30b9\u30ec\u30c3\u30c9\u6570 AFFMASKS : \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u6642\u306b\u8a2d\u5b9a\u3055\u308c\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af \u4f7f\u3044\u65b9 softneuro attr [-pass PASSWORD] [-help] DNN... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002\u8907\u6570\u6307\u5b9a\u3057\u3066\u540c\u6642\u306b\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u3000\u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -p, --pass PASSWORD\u3000 \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u5834\u5408\u306b\u5165\u529b\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002 --net \u30cd\u30c3\u30c8\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u4f8b\uff1a\u30cd\u30c3\u30c8\u306e\u540d\u524d\u3001\u5165\u51fa\u529b\u6b21\u5143\u6570\u3001\u30aa\u30da\u30ec\u30fc\u30bf\u30fc\u6570\u306a\u3069\u3002\u3000\u3000 --cipher \u6697\u53f7\u5316\u306e\u6709\u7121\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000\u3000\u3000 --compress \u30b3\u30f3\u30d7\u30ec\u30b9\u306e\u6709\u7121\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000 --tune \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000 -a, --all \u3059\u3079\u3066\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002\u3000\u3000\u3000\u3000 \u4f7f\u7528\u4f8b $ softneuro attr -a -p password ssd_tuned_ciphered_compressed.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS ssd_tuned_ciphered_compressed.dnn preprocess 1x300x300x3 1x300x6 2,286,418,064 password qint8 cpu 4 0x2 main cpu/naive 0x2 postprocess 0x2 0x2","title":"attr"},{"location":"commands/dnn/referer.ja.html#view","text":"\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u5165\u51fa\u529b\u30b5\u30a4\u30ba\u306a\u3069\u3001DNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u305f\u8a73\u7d30\u306a\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro view [--help] [--password] [--param] [--routine] [--size] [--all] [-name NAME]... [-type TYPE]... DNN \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u30ec\u30a4\u30e4\u30fc\u60c5\u5831\u3092\u8868\u793a\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u5834\u5408\u306b\u5165\u529b\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002 -P, --param \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u5165\u529b\u30fb\u51fa\u529b\u30fb\u91cd\u307f\u30fb\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -r, --routine \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u30eb\u30fc\u30c1\u30f3\u3068\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -s, --size \u5404\u30ec\u30a4\u30e4\u30fc\u306e\u30c7\u30fc\u30bf\u30b5\u30a4\u30ba\u3068\u30aa\u30da\u30ec\u30fc\u30b7\u30e7\u30f3\u6570\u3092\u8868\u793a\u3057\u307e\u3059 -a, --all --param , --routine , --size \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3057\u305f\u969b\u306b\u8868\u793a\u3055\u308c\u308b\u60c5\u5831\u3092\u3059\u3079\u3066\u8868\u793a\u3057\u307e\u3059\u3002 --name NAME \u8868\u793a\u3059\u308b\u60c5\u5831\u3092\u30ec\u30a4\u30e4\u30fc\u540d\u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002 \u5165\u529b\u3057\u305f\u6587\u5b57\u5217\u3092\u542b\u3080\u30ec\u30a4\u30e4\u30fc\u540d\u3067\u3042\u308c\u3070\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --type TYPE \u8868\u793a\u3059\u308b\u60c5\u5831\u3092\u30ec\u30a4\u30e4\u30fc\u306e\u7a2e\u985e\u3067\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u307e\u3059\u3002 \u4e00\u81f4\u3057\u305f\u7a2e\u985e\u306e\u30ec\u30a4\u30e4\u30fc\u60c5\u5831\u306e\u307f\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro view ssd.dnn [preprocess] # NAME TYPE 0 ? source 1 ? resize 2 ? madd 3 ? sink [main] # NAME TYPE 0 input_1 source 1 conv1 conv2 2 conv_dw_1 depthwise_conv2 3 conv_pw_1 conv2 4 conv_dw_2 depthwise_conv2 5 conv_pw_2 conv2 6 conv_dw_3 depthwise_conv2 7 conv_pw_3 conv2 8 conv_dw_4 depthwise_conv2 9 conv_pw_4 conv2 10 conv_dw_5 depthwise_conv2 11 conv_pw_5 conv2 12 conv_dw_6 depthwise_conv2 13 conv_pw_6 conv2 14 conv_dw_7 depthwise_conv2 15 conv_pw_7 conv2 16 conv_dw_8 depthwise_conv2 17 conv_pw_8 conv2 18 conv_dw_9 depthwise_conv2 19 conv_pw_9 conv2 20 conv_dw_10 depthwise_conv2 21 conv_pw_10 conv2 22 conv_dw_11 depthwise_conv2 23 conv_pw_11 conv2 24 conv_dw_12 depthwise_conv2 25 conv_pw_12 conv2 26 conv_dw_13 depthwise_conv2 27 conv_pw_13 conv2 28 conv14_1 conv2 29 conv14_2 conv2 30 conv15_1 conv2 31 conv15_2 conv2 32 conv16_1 conv2 33 conv16_2 conv2 34 conv17_1 conv2 35 conv17_2 conv2 36 conv17_mbox_conf_2 conv2 37 conv17_mbox_conf_2_flat reshape 38 conv5_mbox_conf_2 conv2 39 conv5_mbox_conf_2_flat reshape 40 conv5_mbox_loc conv2 41 conv5_mbox_loc_flat reshape 42 conv5_mbox_priorbox priorbox 43 conv11_mbox_conf_2 conv2 44 conv11_mbox_conf_2_flat reshape 45 conv11_mbox_loc conv2 46 conv11_mbox_loc_flat reshape 47 conv11_mbox_priorbox priorbox 48 conv13_mbox_conf_2 conv2 49 conv13_mbox_conf_2_flat reshape 50 conv13_mbox_loc conv2 51 conv13_mbox_loc_flat reshape 52 conv13_mbox_priorbox priorbox 53 conv14_mbox_conf_2 conv2 54 conv14_mbox_conf_2_flat reshape 55 conv14_mbox_loc conv2 56 conv14_mbox_loc_flat reshape 57 conv14_mbox_priorbox priorbox 58 conv15_mbox_conf_2 conv2 59 conv15_mbox_conf_2_flat reshape 60 conv15_mbox_loc conv2 61 conv15_mbox_loc_flat reshape 62 conv15_mbox_priorbox priorbox 63 conv16_mbox_conf_2 conv2 64 conv16_mbox_conf_2_flat reshape 65 conv16_mbox_loc conv2 66 conv16_mbox_loc_flat reshape 67 conv16_mbox_priorbox priorbox 68 conv17_mbox_loc conv2 69 conv17_mbox_loc_flat reshape 70 conv17_mbox_priorbox priorbox 71 mbox_priorbox concat 72 mbox_conf concat 73 mbox_conf_logits reshape 74 activation_36 softmax 75 mbox_loc concat 76 mbox_loc_final reshape 77 predictions concat 78 sink_0 sink [postprocess] # NAME TYPE 0 source_1 source 1 decode decode_ssd 2 sink sink","title":"view"},{"location":"commands/dnn/referer.ja.html#plot","text":"DNN\u30d5\u30a1\u30a4\u30eb\u306b\u4fdd\u5b58\u3055\u308c\u305f\u30e2\u30c7\u30eb\u69cb\u9020\u3092\u753b\u50cf\u3068\u3057\u3066\u51fa\u529b\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro plot [--help] [--net NET] [--bg-color BG_COLOR] [--fg-color FG_COLOR] [--font-color FONT_COLOR] [--font-size SIZE] [--format FORMAT] DNN OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u56f3\u3092\u51fa\u529b\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u51fa\u529b\u7d50\u679c\u3068\u306a\u308b\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --net NET \u753b\u50cf\u51fa\u529b\u3059\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u3059\u3002(preprocess, main \u306a\u3069) \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fmain\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u9078\u3073\u307e\u3059\u3002 --bg-color BG_COLOR \u753b\u50cf\u306e\u80cc\u666f\u8272\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f white \u3067\u3059\u3002 --fg-color FG_COLOR \u753b\u50cf\u5185\u306e\u56f3\u5f62\u306e\u8272\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f black \u3067\u3059\u3002 --font-color FONT_COLOR \u753b\u50cf\u5185\u306e\u6587\u5b57\u5217\u306e\u8272\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f black \u3067\u3059\u3002 --font-size SIZE \u753b\u50cf\u5185\u306e\u6587\u5b57\u5217\u306e\u30b5\u30a4\u30ba\u3067\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f14\u3067\u3059\u3002 --format FORMAT \u51fa\u529b\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u3067\u3059\u3002auto, png, svg, gif, jpeg, pdf, dot\u5f62\u5f0f\u304c\u9078\u3079\u307e\u3059\u3002 \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fauto(OUTPUT\u306e\u62e1\u5f35\u5b50)\u3092\u5229\u7528\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4e0b\u56f3\u306e\u3088\u3046\u306ainception.png\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 softneuro plot inception.dnn inceptinon.png inception.png","title":"plot"},{"location":"commands/dnn/referer.html","text":"Model Information \u00b6 Commands for showing various DNN file information. attr \u00b6 Show DNN file attributes such as tuning/encryption status and input/output. The available attributes are as follows: NAME : File name NET : Net information INPUT : Input shape OUTPUT : Output shape #OPS : Operation count CIPHER : Encryption status COMPRESS : Compression information TUNE : Tuning status and schemas #THR : Number of threads used for tuning AFFMASKS : Affinity mask used for tuning Usage softneuro attr [-pass PASSWORD] [-help] DNN... Arguments Argument Description DNN DNN file to have its attributes printed. More than one can be set at once. Flags Flag Description -h, --help \u3000\u3000 Show this help message and exit. -p, --pass PASSWORD\u3000 Password for DNN. --net Show net information, i.e. net names, input/output shapes and the number of operations. --cipher Show cipher information. --compress Show compression information. --tune Show tuning information.\u3000 -a, --all Show all information. Example $ softneuro attr -a -p password ssd_tuned_ciphered_compressed.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS ssd_tuned_ciphered_compressed.dnn preprocess 1x300x300x3 1x300x6 2,286,418,064 password qint8 cpu 4 0x2 main cpu/naive 0x2 postprocess 0x2 0x2 view \u00b6 Shows input and output sizes for each layer, among other information for a DNN file. Usage usage: softneuro view [--help] [--password] [--param] [--routine] [--size] [--all] [-name NAME]... [-type TYPE]... DNN Arguments Argument Description DNN DNN file to have its information displayed. Flags Flag Description -h, --help \u3000\u3000 Show this help message and exit. -p, --pass PASSWORD\u3000 Password for DNN. -P, --param Show the input, output, weight and parameters for each layer. -r, --routine Show the routines and their parameters for each layer. -s, --size Show the data size for all data. -a, --all Combines the --param , --routine and --size flags. --name NAME Filters the information to any layer containing NAME in its name. --type TYPE Filters the information by layer type. Example $ softneuro view ssd.dnn [preprocess] # NAME TYPE 0 ? source 1 ? resize 2 ? madd 3 ? sink [main] # NAME TYPE 0 input_1 source 1 conv1 conv2 2 conv_dw_1 depthwise_conv2 3 conv_pw_1 conv2 4 conv_dw_2 depthwise_conv2 5 conv_pw_2 conv2 6 conv_dw_3 depthwise_conv2 7 conv_pw_3 conv2 8 conv_dw_4 depthwise_conv2 9 conv_pw_4 conv2 10 conv_dw_5 depthwise_conv2 11 conv_pw_5 conv2 12 conv_dw_6 depthwise_conv2 13 conv_pw_6 conv2 14 conv_dw_7 depthwise_conv2 15 conv_pw_7 conv2 16 conv_dw_8 depthwise_conv2 17 conv_pw_8 conv2 18 conv_dw_9 depthwise_conv2 19 conv_pw_9 conv2 20 conv_dw_10 depthwise_conv2 21 conv_pw_10 conv2 22 conv_dw_11 depthwise_conv2 23 conv_pw_11 conv2 24 conv_dw_12 depthwise_conv2 25 conv_pw_12 conv2 26 conv_dw_13 depthwise_conv2 27 conv_pw_13 conv2 28 conv14_1 conv2 29 conv14_2 conv2 30 conv15_1 conv2 31 conv15_2 conv2 32 conv16_1 conv2 33 conv16_2 conv2 34 conv17_1 conv2 35 conv17_2 conv2 36 conv17_mbox_conf_2 conv2 37 conv17_mbox_conf_2_flat reshape 38 conv5_mbox_conf_2 conv2 39 conv5_mbox_conf_2_flat reshape 40 conv5_mbox_loc conv2 41 conv5_mbox_loc_flat reshape 42 conv5_mbox_priorbox priorbox 43 conv11_mbox_conf_2 conv2 44 conv11_mbox_conf_2_flat reshape 45 conv11_mbox_loc conv2 46 conv11_mbox_loc_flat reshape 47 conv11_mbox_priorbox priorbox 48 conv13_mbox_conf_2 conv2 49 conv13_mbox_conf_2_flat reshape 50 conv13_mbox_loc conv2 51 conv13_mbox_loc_flat reshape 52 conv13_mbox_priorbox priorbox 53 conv14_mbox_conf_2 conv2 54 conv14_mbox_conf_2_flat reshape 55 conv14_mbox_loc conv2 56 conv14_mbox_loc_flat reshape 57 conv14_mbox_priorbox priorbox 58 conv15_mbox_conf_2 conv2 59 conv15_mbox_conf_2_flat reshape 60 conv15_mbox_loc conv2 61 conv15_mbox_loc_flat reshape 62 conv15_mbox_priorbox priorbox 63 conv16_mbox_conf_2 conv2 64 conv16_mbox_conf_2_flat reshape 65 conv16_mbox_loc conv2 66 conv16_mbox_loc_flat reshape 67 conv16_mbox_priorbox priorbox 68 conv17_mbox_loc conv2 69 conv17_mbox_loc_flat reshape 70 conv17_mbox_priorbox priorbox 71 mbox_priorbox concat 72 mbox_conf concat 73 mbox_conf_logits reshape 74 activation_36 softmax 75 mbox_loc concat 76 mbox_loc_final reshape 77 predictions concat 78 sink_0 sink [postprocess] # NAME TYPE 0 source_1 source 1 decode decode_ssd 2 sink sink plot \u00b6 Generates an image file showing the model architecture for a DNN file. Usage usage: softneuro plot [--help] [--net NET] [--bg-color BG_COLOR] [--fg-color FG_COLOR] [--font-color FONT_COLOR] [--font_size SIZE] [--format FORMAT] DNN OUTPUT Arguments Argument Description DNN DNN file to be plotted. OUTPUT Output image file. Flags Flag Description -h, --help Shows the command help. --net NET Network (preprocess, main...) to be transformed into an image. Defaults to main. --bg-color BG_COLOR Image background color. Defaults to white . --fg-color FG_COLOR Rectangle color. Defaults to black . --font-color FONT_COLOR Font color. Defaults to black . --font-size SIZE Font size. Defaults to 14. --format FORMAT Output file format, one of auto, png, svg, gif, jpeg, pdf or dot. Defaults to auto (the OUTPUT file extension). Example The following image will be generated as \"inception.png\". \u203bThere's no terminal output. softneuro plot inception.dnn inception.png inception.png","title":"Model Information"},{"location":"commands/dnn/referer.html#model-information","text":"Commands for showing various DNN file information.","title":"Model Information"},{"location":"commands/dnn/referer.html#attr","text":"Show DNN file attributes such as tuning/encryption status and input/output. The available attributes are as follows: NAME : File name NET : Net information INPUT : Input shape OUTPUT : Output shape #OPS : Operation count CIPHER : Encryption status COMPRESS : Compression information TUNE : Tuning status and schemas #THR : Number of threads used for tuning AFFMASKS : Affinity mask used for tuning Usage softneuro attr [-pass PASSWORD] [-help] DNN... Arguments Argument Description DNN DNN file to have its attributes printed. More than one can be set at once. Flags Flag Description -h, --help \u3000\u3000 Show this help message and exit. -p, --pass PASSWORD\u3000 Password for DNN. --net Show net information, i.e. net names, input/output shapes and the number of operations. --cipher Show cipher information. --compress Show compression information. --tune Show tuning information.\u3000 -a, --all Show all information. Example $ softneuro attr -a -p password ssd_tuned_ciphered_compressed.dnn NAME NET INPUT OUTPUT #OPS CIPHER COMPRESS TUNE #THR AFFMASKS ssd_tuned_ciphered_compressed.dnn preprocess 1x300x300x3 1x300x6 2,286,418,064 password qint8 cpu 4 0x2 main cpu/naive 0x2 postprocess 0x2 0x2","title":"attr"},{"location":"commands/dnn/referer.html#view","text":"Shows input and output sizes for each layer, among other information for a DNN file. Usage usage: softneuro view [--help] [--password] [--param] [--routine] [--size] [--all] [-name NAME]... [-type TYPE]... DNN Arguments Argument Description DNN DNN file to have its information displayed. Flags Flag Description -h, --help \u3000\u3000 Show this help message and exit. -p, --pass PASSWORD\u3000 Password for DNN. -P, --param Show the input, output, weight and parameters for each layer. -r, --routine Show the routines and their parameters for each layer. -s, --size Show the data size for all data. -a, --all Combines the --param , --routine and --size flags. --name NAME Filters the information to any layer containing NAME in its name. --type TYPE Filters the information by layer type. Example $ softneuro view ssd.dnn [preprocess] # NAME TYPE 0 ? source 1 ? resize 2 ? madd 3 ? sink [main] # NAME TYPE 0 input_1 source 1 conv1 conv2 2 conv_dw_1 depthwise_conv2 3 conv_pw_1 conv2 4 conv_dw_2 depthwise_conv2 5 conv_pw_2 conv2 6 conv_dw_3 depthwise_conv2 7 conv_pw_3 conv2 8 conv_dw_4 depthwise_conv2 9 conv_pw_4 conv2 10 conv_dw_5 depthwise_conv2 11 conv_pw_5 conv2 12 conv_dw_6 depthwise_conv2 13 conv_pw_6 conv2 14 conv_dw_7 depthwise_conv2 15 conv_pw_7 conv2 16 conv_dw_8 depthwise_conv2 17 conv_pw_8 conv2 18 conv_dw_9 depthwise_conv2 19 conv_pw_9 conv2 20 conv_dw_10 depthwise_conv2 21 conv_pw_10 conv2 22 conv_dw_11 depthwise_conv2 23 conv_pw_11 conv2 24 conv_dw_12 depthwise_conv2 25 conv_pw_12 conv2 26 conv_dw_13 depthwise_conv2 27 conv_pw_13 conv2 28 conv14_1 conv2 29 conv14_2 conv2 30 conv15_1 conv2 31 conv15_2 conv2 32 conv16_1 conv2 33 conv16_2 conv2 34 conv17_1 conv2 35 conv17_2 conv2 36 conv17_mbox_conf_2 conv2 37 conv17_mbox_conf_2_flat reshape 38 conv5_mbox_conf_2 conv2 39 conv5_mbox_conf_2_flat reshape 40 conv5_mbox_loc conv2 41 conv5_mbox_loc_flat reshape 42 conv5_mbox_priorbox priorbox 43 conv11_mbox_conf_2 conv2 44 conv11_mbox_conf_2_flat reshape 45 conv11_mbox_loc conv2 46 conv11_mbox_loc_flat reshape 47 conv11_mbox_priorbox priorbox 48 conv13_mbox_conf_2 conv2 49 conv13_mbox_conf_2_flat reshape 50 conv13_mbox_loc conv2 51 conv13_mbox_loc_flat reshape 52 conv13_mbox_priorbox priorbox 53 conv14_mbox_conf_2 conv2 54 conv14_mbox_conf_2_flat reshape 55 conv14_mbox_loc conv2 56 conv14_mbox_loc_flat reshape 57 conv14_mbox_priorbox priorbox 58 conv15_mbox_conf_2 conv2 59 conv15_mbox_conf_2_flat reshape 60 conv15_mbox_loc conv2 61 conv15_mbox_loc_flat reshape 62 conv15_mbox_priorbox priorbox 63 conv16_mbox_conf_2 conv2 64 conv16_mbox_conf_2_flat reshape 65 conv16_mbox_loc conv2 66 conv16_mbox_loc_flat reshape 67 conv16_mbox_priorbox priorbox 68 conv17_mbox_loc conv2 69 conv17_mbox_loc_flat reshape 70 conv17_mbox_priorbox priorbox 71 mbox_priorbox concat 72 mbox_conf concat 73 mbox_conf_logits reshape 74 activation_36 softmax 75 mbox_loc concat 76 mbox_loc_final reshape 77 predictions concat 78 sink_0 sink [postprocess] # NAME TYPE 0 source_1 source 1 decode decode_ssd 2 sink sink","title":"view"},{"location":"commands/dnn/referer.html#plot","text":"Generates an image file showing the model architecture for a DNN file. Usage usage: softneuro plot [--help] [--net NET] [--bg-color BG_COLOR] [--fg-color FG_COLOR] [--font-color FONT_COLOR] [--font_size SIZE] [--format FORMAT] DNN OUTPUT Arguments Argument Description DNN DNN file to be plotted. OUTPUT Output image file. Flags Flag Description -h, --help Shows the command help. --net NET Network (preprocess, main...) to be transformed into an image. Defaults to main. --bg-color BG_COLOR Image background color. Defaults to white . --fg-color FG_COLOR Rectangle color. Defaults to black . --font-color FONT_COLOR Font color. Defaults to black . --font-size SIZE Font size. Defaults to 14. --format FORMAT Output file format, one of auto, png, svg, gif, jpeg, pdf or dot. Defaults to auto (the OUTPUT file extension). Example The following image will be generated as \"inception.png\". \u203bThere's no terminal output. softneuro plot inception.dnn inception.png inception.png","title":"plot"},{"location":"commands/general/general.ja.html","text":"\u4e00\u822c\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 \u4e00\u822c\u7684\u306a\u64cd\u4f5c\u3092\u884c\u3046\u30b3\u30de\u30f3\u30c9\u306e\u64cd\u4f5c\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 help \u00b6 \u5404\u30b3\u30de\u30f3\u30c9\u306e\u5229\u7528\u65b9\u6cd5\u3092\u8868\u793a\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u307e\u305f\u3001\u4e00\u90e8\u306e\u5f15\u6570\u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u3082\u8868\u793a\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro help [-h] COMMAND \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 COMMAND \u30d8\u30eb\u30d7\u3092\u8868\u793a\u3059\u308b\u5bfe\u8c61\u306e\u30b3\u30de\u30f3\u30c9\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u3000\u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b1 $ softneuro help version usage: softneuro version [-h] Show the SoftNeuro version. [OPTIONS] -h, --help show this help message and exit. \u4f7f\u7528\u4f8b2 $ softneuro help routine_desc usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX] The routine descriptor represents routine information. It may be followed by layer indices starting with @ ('softneuro help layer_indices' for more detail). [REQUIRED] DEVICE device name. 'cpu', 'opencl', 'cuda', etc. [OPTIONS] DTYPE a data type. 'float32' (default), 'float16', 'qint8', etc. CH a channels position. 'chf' (channels-first) or 'chl' (channels-last, default). LEVEL a optimization level. 'naive', 'fast' (default) or 'faster'. AUX auxiliary information. Any text can be used except those used in LEVEL. [EXAMPLES] cpu/faster/wg3x3_nxn DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn'. opencl:float16 DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX=''. cpu:chf/naive DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX=''. version \u00b6 SoftNeuro\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 softneuro [-h] version \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u3000\u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro version SoftNeuro 5.0.e41bf68 license \u00b6 \u30e9\u30a4\u30bb\u30f3\u30b9\u60c5\u5831\u306e\u78ba\u8a8d\u3068\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u8a2d\u5b9a\u3092\u884c\u3046\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 softneuro [-h] license [--key LICENSE_KEY] \u30aa\u30d7\u30b7\u30e7\u30f3 Flag Description -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --key \u8a2d\u5b9a\u3059\u308b\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u30e9\u30a4\u30bb\u30f3\u30b9\u60c5\u5831\u306e\u78ba\u8a8d \u00b6 \u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u8a2d\u5b9a\u524d \u00b6 $ softneuro license softneuro:Error: No license key. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: Send to Morpho staff this USER_ID to get LICENSE_KEY. \u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u671f\u9650\u524d \u00b6 $ softneuro license License is valid. User ID: 12345678-ABCDEFGH. License Key: BC67E6E8-9AC2F88B-88F4005D-12238393. Expired Date: 2021-03-14. \u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u671f\u9650\u5f8c \u00b6 $ softneuro license softneuro:Error: License expired. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: License Key: B30CF510-B284DCEF-E9F7ECC3-9114E854. softneuro:Error: Expired Date: 2021-02-11. \u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u8a2d\u5b9a \u00b6 $ softneuro license --key 12345678-90123456-ABCDEFGH-IJKLMNOP","title":"\u4e00\u822c\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/general/general.ja.html#_1","text":"\u4e00\u822c\u7684\u306a\u64cd\u4f5c\u3092\u884c\u3046\u30b3\u30de\u30f3\u30c9\u306e\u64cd\u4f5c\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002","title":"\u4e00\u822c\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/general/general.ja.html#help","text":"\u5404\u30b3\u30de\u30f3\u30c9\u306e\u5229\u7528\u65b9\u6cd5\u3092\u8868\u793a\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u307e\u305f\u3001\u4e00\u90e8\u306e\u5f15\u6570\u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u3082\u8868\u793a\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro help [-h] COMMAND \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 COMMAND \u30d8\u30eb\u30d7\u3092\u8868\u793a\u3059\u308b\u5bfe\u8c61\u306e\u30b3\u30de\u30f3\u30c9\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u3000\u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b1 $ softneuro help version usage: softneuro version [-h] Show the SoftNeuro version. [OPTIONS] -h, --help show this help message and exit. \u4f7f\u7528\u4f8b2 $ softneuro help routine_desc usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX] The routine descriptor represents routine information. It may be followed by layer indices starting with @ ('softneuro help layer_indices' for more detail). [REQUIRED] DEVICE device name. 'cpu', 'opencl', 'cuda', etc. [OPTIONS] DTYPE a data type. 'float32' (default), 'float16', 'qint8', etc. CH a channels position. 'chf' (channels-first) or 'chl' (channels-last, default). LEVEL a optimization level. 'naive', 'fast' (default) or 'faster'. AUX auxiliary information. Any text can be used except those used in LEVEL. [EXAMPLES] cpu/faster/wg3x3_nxn DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn'. opencl:float16 DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX=''. cpu:chf/naive DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX=''.","title":"help"},{"location":"commands/general/general.ja.html#version","text":"SoftNeuro\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 softneuro [-h] version \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u3000\u3000 \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro version SoftNeuro 5.0.e41bf68","title":"version"},{"location":"commands/general/general.ja.html#license","text":"\u30e9\u30a4\u30bb\u30f3\u30b9\u60c5\u5831\u306e\u78ba\u8a8d\u3068\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u8a2d\u5b9a\u3092\u884c\u3046\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u4f7f\u3044\u65b9 softneuro [-h] license [--key LICENSE_KEY] \u30aa\u30d7\u30b7\u30e7\u30f3 Flag Description -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --key \u8a2d\u5b9a\u3059\u308b\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b","title":"license"},{"location":"commands/general/general.ja.html#_2","text":"","title":"\u30e9\u30a4\u30bb\u30f3\u30b9\u60c5\u5831\u306e\u78ba\u8a8d"},{"location":"commands/general/general.ja.html#_3","text":"$ softneuro license softneuro:Error: No license key. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: Send to Morpho staff this USER_ID to get LICENSE_KEY.","title":"\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u8a2d\u5b9a\u524d"},{"location":"commands/general/general.ja.html#_4","text":"$ softneuro license License is valid. User ID: 12345678-ABCDEFGH. License Key: BC67E6E8-9AC2F88B-88F4005D-12238393. Expired Date: 2021-03-14.","title":"\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u671f\u9650\u524d"},{"location":"commands/general/general.ja.html#_5","text":"$ softneuro license softneuro:Error: License expired. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: License Key: B30CF510-B284DCEF-E9F7ECC3-9114E854. softneuro:Error: Expired Date: 2021-02-11.","title":"\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u671f\u9650\u5f8c"},{"location":"commands/general/general.ja.html#_6","text":"$ softneuro license --key 12345678-90123456-ABCDEFGH-IJKLMNOP","title":"\u30e9\u30a4\u30bb\u30f3\u30b9\u30ad\u30fc\u306e\u8a2d\u5b9a"},{"location":"commands/general/general.html","text":"General Commands \u00b6 help \u00b6 Shows usage help for each command. Also describes the formatting of some arguments. Usage softneuro help [-h] COMMAND Arguments Argument Description COMMAND Command for which the help will be shown. Flags Flag Description -h, --help \u3000\u3000 Shows the help for this command. Example 1 $ softneuro help version usage: softneuro version [-h] Show the SoftNeuro version. [OPTIONS] -h, --help show this help message and exit. Example 2 $ softneuro help routine_desc usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX] The routine descriptor represents routine information. It may be followed by layer indices starting with @ ('softneuro help layer_indices' for more detail). [REQUIRED] DEVICE device name. 'cpu', 'opencl', 'cuda', etc. [OPTIONS] DTYPE a data type. 'float32' (default), 'float16', 'qint8', etc. CH a channels position. 'chf' (channels-first) or 'chl' (channels-last, default). LEVEL a optimization level. 'naive', 'fast' (default) or 'faster'. AUX auxiliary information. Any text can be used except those used in LEVEL. [EXAMPLES] cpu/faster/wg3x3_nxn DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn'. opencl:float16 DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX=''. cpu:chf/naive DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX=''. version \u00b6 Shows the SoftNeuro version. Usage softneuro [-h] version Flags Flag Description -h, --help \u3000\u3000 Shows the help for this command. Example $ softneuro version SoftNeuro 5.0.e41bf68 license \u00b6 Command for checking the license information and setting a license key. Usage softneuro [-h] license [--key LICENSE_KEY] Flags Flag Description -h, -help \u3000\u3000 Shows the help for this command. --key \u3000\u3000 Specify a license key to be set. Example Checking license information \u00b6 Before setting a license key \u00b6 $ softneuro license softneuro:Error: No license key. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: Send to Morpho staff this USER_ID to get LICENSE_KEY. License key expiration date \u00b6 $ softneuro license License is valid. User ID: 12345678-ABCDEFGH. License Key: BC67E6E8-9AC2F88B-88F4005D-12238393. Expired Date: 2021-03-14. After license key expiration \u00b6 $ softneuro license softneuro:Error: License expired. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: License Key: B30CF510-B284DCEF-E9F7ECC3-9114E854. softneuro:Error: Expired Date: 2021-02-11. Setting a license key \u00b6 $ softneuro license --key 12345678-90123456-ABCDEFGH-IJKLMNOP","title":"General Commands"},{"location":"commands/general/general.html#general-commands","text":"","title":"General Commands"},{"location":"commands/general/general.html#help","text":"Shows usage help for each command. Also describes the formatting of some arguments. Usage softneuro help [-h] COMMAND Arguments Argument Description COMMAND Command for which the help will be shown. Flags Flag Description -h, --help \u3000\u3000 Shows the help for this command. Example 1 $ softneuro help version usage: softneuro version [-h] Show the SoftNeuro version. [OPTIONS] -h, --help show this help message and exit. Example 2 $ softneuro help routine_desc usage: DEVICE[:DTYPE][:CH][/LEVEL][/AUX] The routine descriptor represents routine information. It may be followed by layer indices starting with @ ('softneuro help layer_indices' for more detail). [REQUIRED] DEVICE device name. 'cpu', 'opencl', 'cuda', etc. [OPTIONS] DTYPE a data type. 'float32' (default), 'float16', 'qint8', etc. CH a channels position. 'chf' (channels-first) or 'chl' (channels-last, default). LEVEL a optimization level. 'naive', 'fast' (default) or 'faster'. AUX auxiliary information. Any text can be used except those used in LEVEL. [EXAMPLES] cpu/faster/wg3x3_nxn DEVICE='cpu', DTYPE='float32', CH='chl', LEVEL='faster' and AUX='wg3x3_nxn'. opencl:float16 DEVICE='opencl', DTYPE='float16', CH='chl', LEVEL='fast' and AUX=''. cpu:chf/naive DEVICE='cpu', DTYPE='float32', CH='chf', LEVEL='naive' and AUX=''.","title":"help"},{"location":"commands/general/general.html#version","text":"Shows the SoftNeuro version. Usage softneuro [-h] version Flags Flag Description -h, --help \u3000\u3000 Shows the help for this command. Example $ softneuro version SoftNeuro 5.0.e41bf68","title":"version"},{"location":"commands/general/general.html#license","text":"Command for checking the license information and setting a license key. Usage softneuro [-h] license [--key LICENSE_KEY] Flags Flag Description -h, -help \u3000\u3000 Shows the help for this command. --key \u3000\u3000 Specify a license key to be set. Example","title":"license"},{"location":"commands/general/general.html#checking-license-information","text":"","title":"Checking license information"},{"location":"commands/general/general.html#before-setting-a-license-key","text":"$ softneuro license softneuro:Error: No license key. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: Send to Morpho staff this USER_ID to get LICENSE_KEY.","title":"Before setting a license key"},{"location":"commands/general/general.html#license-key-expiration-date","text":"$ softneuro license License is valid. User ID: 12345678-ABCDEFGH. License Key: BC67E6E8-9AC2F88B-88F4005D-12238393. Expired Date: 2021-03-14.","title":"License key expiration date"},{"location":"commands/general/general.html#after-license-key-expiration","text":"$ softneuro license softneuro:Error: License expired. softneuro:Error: User ID: 12345678-ABCDEFGH. softneuro:Error: License Key: B30CF510-B284DCEF-E9F7ECC3-9114E854. softneuro:Error: Expired Date: 2021-02-11.","title":"After license key expiration"},{"location":"commands/general/general.html#setting-a-license-key","text":"$ softneuro license --key 12345678-90123456-ABCDEFGH-IJKLMNOP","title":"Setting a license key"},{"location":"commands/layer-routine/layer-routine.ja.html","text":"\u30ec\u30a4\u30e4\u30fb\u30eb\u30fc\u30c1\u30f3\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 SoftNeuro\u306e\u30ec\u30a4\u30e4\u30fb\u30eb\u30fc\u30c1\u30f3\u306b\u5bfe\u3059\u308b\u64cd\u4f5c\u3092\u884c\u3046\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u306e\u64cd\u4f5c\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 GPU\u306a\u3069\u3092\u542b\u3081\u305f\u30de\u30eb\u30c1\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u74b0\u5883\u306b\u304a\u3044\u3066\u3001\u5229\u7528\u53ef\u80fd\u306a\u30c7\u30d0\u30a4\u30b9\u3001\u30ec\u30a4\u30e4\u3001\u30eb\u30fc\u30c1\u30f3\u306e\u78ba\u8a8d\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 plugins \u00b6 \u8ffd\u52a0\u30eb\u30fc\u30c1\u30f3\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u7ba1\u7406\u3092\u884c\u3044\u307e\u3059\u3002 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4e00\u89a7\u8868\u793a\u3001\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30fb\u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3001\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4e00\u89a7\u306e\u8868\u793a\u306a\u3069\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro plugins [--help] [-i PLUGIN] [-u PLUGIN] [-s] \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -i, --install PLUGIN PLUGIN \u3067\u6307\u5b9a\u3057\u305f\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 auto \u3068\u6307\u5b9a\u3059\u308b\u3068\u9069\u5207\u306a\u3082\u306e\u3092\u5168\u3066\u81ea\u52d5\u7684\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 -u, --uninstall PLUGIN PLUGIN \u3067\u6307\u5b9a\u3057\u305f\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 all \u3068\u6307\u5b9a\u3059\u308b\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e\u5168\u3066\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 -s, --status \u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u3068\u305d\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u72b6\u6cc1\u3092\u4e00\u89a7\u8868\u793a\u3057\u307e\u3059\u3002\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u72b6\u6cc1\u306e\u51e1\u4f8b\u306f\u4e0b\u8a18\u306e\u8868\u306e\u3068\u304a\u308a\u3067\u3059\u3002 \u30b7\u30f3\u30dc\u30eb \u72b6\u614b I \u6b63\u5e38\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306a\u72b6\u614b C \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u3060\u304c\u4e21\u7acb\u3067\u304d\u306a\u3044\u4ed6\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u304c\u5b58\u5728\u3059\u308b\u72b6\u614b ? \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u3060\u304c\u6b63\u5e38\u306b\u5b9f\u884c\u3067\u304d\u306a\u3044\u53ef\u80fd\u6027\u304c\u3042\u308b\u72b6\u614b \u306a\u3057 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u306a\u3044\u72b6\u614b \u4f7f\u7528\u4f8b \u30aa\u30d7\u30b7\u30e7\u30f3\u7121\u3057\u3067\u5b9f\u884c\u3059\u308b\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 $ softneuro plugins plugin_avx2 AVX routines. plugin_opencl OpenCL routines. \u6b21\u306b\u4ed6\u306b\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u304c\u306a\u3044\u304b\u78ba\u8a8d\u3057\u307e\u3059\u3002\u4e0b\u306e\u4f8b\u3067\u306f\u3001 plugin_cuda \u304c\u5229\u7528\u53ef\u80fd\u3067\u3059\u3002 $ softneuro plugins -s I plugin_avx2 I plugin_opencl plugin_cuda -i \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u3001 plugin_cuda \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u8ffd\u52a0\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 $ softneuro plugin -i plugin_cuda `plugin_cuda` is installed. layers \u00b6 \u5229\u7528\u53ef\u80fd\u306a\u30ec\u30a4\u30e4\u30fc\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro layers [--help] \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro layers adaptive_unit_scale add ave_pool2 batch_norm box_filter : lparams \u00b6 \u30ec\u30a4\u30e4\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3068\u305d\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro lparams [--help] LAYER \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30ec\u30a4\u30e4\u30fc\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro lparams conv2 {'padding': 'valid', 'pads': 0, 'dilations': 1, 'strides': 1, 'has_relu': false, 'relu_max_value': -1.0} routines \u00b6 \u5b9f\u884c\u74b0\u5883\u3067\u5b9f\u884c\u53ef\u80fd\u306a\u30b9\u30ad\u30fc\u30de\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u5b9f\u884c\u74b0\u5883\u3067\u5b9f\u884c\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro routines [--help] LAYER \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u5b9f\u884c\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30ec\u30a4\u30e4\u30fc\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001\u30b9\u30ad\u30fc\u30de\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro routines conv2 cpu/naive cpu/naive/wg2 cpu:chf/naive cpu:qint8:pt_sym/naive cpu:qint8:pt_asym/naive cpu:qint8:pc_sym/naive cpu:qint8:pc_asym/naive cpu:qint8/naive cpu/wg2 : rparams \u00b6 \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3068\u305d\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306e\u4e00\u89a7(\u30ec\u30b7\u30d4)\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro rparams [--help] LAYER ROUTINE \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30eb\u30fc\u30c1\u30f3\u3092\u6301\u3064\u30ec\u30a4\u30e4\u30fc\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 ROUTINE \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30eb\u30fc\u30c1\u30f3\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro rparams conv2 cpu/wg3x3_nxn_avx {'cache': [8192, 16384, 32768], 'task_unit': [4, 8, 16], 'tile_size': [2, 4, 6, 8]} test \u00b6 \u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306e\u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro test [-o OUTPUT]... [--weight WNAME TENSOR]...[--thread NTHREADS] [--affinity MASK[@IDS]] [--params PARAMS][--routine ROUTINE] [--rparams RPARAMS] [--loop NLOOPS] [--help] LAYER [INPUT]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3059\u308b\u30ec\u30a4\u30e4\u3002 INPUT \u5165\u529b\u3068\u306a\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306f tensor specification \u3067\u3059\u3002\u672a\u6307\u5b9a\u6642\u306f[-1, 1]\u306e\u4e71\u6570\u304c\u5165\u529b\u3068\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -o OUTPUT, --output OUTPUT \u7d50\u679c\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 --weight WNAME TENSOR WNAME \u3067\u6307\u5b9a\u3057\u305f\u30a6\u30a8\u30a4\u30c8\u306b TENSOR \u3092\u8a2d\u5b9a\u3057\u3066\u5b9f\u884c\u3057\u307e\u3059\u3002\u30c6\u30f3\u30bd\u30eb\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306f tensor specification \u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\u672a\u6307\u5b9a\u6642\u306f[-1, 1]\u306e\u4e71\u6570\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002\u3000 --thread NTHREADS \u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 \u6307\u5b9a\u306e\u306a\u3044\u5834\u5408\u306fCPU\u306e\u30b3\u30a2\u6570\u3068\u540c\u3058\u6570\u306b\u306a\u308a\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --params PARAMS \u30ec\u30a4\u30e4\u30d1\u30e9\u30e1\u30fc\u30bf\u3092JSON\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u306f lparams \u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 -r ROUTINE, --routine ROUTINE \u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3057\u3066\u5b9f\u884c\u3057\u307e\u3059\u3002 \u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f cpu \u3068\u306a\u308a\u307e\u3059\u3002\u5b9f\u884c\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306f routines \u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 --rparams RPARAMS \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3092JSON\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\u6307\u5b9a\u53ef\u80fd\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306f rparams \u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 -l NLOOPS, --loop NLOOPS \u6307\u5b9a\u3057\u305f\u56de\u6570\u3060\u3051\u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro test -o out.npy --weight kernel \"shape=3x3x128x128\" --weight bias \"shape=128\" --params '{\"padding\": \"valid\", \"stride\": 2}' --routine \"cpu/fast\" conv2 \"shape=1x64x64x128\" --------------------------------- Statistics --------------------------------- FUNCTION AVE(usec) MIN(usec) MAX(usec) #CALL Dnn_forward() 2,348 2,348 2,348 1 Used memory: 9,924,608 Bytes","title":"\u30ec\u30a4\u30e4\u30fb\u30eb\u30fc\u30c1\u30f3\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/layer-routine/layer-routine.ja.html#_1","text":"SoftNeuro\u306e\u30ec\u30a4\u30e4\u30fb\u30eb\u30fc\u30c1\u30f3\u306b\u5bfe\u3059\u308b\u64cd\u4f5c\u3092\u884c\u3046\u305f\u3081\u306e\u30b3\u30de\u30f3\u30c9\u306e\u64cd\u4f5c\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 GPU\u306a\u3069\u3092\u542b\u3081\u305f\u30de\u30eb\u30c1\u30d0\u30c3\u30af\u30a8\u30f3\u30c9\u74b0\u5883\u306b\u304a\u3044\u3066\u3001\u5229\u7528\u53ef\u80fd\u306a\u30c7\u30d0\u30a4\u30b9\u3001\u30ec\u30a4\u30e4\u3001\u30eb\u30fc\u30c1\u30f3\u306e\u78ba\u8a8d\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002","title":"\u30ec\u30a4\u30e4\u30fb\u30eb\u30fc\u30c1\u30f3\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/layer-routine/layer-routine.ja.html#plugins","text":"\u8ffd\u52a0\u30eb\u30fc\u30c1\u30f3\u3092\u5229\u7528\u3059\u308b\u305f\u3081\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u7ba1\u7406\u3092\u884c\u3044\u307e\u3059\u3002 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4e00\u89a7\u8868\u793a\u3001\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30fb\u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3001\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u306e\u4e00\u89a7\u306e\u8868\u793a\u306a\u3069\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 softneuro plugins [--help] [-i PLUGIN] [-u PLUGIN] [-s] \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 -i, --install PLUGIN PLUGIN \u3067\u6307\u5b9a\u3057\u305f\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 auto \u3068\u6307\u5b9a\u3059\u308b\u3068\u9069\u5207\u306a\u3082\u306e\u3092\u5168\u3066\u81ea\u52d5\u7684\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 -u, --uninstall PLUGIN PLUGIN \u3067\u6307\u5b9a\u3057\u305f\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 all \u3068\u6307\u5b9a\u3059\u308b\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e\u5168\u3066\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u30a2\u30f3\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 -s, --status \u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u3068\u305d\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u72b6\u6cc1\u3092\u4e00\u89a7\u8868\u793a\u3057\u307e\u3059\u3002\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u72b6\u6cc1\u306e\u51e1\u4f8b\u306f\u4e0b\u8a18\u306e\u8868\u306e\u3068\u304a\u308a\u3067\u3059\u3002 \u30b7\u30f3\u30dc\u30eb \u72b6\u614b I \u6b63\u5e38\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306a\u72b6\u614b C \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u3060\u304c\u4e21\u7acb\u3067\u304d\u306a\u3044\u4ed6\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u304c\u5b58\u5728\u3059\u308b\u72b6\u614b ? \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u3060\u304c\u6b63\u5e38\u306b\u5b9f\u884c\u3067\u304d\u306a\u3044\u53ef\u80fd\u6027\u304c\u3042\u308b\u72b6\u614b \u306a\u3057 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u3066\u3044\u306a\u3044\u72b6\u614b \u4f7f\u7528\u4f8b \u30aa\u30d7\u30b7\u30e7\u30f3\u7121\u3057\u3067\u5b9f\u884c\u3059\u308b\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e\u30d7\u30e9\u30b0\u30a4\u30f3\u304c\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 $ softneuro plugins plugin_avx2 AVX routines. plugin_opencl OpenCL routines. \u6b21\u306b\u4ed6\u306b\u5229\u7528\u53ef\u80fd\u306a\u30d7\u30e9\u30b0\u30a4\u30f3\u304c\u306a\u3044\u304b\u78ba\u8a8d\u3057\u307e\u3059\u3002\u4e0b\u306e\u4f8b\u3067\u306f\u3001 plugin_cuda \u304c\u5229\u7528\u53ef\u80fd\u3067\u3059\u3002 $ softneuro plugins -s I plugin_avx2 I plugin_opencl plugin_cuda -i \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3057\u3066\u3001 plugin_cuda \u30d7\u30e9\u30b0\u30a4\u30f3\u3092\u8ffd\u52a0\u3067\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u307e\u3059\u3002 $ softneuro plugin -i plugin_cuda `plugin_cuda` is installed.","title":"plugins"},{"location":"commands/layer-routine/layer-routine.ja.html#layers","text":"\u5229\u7528\u53ef\u80fd\u306a\u30ec\u30a4\u30e4\u30fc\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro layers [--help] \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro layers adaptive_unit_scale add ave_pool2 batch_norm box_filter :","title":"layers"},{"location":"commands/layer-routine/layer-routine.ja.html#lparams","text":"\u30ec\u30a4\u30e4\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u3068\u305d\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306e\u4e00\u89a7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro lparams [--help] LAYER \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30ec\u30a4\u30e4\u30fc\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro lparams conv2 {'padding': 'valid', 'pads': 0, 'dilations': 1, 'strides': 1, 'has_relu': false, 'relu_max_value': -1.0}","title":"lparams"},{"location":"commands/layer-routine/layer-routine.ja.html#routines","text":"\u5b9f\u884c\u74b0\u5883\u3067\u5b9f\u884c\u53ef\u80fd\u306a\u30b9\u30ad\u30fc\u30de\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u5b9f\u884c\u74b0\u5883\u3067\u5b9f\u884c\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro routines [--help] LAYER \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u5b9f\u884c\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30ec\u30a4\u30e4\u30fc\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001\u30b9\u30ad\u30fc\u30de\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro routines conv2 cpu/naive cpu/naive/wg2 cpu:chf/naive cpu:qint8:pt_sym/naive cpu:qint8:pt_asym/naive cpu:qint8:pc_sym/naive cpu:qint8:pc_asym/naive cpu:qint8/naive cpu/wg2 :","title":"routines"},{"location":"commands/layer-routine/layer-routine.ja.html#rparams","text":"\u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3068\u305d\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u306e\u4e00\u89a7(\u30ec\u30b7\u30d4)\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro rparams [--help] LAYER ROUTINE \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30eb\u30fc\u30c1\u30f3\u3092\u6301\u3064\u30ec\u30a4\u30e4\u30fc\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 ROUTINE \u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4e00\u89a7\u3092\u8868\u793a\u3059\u308b\u30eb\u30fc\u30c1\u30f3\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro rparams conv2 cpu/wg3x3_nxn_avx {'cache': [8192, 16384, 32768], 'task_unit': [4, 8, 16], 'tile_size': [2, 4, 6, 8]}","title":"rparams"},{"location":"commands/layer-routine/layer-routine.ja.html#test","text":"\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306e\u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro test [-o OUTPUT]... [--weight WNAME TENSOR]...[--thread NTHREADS] [--affinity MASK[@IDS]] [--params PARAMS][--routine ROUTINE] [--rparams RPARAMS] [--loop NLOOPS] [--help] LAYER [INPUT]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 LAYER \u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u5b9f\u884c\u3059\u308b\u30ec\u30a4\u30e4\u3002 INPUT \u5165\u529b\u3068\u306a\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306f tensor specification \u3067\u3059\u3002\u672a\u6307\u5b9a\u6642\u306f[-1, 1]\u306e\u4e71\u6570\u304c\u5165\u529b\u3068\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -o OUTPUT, --output OUTPUT \u7d50\u679c\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 --weight WNAME TENSOR WNAME \u3067\u6307\u5b9a\u3057\u305f\u30a6\u30a8\u30a4\u30c8\u306b TENSOR \u3092\u8a2d\u5b9a\u3057\u3066\u5b9f\u884c\u3057\u307e\u3059\u3002\u30c6\u30f3\u30bd\u30eb\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306f tensor specification \u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\u672a\u6307\u5b9a\u6642\u306f[-1, 1]\u306e\u4e71\u6570\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002\u3000 --thread NTHREADS \u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 \u6307\u5b9a\u306e\u306a\u3044\u5834\u5408\u306fCPU\u306e\u30b3\u30a2\u6570\u3068\u540c\u3058\u6570\u306b\u306a\u308a\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --params PARAMS \u30ec\u30a4\u30e4\u30d1\u30e9\u30e1\u30fc\u30bf\u3092JSON\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\u30d1\u30e9\u30e1\u30fc\u30bf\u306f lparams \u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 -r ROUTINE, --routine ROUTINE \u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3057\u3066\u5b9f\u884c\u3057\u307e\u3059\u3002 \u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f cpu \u3068\u306a\u308a\u307e\u3059\u3002\u5b9f\u884c\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306f routines \u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 --rparams RPARAMS \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3092JSON\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002\u6307\u5b9a\u53ef\u80fd\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306f rparams \u30b3\u30de\u30f3\u30c9\u3067\u78ba\u8a8d\u3067\u304d\u307e\u3059\u3002 -l NLOOPS, --loop NLOOPS \u6307\u5b9a\u3057\u305f\u56de\u6570\u3060\u3051\u52d5\u4f5c\u30c6\u30b9\u30c8\u3092\u7e70\u308a\u8fd4\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro test -o out.npy --weight kernel \"shape=3x3x128x128\" --weight bias \"shape=128\" --params '{\"padding\": \"valid\", \"stride\": 2}' --routine \"cpu/fast\" conv2 \"shape=1x64x64x128\" --------------------------------- Statistics --------------------------------- FUNCTION AVE(usec) MIN(usec) MAX(usec) #CALL Dnn_forward() 2,348 2,348 2,348 1 Used memory: 9,924,608 Bytes","title":"test"},{"location":"commands/layer-routine/layer-routine.html","text":"Layer/Routine Operation Commands \u00b6 Layer and routine related SoftNeuro commands. It is possible to verify routine information per layer, such as available devices and parameters. plugins \u00b6 Manages plugins for additional routines. User can view the list of installed plugins, install/uninstall plugins, and view the list of all avalable plugins with their status. Usage softneuro plugins [--help] [-i PLUGIN|auto] [-u PLUGIN|all] [-s] Flags Flag Description -h, --help Shows the command help. -i, --install PLUGIN Installs a plugin PLUGIN . If auto is provieded, it installs all appropriate plugins automatically. -u, --uninstall PLUGIN Uninstall a plugin PLUGIN . If all is provided, it uninstalls all plugins. -s, --status Lists available plugins and their status. The meaning of staus symbols is shown below. Symbol Status I Installed successfully C Installed but conflicted with other plugins ? Installed but may not be loaded on run time (space) Not installed Example Running without any options, you can view the installed plugins. $ softneuro plugins plugin_avx2 AVX routines. plugin_opencl OpenCL routines. You may check if other plugins are available. The following result shows plugin_cuda is avalable. $ softneuro plugins -s I plugin_avx2 I plugin_opencl plugin_cuda Then you can install plugin_cuda by the following command. $ softneuro plugin -i plugin_cuda `plugin_cuda` is installed. layers \u00b6 List all available layers. Usage usage: softneuro layers [--help] Flags Flag Description -h, --help Shows the command help. Example $ softneuro layers adaptive_unit_scale add ave_pool2 batch_norm box_filter : lparams \u00b6 Shows the available paramters and their default values for a given layer. Usage usage: softneuro lparams [--help] LAYER Arguments Argument Description LAYER Layer to have its parameters shown. Flags Flag Description -h, --help Shows the command help. Example $ softneuro lparams conv2 {'padding': 'valid', 'pads': 0, 'dilations': 1, 'strides': 1, 'has_relu': false, 'relu_max_value': -1.0} routines \u00b6 Shows the available execution routines in the current environment. Shows the available execution schemas in the current environment. Usage usage: softneuro routines [--help] LAYER Arguments Argument Description LAYER Layer to have its routines shown. Shows schemas when no layer was set. Flags Flag Description -h, --help Shows the command help. Example $ softneuro routines conv2 cpu/naive cpu/naive/wg2 cpu:chf/naive cpu:qint8:pt_sym/naive cpu:qint8:pt_asym/naive cpu:qint8:pc_sym/naive cpu:qint8:pc_asym/naive cpu:qint8/naive cpu/wg2 : rparams \u00b6 Show a recipe for routine parameters. Usage usage: softneuro rparams [--help] LAYER Arguments Argument Description LAYER Layer that has the routine for which parameters will be shown. ROUTINE Routine to have its parameters shown. Flags Flag Description -h, --help Shows the command help. Example $ softneuro rparams conv2 cpu/wg3x3_nxn_avx {'cache': [8192, 16384, 32768], 'task_unit': [4, 8, 16], 'tile_size': [2, 4, 6, 8]} test \u00b6 Does a test run of the given layer. Usage usage: softneuro test [-o OUTPUT]... [--weight WNAME TENSOR]...[--thread NTHREADS] [--affinity MASK[@IDS]] [--params PARAMS][--routine ROUTINE] [--rparams RPARAMS] [--loop NLOOPS] [--help] LAYER [INPUT]... Arguments Argument Description LAYER Layer to be tested. INPUT Input numpy file or tensor specification . Flags Flag Description -o OUTPUT, --output OUTPUT Filename for the output numpy file. Must be set. --weight WNAME TENSOR Insert TENSOR data into the WNAME weight tensor. TENSOR can be a numpy file or tensor specification . If weights aren't set they are initialized to random numbers in [-1, 1]. --thread NTHREADS How many threads to be used on execution. Defaults to the amount of CPU cores. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. --params PARAMS Layer parameters in JSON format. Parameters can be checked with the lparams command. -r ROUTINE, --routine ROUTINE Set the routine to be executed. Available routines can be checked with the routines command. Defaults to the best available. --rparams RPARAMS Routine parameters in JSON format. Parameters can be cheked with the rparams command. -l NLOOPS, --loop NLOOPS Amount of times to run the test. Useful for benchmarking. -h, --help Shows the command help. Example $ softneuro test -o out.npy --weight kernel \"shape=3x3x128x128\" --weight bias \"shape=128\" --params '{\"padding\": \"valid\", \"stride\": 2}' --routine \"cpu/fast\" conv2 \"shape=1x64x64x128\" --------------------------------- Statistics --------------------------------- FUNCTION AVE(usec) MIN(usec) MAX(usec) #CALL Dnn_forward() 2,348 2,348 2,348 1 Used memory: 9,924,608 Bytes","title":"Layer/Routine Operation Commands"},{"location":"commands/layer-routine/layer-routine.html#layerroutine-operation-commands","text":"Layer and routine related SoftNeuro commands. It is possible to verify routine information per layer, such as available devices and parameters.","title":"Layer/Routine Operation Commands"},{"location":"commands/layer-routine/layer-routine.html#plugins","text":"Manages plugins for additional routines. User can view the list of installed plugins, install/uninstall plugins, and view the list of all avalable plugins with their status. Usage softneuro plugins [--help] [-i PLUGIN|auto] [-u PLUGIN|all] [-s] Flags Flag Description -h, --help Shows the command help. -i, --install PLUGIN Installs a plugin PLUGIN . If auto is provieded, it installs all appropriate plugins automatically. -u, --uninstall PLUGIN Uninstall a plugin PLUGIN . If all is provided, it uninstalls all plugins. -s, --status Lists available plugins and their status. The meaning of staus symbols is shown below. Symbol Status I Installed successfully C Installed but conflicted with other plugins ? Installed but may not be loaded on run time (space) Not installed Example Running without any options, you can view the installed plugins. $ softneuro plugins plugin_avx2 AVX routines. plugin_opencl OpenCL routines. You may check if other plugins are available. The following result shows plugin_cuda is avalable. $ softneuro plugins -s I plugin_avx2 I plugin_opencl plugin_cuda Then you can install plugin_cuda by the following command. $ softneuro plugin -i plugin_cuda `plugin_cuda` is installed.","title":"plugins"},{"location":"commands/layer-routine/layer-routine.html#layers","text":"List all available layers. Usage usage: softneuro layers [--help] Flags Flag Description -h, --help Shows the command help. Example $ softneuro layers adaptive_unit_scale add ave_pool2 batch_norm box_filter :","title":"layers"},{"location":"commands/layer-routine/layer-routine.html#lparams","text":"Shows the available paramters and their default values for a given layer. Usage usage: softneuro lparams [--help] LAYER Arguments Argument Description LAYER Layer to have its parameters shown. Flags Flag Description -h, --help Shows the command help. Example $ softneuro lparams conv2 {'padding': 'valid', 'pads': 0, 'dilations': 1, 'strides': 1, 'has_relu': false, 'relu_max_value': -1.0}","title":"lparams"},{"location":"commands/layer-routine/layer-routine.html#routines","text":"Shows the available execution routines in the current environment. Shows the available execution schemas in the current environment. Usage usage: softneuro routines [--help] LAYER Arguments Argument Description LAYER Layer to have its routines shown. Shows schemas when no layer was set. Flags Flag Description -h, --help Shows the command help. Example $ softneuro routines conv2 cpu/naive cpu/naive/wg2 cpu:chf/naive cpu:qint8:pt_sym/naive cpu:qint8:pt_asym/naive cpu:qint8:pc_sym/naive cpu:qint8:pc_asym/naive cpu:qint8/naive cpu/wg2 :","title":"routines"},{"location":"commands/layer-routine/layer-routine.html#rparams","text":"Show a recipe for routine parameters. Usage usage: softneuro rparams [--help] LAYER Arguments Argument Description LAYER Layer that has the routine for which parameters will be shown. ROUTINE Routine to have its parameters shown. Flags Flag Description -h, --help Shows the command help. Example $ softneuro rparams conv2 cpu/wg3x3_nxn_avx {'cache': [8192, 16384, 32768], 'task_unit': [4, 8, 16], 'tile_size': [2, 4, 6, 8]}","title":"rparams"},{"location":"commands/layer-routine/layer-routine.html#test","text":"Does a test run of the given layer. Usage usage: softneuro test [-o OUTPUT]... [--weight WNAME TENSOR]...[--thread NTHREADS] [--affinity MASK[@IDS]] [--params PARAMS][--routine ROUTINE] [--rparams RPARAMS] [--loop NLOOPS] [--help] LAYER [INPUT]... Arguments Argument Description LAYER Layer to be tested. INPUT Input numpy file or tensor specification . Flags Flag Description -o OUTPUT, --output OUTPUT Filename for the output numpy file. Must be set. --weight WNAME TENSOR Insert TENSOR data into the WNAME weight tensor. TENSOR can be a numpy file or tensor specification . If weights aren't set they are initialized to random numbers in [-1, 1]. --thread NTHREADS How many threads to be used on execution. Defaults to the amount of CPU cores. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. --params PARAMS Layer parameters in JSON format. Parameters can be checked with the lparams command. -r ROUTINE, --routine ROUTINE Set the routine to be executed. Available routines can be checked with the routines command. Defaults to the best available. --rparams RPARAMS Routine parameters in JSON format. Parameters can be cheked with the rparams command. -l NLOOPS, --loop NLOOPS Amount of times to run the test. Useful for benchmarking. -h, --help Shows the command help. Example $ softneuro test -o out.npy --weight kernel \"shape=3x3x128x128\" --weight bias \"shape=128\" --params '{\"padding\": \"valid\", \"stride\": 2}' --routine \"cpu/fast\" conv2 \"shape=1x64x64x128\" --------------------------------- Statistics --------------------------------- FUNCTION AVE(usec) MIN(usec) MAX(usec) #CALL Dnn_forward() 2,348 2,348 2,348 1 Used memory: 9,924,608 Bytes","title":"test"},{"location":"commands/numpy/numpy.ja.html","text":"numpy\u30c6\u30f3\u30bd\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9 \u00b6 softneuro\u306e\u5165\u529b\u3068\u3057\u3066\u5229\u7528\u53ef\u80fd\u306anumpy\u30c6\u30f3\u30bd\u30eb\u306e\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002 Tensor Specification \u00b6 numpy\u30c6\u30f3\u30bd\u30eb\u306e\u6307\u5b9a\u5f62\u5f0f\u3067\u3042\u308bTensor Specification\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\u3002 Tensor Specification\u306f\u30ab\u30f3\u30de\u3067\u9023\u7d50\u3055\u308c\u305f\u30ad\u30fc\u30fb\u30d0\u30ea\u30e5\u30fc\u30da\u30a2\u3067\u3059\u3002\u4f8b\uff1a 'key1=val1,key2=val2,...' \u6307\u5b9a\u53ef\u80fd\u30ad\u30fc \u30ad\u30fc\u540d \u5185\u5bb9 shape \u30c6\u30f3\u30bd\u30eb\u306e\u30b7\u30a7\u30a4\u30d7\u3067\u3059\u3002 x \u3067\u9023\u7d50\u3055\u308c\u305f\u6574\u6570\u5024\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002(\u4f8b\uff1a 1x224x224x3 ) dtype \u30c6\u30f3\u30bd\u30eb\u306e\u30c7\u30fc\u30bf\u30bf\u30a4\u30d7\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f float32 \u3067\u3059\u3002 val \u30c6\u30f3\u30bd\u30eb\u306e\u8981\u7d20\u5024\u3067\u3059\u3002\u5b9a\u6570\u307e\u305f\u306f\u3042\u308b\u7bc4\u56f2\u306e\u4e71\u6570\u5024\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002\u4e71\u6570\u5024\u306e\u7bc4\u56f2\u306f .. \u3067\u9023\u7d50\u3055\u308c\u305f2\u3064\u306e\u6570\u5024\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002(\u4f8b\uff1a 0.0..1.0 ) \u4f7f\u7528\u4f8b 1x128x128x16 \u306e\u30b7\u30a7\u30a4\u30d7\u3001 float32 \u306e\u30c7\u30fc\u30bf\u30bf\u30a4\u30d7\u3001\u8981\u7d20\u304c-1.0\u304b\u30891.0\u306e\u4e71\u6570\u5024\u306e\u30c6\u30f3\u30bd\u30eb\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 shape=1x128x128x16,val=-1.0..1.0 \u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30d8\u30eb\u30d7\u3082\u53c2\u7167\u53ef\u80fd\u3067\u3059\u3002 $ softneuro help tensor_spec usage: shape=SHAPE[,dtype=DTYPE][,val=VAL] The tensor specification. [REQUIRED] SHAPE a shape of tensor. It is given as numbers concatenated by 'x' (e.g. 1x224x224x3). [OPTIONS] DTYPE a data type. The default is 'float32'. VAL element values. It is given as a number for constant values (e.g. 0.5) or two numbers concatenated by '..' for random values between a range (e.g. 0.0..1.0). The default is '-1..1'. [EXAMPLE] shape=1x128x128x16,val=-0.5..2 represetns a tensor whose shape is 1x128x128x16, data type is 'float32' and elements have random value from -0.5 to 2. mknpy \u00b6 \u30c6\u30f3\u30bd\u30eb\u3092\u4f5c\u6210\u3057numpy\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro mknpy [--help] SPEC ONPY \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 SPEC \u4f5c\u6210\u3059\u308b\u30c6\u30f3\u30bd\u30eb\u306e Tensor Specification \u3067\u3059\u3002 ONPY \u51fa\u529b\u3055\u308c\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306btensor.npy\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro mknpy \"shape=128x128x16,val=-1.0..1.0\" tensor.npy attrnpy \u00b6 \u30c6\u30f3\u30bd\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u5c5e\u6027\u60c5\u5831\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002 NAME : \u30d5\u30a1\u30a4\u30eb\u540d DTYPE : \u30c7\u30fc\u30bf\u30bf\u30a4\u30d7 SHAPE : \u30b7\u30a7\u30a4\u30d7 RANGE : \u8981\u7d20\u5024\u306e\u7bc4\u56f2 AVERAGE : \u5e73\u5747\u5024 STDEV : \u6a19\u6e96\u504f\u5dee \u4f7f\u3044\u65b9 usage: softneuro attrnpy [--help] NPY... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 NPY \u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro attrnpy tensor.npy NAME DTYPE SHAPE RANGE AVERAGE STDEV tensor.npy float32 128x128x16 -0.999991:0.999995 0.00036936 0.576519 viewnpy \u00b6 numpy\u30c6\u30f3\u30bd\u30eb\u306e\u5024\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro viewnpy [--from INDICES] [--cols COLS] [--help] NPY \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 NPY \u51fa\u529bnumpy\u30d5\u30a1\u30a4\u30eb\u540d\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --from INDICES INDICES \u3067\u6307\u5b9a\u3055\u308c\u305f\u4f4d\u7f6e\u306e\u5024\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --cols COLS \u8868\u793a\u306e\u969b\u306e\u5217\u6570\u3092 COLS \u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro viewnpy --from \"127,127,10\" tensor.npy (127,127,10) -0.459925, -0.40616, (127,127,12) 0.89318, -0.275693, -0.337535, 0.115791] cmpnpy \u00b6 2\u3064\u306enumpy\u30c6\u30f3\u30bd\u30eb\u306e\u5024\u3092\u6bd4\u8f03\u3057\u3001S/N\u6bd4(db)\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u76ee\u5b89\u3068\u3057\u3066\u306f100db\u4ee5\u4e0a\u3067\u4e00\u81f4\u300160db\u4ee5\u4e0a\u3067\u307b\u307c\u4e00\u81f4\u300120db\u4ee5\u4e0a\u3067\u6982\u306d\u4e00\u81f4\u3001\u305d\u308c\u672a\u6e80\u306f\u4e0d\u4e00\u81f4\u3068\u306a\u308a\u307e\u3059\u3002 \u4e21\u65b9\u306e\u5165\u529b\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u3001\u4e21\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u542b\u307e\u308c\u308b\u540c\u540d\u306enumpy\u540c\u58eb\u3092\u6bd4\u8f03\u3067\u304d\u307e\u3059\u3002 \u3053\u306e\u6a5f\u80fd\u306f run \u30b3\u30de\u30f3\u30c9\u3067 --dump \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3059\u308b\u306a\u3069\u3057\u305f\u5834\u5408\u306b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u4e2d\u9593\u51fa\u529b\u304c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4fdd\u5b58\u3055\u308c\u308b\u306e\u3067\u3001 \u305d\u306e\u7d50\u679c\u540c\u58eb\u3092\u6bd4\u8f03\u3059\u308b\u5834\u5408\u306a\u3069\u306b\u5229\u7528\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro cmpnpy [--axis A] [--help] TRUENPY TGTNPY \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 TRUENPY \u771f\u5024\u306enumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u7fa4\u3092\u542b\u3080\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3002 TGTNPY \u6bd4\u8f03\u5bfe\u8c61\u3068\u306a\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u7fa4\u3092\u542b\u3080\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --axis A \u6bd4\u8f03\u3092\u884c\u3046numpy\u30c6\u30f3\u30bd\u30eb\u306e\u8ef8\u3092 A \u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3002 \u4f7f\u7528\u4f8b $ softneuro cmpnpy tensor.npy tensor2.npy SNR(db) PSNR(db) MIN:MAX > 200 > 200 -1:1","title":"numpy\u30c6\u30f3\u30bd\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/numpy/numpy.ja.html#numpy","text":"softneuro\u306e\u5165\u529b\u3068\u3057\u3066\u5229\u7528\u53ef\u80fd\u306anumpy\u30c6\u30f3\u30bd\u30eb\u306e\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002","title":"numpy\u30c6\u30f3\u30bd\u30eb\u64cd\u4f5c\u30b3\u30de\u30f3\u30c9"},{"location":"commands/numpy/numpy.ja.html#tensor-specification","text":"numpy\u30c6\u30f3\u30bd\u30eb\u306e\u6307\u5b9a\u5f62\u5f0f\u3067\u3042\u308bTensor Specification\u306b\u3064\u3044\u3066\u89e3\u8aac\u3057\u307e\u3059\u3002 Tensor Specification\u306f\u30ab\u30f3\u30de\u3067\u9023\u7d50\u3055\u308c\u305f\u30ad\u30fc\u30fb\u30d0\u30ea\u30e5\u30fc\u30da\u30a2\u3067\u3059\u3002\u4f8b\uff1a 'key1=val1,key2=val2,...' \u6307\u5b9a\u53ef\u80fd\u30ad\u30fc \u30ad\u30fc\u540d \u5185\u5bb9 shape \u30c6\u30f3\u30bd\u30eb\u306e\u30b7\u30a7\u30a4\u30d7\u3067\u3059\u3002 x \u3067\u9023\u7d50\u3055\u308c\u305f\u6574\u6570\u5024\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002(\u4f8b\uff1a 1x224x224x3 ) dtype \u30c6\u30f3\u30bd\u30eb\u306e\u30c7\u30fc\u30bf\u30bf\u30a4\u30d7\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f float32 \u3067\u3059\u3002 val \u30c6\u30f3\u30bd\u30eb\u306e\u8981\u7d20\u5024\u3067\u3059\u3002\u5b9a\u6570\u307e\u305f\u306f\u3042\u308b\u7bc4\u56f2\u306e\u4e71\u6570\u5024\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002\u4e71\u6570\u5024\u306e\u7bc4\u56f2\u306f .. \u3067\u9023\u7d50\u3055\u308c\u305f2\u3064\u306e\u6570\u5024\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002(\u4f8b\uff1a 0.0..1.0 ) \u4f7f\u7528\u4f8b 1x128x128x16 \u306e\u30b7\u30a7\u30a4\u30d7\u3001 float32 \u306e\u30c7\u30fc\u30bf\u30bf\u30a4\u30d7\u3001\u8981\u7d20\u304c-1.0\u304b\u30891.0\u306e\u4e71\u6570\u5024\u306e\u30c6\u30f3\u30bd\u30eb\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 shape=1x128x128x16,val=-1.0..1.0 \u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30d8\u30eb\u30d7\u3082\u53c2\u7167\u53ef\u80fd\u3067\u3059\u3002 $ softneuro help tensor_spec usage: shape=SHAPE[,dtype=DTYPE][,val=VAL] The tensor specification. [REQUIRED] SHAPE a shape of tensor. It is given as numbers concatenated by 'x' (e.g. 1x224x224x3). [OPTIONS] DTYPE a data type. The default is 'float32'. VAL element values. It is given as a number for constant values (e.g. 0.5) or two numbers concatenated by '..' for random values between a range (e.g. 0.0..1.0). The default is '-1..1'. [EXAMPLE] shape=1x128x128x16,val=-0.5..2 represetns a tensor whose shape is 1x128x128x16, data type is 'float32' and elements have random value from -0.5 to 2.","title":"Tensor Specification"},{"location":"commands/numpy/numpy.ja.html#mknpy","text":"\u30c6\u30f3\u30bd\u30eb\u3092\u4f5c\u6210\u3057numpy\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro mknpy [--help] SPEC ONPY \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 SPEC \u4f5c\u6210\u3059\u308b\u30c6\u30f3\u30bd\u30eb\u306e Tensor Specification \u3067\u3059\u3002 ONPY \u51fa\u529b\u3055\u308c\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306btensor.npy\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro mknpy \"shape=128x128x16,val=-1.0..1.0\" tensor.npy","title":"mknpy"},{"location":"commands/numpy/numpy.ja.html#attrnpy","text":"\u30c6\u30f3\u30bd\u30eb\u306e\u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u5c5e\u6027\u60c5\u5831\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002 NAME : \u30d5\u30a1\u30a4\u30eb\u540d DTYPE : \u30c7\u30fc\u30bf\u30bf\u30a4\u30d7 SHAPE : \u30b7\u30a7\u30a4\u30d7 RANGE : \u8981\u7d20\u5024\u306e\u7bc4\u56f2 AVERAGE : \u5e73\u5747\u5024 STDEV : \u6a19\u6e96\u504f\u5dee \u4f7f\u3044\u65b9 usage: softneuro attrnpy [--help] NPY... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 NPY \u5c5e\u6027\u60c5\u5831\u3092\u8868\u793a\u3059\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro attrnpy tensor.npy NAME DTYPE SHAPE RANGE AVERAGE STDEV tensor.npy float32 128x128x16 -0.999991:0.999995 0.00036936 0.576519","title":"attrnpy"},{"location":"commands/numpy/numpy.ja.html#viewnpy","text":"numpy\u30c6\u30f3\u30bd\u30eb\u306e\u5024\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro viewnpy [--from INDICES] [--cols COLS] [--help] NPY \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 NPY \u51fa\u529bnumpy\u30d5\u30a1\u30a4\u30eb\u540d\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --from INDICES INDICES \u3067\u6307\u5b9a\u3055\u308c\u305f\u4f4d\u7f6e\u306e\u5024\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --cols COLS \u8868\u793a\u306e\u969b\u306e\u5217\u6570\u3092 COLS \u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro viewnpy --from \"127,127,10\" tensor.npy (127,127,10) -0.459925, -0.40616, (127,127,12) 0.89318, -0.275693, -0.337535, 0.115791]","title":"viewnpy"},{"location":"commands/numpy/numpy.ja.html#cmpnpy","text":"2\u3064\u306enumpy\u30c6\u30f3\u30bd\u30eb\u306e\u5024\u3092\u6bd4\u8f03\u3057\u3001S/N\u6bd4(db)\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u76ee\u5b89\u3068\u3057\u3066\u306f100db\u4ee5\u4e0a\u3067\u4e00\u81f4\u300160db\u4ee5\u4e0a\u3067\u307b\u307c\u4e00\u81f4\u300120db\u4ee5\u4e0a\u3067\u6982\u306d\u4e00\u81f4\u3001\u305d\u308c\u672a\u6e80\u306f\u4e0d\u4e00\u81f4\u3068\u306a\u308a\u307e\u3059\u3002 \u4e21\u65b9\u306e\u5165\u529b\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u6307\u5b9a\u3059\u308b\u3053\u3068\u3067\u3001\u4e21\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u542b\u307e\u308c\u308b\u540c\u540d\u306enumpy\u540c\u58eb\u3092\u6bd4\u8f03\u3067\u304d\u307e\u3059\u3002 \u3053\u306e\u6a5f\u80fd\u306f run \u30b3\u30de\u30f3\u30c9\u3067 --dump \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3059\u308b\u306a\u3069\u3057\u305f\u5834\u5408\u306b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u4e2d\u9593\u51fa\u529b\u304c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u4fdd\u5b58\u3055\u308c\u308b\u306e\u3067\u3001 \u305d\u306e\u7d50\u679c\u540c\u58eb\u3092\u6bd4\u8f03\u3059\u308b\u5834\u5408\u306a\u3069\u306b\u5229\u7528\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro cmpnpy [--axis A] [--help] TRUENPY TGTNPY \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 TRUENPY \u771f\u5024\u306enumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u7fa4\u3092\u542b\u3080\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3002 TGTNPY \u6bd4\u8f03\u5bfe\u8c61\u3068\u306a\u308bnumpy\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u7fa4\u3092\u542b\u3080\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --axis A \u6bd4\u8f03\u3092\u884c\u3046numpy\u30c6\u30f3\u30bd\u30eb\u306e\u8ef8\u3092 A \u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3002 \u4f7f\u7528\u4f8b $ softneuro cmpnpy tensor.npy tensor2.npy SNR(db) PSNR(db) MIN:MAX > 200 > 200 -1:1","title":"cmpnpy"},{"location":"commands/numpy/numpy.html","text":"numpy Tensor Operation Commands \u00b6 Commands for handling numpy files formatted as tensors for snr inputs. Tensor Specification \u00b6 A numpy tensor can be specified via Tensor Specification. The Tensor Specification format is that of comma-separated key and value pairs, as in 'key1=val1,key2=val2,...' . Available keys Key Description shape Tensor shape. Dimension shapes are concatenated by x . Example: 1x224x224x3 dtype Tensor data type, defaults to float32 val Tensor initial values. Can be set to a pre-defined scalar or to random values inside a range. A range is defined by two numbers separated by .. . Example: 0.0..1.0 Example Define a tensor with 1x128x128x16 shape, of float32 type and containing random numbers from -1.0 to 1.0. shape=1x128x128x16,val=-1.0..1.0 The following help is also available. $ softneuro help tensor_spec usage: shape=SHAPE[,dtype=DTYPE][,val=VAL] The tensor specification. [REQUIRED] SHAPE a shape of tensor. It is given as numbers concatenated by 'x' (e.g. 1x224x224x3). [OPTIONS] DTYPE a data type. The default is 'float32'. VAL element values. It is given as a number for constant values (e.g. 0.5) or two numbers concatenated by '..' for random values between a range (e.g. 0.0..1.0). The default is '-1..1'. [EXAMPLE] shape=1x128x128x16,val=-0.5..2 represetns a tensor whose shape is 1x128x128x16, data type is 'float32' and elements have random value from -0.5 to 2. mknpy \u00b6 Create a tensor and save it in numpy format. Usage usage: softneuro mknpy [--help] SPEC ONPY Arguments Argument Description SPEC Tensor Specification . ONPY Output numpy file name. Flags Flag Description -h, --help Shows the command help. Example Creates a tensor.npy file containing the tensor data at the execution directory. \u203bThere's no terminal output $ softneuro mknpy \"shape=1x128x128x16,val=-1.0..1.0\" tensor.npy attrnpy \u00b6 Shows tensor attributes, as listed below. NAME : File name DTYPE : Data type SHAPE : Shape RANGE : Data range AVERAGE : Data average STDEV : Data standard deviation Usage usage: softneuro attrnpy [--help] NPY... Arguments Argument Description NPY numpy file to have its attributes shown. Flags Flag Description -h, --help Shows the command help. Example $ softneuro attrnpy tensor.npy NAME DTYPE SHAPE RANGE AVERAGE STDEV tensor.npy float32 1x128x128x16 -0.999991:0.999995 0.00036936 0.576519 viewnpy \u00b6 Shows the values from a numpy file. Usage usage: softneuro viewnpy [--from INDICES] [--cols COLS] [--help] NPY Arguments Argument Description NPY numpy file to have its values shown. Flags Flag Description --from INDICES Indices from where to start showing data. --cols COL Specify columns to be displayed. -h, --help Shows the command help. Example $ softneuro viewnpy --from \"127,127,10\" tensor.npy (127,127,10) -0.459925, -0.40616, (127,127,12) 0.89318, -0.275693, -0.337535, 0.115791] cmpnpy \u00b6 Compares two numpy files values, showing their signal-to-noise ratio in db. As a rule of thumb, 100db or more indicates a match, 60db or more indicates reasonable similarity, 20db or more indicates some similarity, less than 20db indicates not a match. Usage usage: softneuro cmpnpy [--axis A] [--help] TRUENPY TGTNPY Arguments Argument Description TRUENPY A numpy file or a directory containing numpy files which have the correct numbers. TGTNPY A numpy file or a directory containing numpy files which have the data to be compared. Flags Flag Description --axis A Which axis to be compared. -h, --help Shows the command help. Example $ softneuro cmpnpy tensor.npy tensor2.npy SNR(db) PSNR(db) MIN:MAX > 200 > 200 -1:1","title":"numpy Tensor Operation Commands"},{"location":"commands/numpy/numpy.html#numpy-tensor-operation-commands","text":"Commands for handling numpy files formatted as tensors for snr inputs.","title":"numpy Tensor Operation Commands"},{"location":"commands/numpy/numpy.html#tensor-specification","text":"A numpy tensor can be specified via Tensor Specification. The Tensor Specification format is that of comma-separated key and value pairs, as in 'key1=val1,key2=val2,...' . Available keys Key Description shape Tensor shape. Dimension shapes are concatenated by x . Example: 1x224x224x3 dtype Tensor data type, defaults to float32 val Tensor initial values. Can be set to a pre-defined scalar or to random values inside a range. A range is defined by two numbers separated by .. . Example: 0.0..1.0 Example Define a tensor with 1x128x128x16 shape, of float32 type and containing random numbers from -1.0 to 1.0. shape=1x128x128x16,val=-1.0..1.0 The following help is also available. $ softneuro help tensor_spec usage: shape=SHAPE[,dtype=DTYPE][,val=VAL] The tensor specification. [REQUIRED] SHAPE a shape of tensor. It is given as numbers concatenated by 'x' (e.g. 1x224x224x3). [OPTIONS] DTYPE a data type. The default is 'float32'. VAL element values. It is given as a number for constant values (e.g. 0.5) or two numbers concatenated by '..' for random values between a range (e.g. 0.0..1.0). The default is '-1..1'. [EXAMPLE] shape=1x128x128x16,val=-0.5..2 represetns a tensor whose shape is 1x128x128x16, data type is 'float32' and elements have random value from -0.5 to 2.","title":"Tensor Specification"},{"location":"commands/numpy/numpy.html#mknpy","text":"Create a tensor and save it in numpy format. Usage usage: softneuro mknpy [--help] SPEC ONPY Arguments Argument Description SPEC Tensor Specification . ONPY Output numpy file name. Flags Flag Description -h, --help Shows the command help. Example Creates a tensor.npy file containing the tensor data at the execution directory. \u203bThere's no terminal output $ softneuro mknpy \"shape=1x128x128x16,val=-1.0..1.0\" tensor.npy","title":"mknpy"},{"location":"commands/numpy/numpy.html#attrnpy","text":"Shows tensor attributes, as listed below. NAME : File name DTYPE : Data type SHAPE : Shape RANGE : Data range AVERAGE : Data average STDEV : Data standard deviation Usage usage: softneuro attrnpy [--help] NPY... Arguments Argument Description NPY numpy file to have its attributes shown. Flags Flag Description -h, --help Shows the command help. Example $ softneuro attrnpy tensor.npy NAME DTYPE SHAPE RANGE AVERAGE STDEV tensor.npy float32 1x128x128x16 -0.999991:0.999995 0.00036936 0.576519","title":"attrnpy"},{"location":"commands/numpy/numpy.html#viewnpy","text":"Shows the values from a numpy file. Usage usage: softneuro viewnpy [--from INDICES] [--cols COLS] [--help] NPY Arguments Argument Description NPY numpy file to have its values shown. Flags Flag Description --from INDICES Indices from where to start showing data. --cols COL Specify columns to be displayed. -h, --help Shows the command help. Example $ softneuro viewnpy --from \"127,127,10\" tensor.npy (127,127,10) -0.459925, -0.40616, (127,127,12) 0.89318, -0.275693, -0.337535, 0.115791]","title":"viewnpy"},{"location":"commands/numpy/numpy.html#cmpnpy","text":"Compares two numpy files values, showing their signal-to-noise ratio in db. As a rule of thumb, 100db or more indicates a match, 60db or more indicates reasonable similarity, 20db or more indicates some similarity, less than 20db indicates not a match. Usage usage: softneuro cmpnpy [--axis A] [--help] TRUENPY TGTNPY Arguments Argument Description TRUENPY A numpy file or a directory containing numpy files which have the correct numbers. TGTNPY A numpy file or a directory containing numpy files which have the data to be compared. Flags Flag Description --axis A Which axis to be compared. -h, --help Shows the command help. Example $ softneuro cmpnpy tensor.npy tensor2.npy SNR(db) PSNR(db) MIN:MAX > 200 > 200 -1:1","title":"cmpnpy"},{"location":"commands/prof-tune/prof-tune.ja.html","text":"\u63a8\u8ad6\u5b9f\u884c\u30fb\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30b3\u30de\u30f3\u30c9 \u00b6 run \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u3066\u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u63a8\u8ad6\u306e\u7d50\u679c\u3084\u51e6\u7406\u6642\u9593\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro run [-o ONPY]... [-p PASSWORD] [--recipe RECIPE][--batch BATCH] [--ishape SHAPE] [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE] [--thread NTHREADS] [--noboost] [--affinity MASK[@THREAD_INDICES]] [-r ROUTINE[@LAYER_INDICES]] [-R RPARAMS[@LAYER_INDICES]] [-nobufopt DEVICE] [--lib LIB] [-l LNUM] [--detail] [--detail2] [--bylayer] [-dump DUMPDIR] [-dump2 DUMPRID] [-t NTOPS] [-h] DNN [INPUT [INPUT ...]] \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 INPUT \u63a8\u8ad6\u5b9f\u884c\u306e\u5165\u529b\u3068\u306a\u308b\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u672a\u6307\u5b9a\u6642\u306f[-1, 1]\u306e\u4e71\u6570\u304c\u5165\u529b\u3068\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -p PASSWORD --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002 -o ONPY \u7d50\u679c\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 --recipe RECIPE \u5229\u7528\u3059\u308brecipe\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u3000 --batch BATCH \u5165\u529b\u3092\u6307\u5b9a\u3057\u305f\u30b5\u30a4\u30ba\u306e\u30d0\u30c3\u30c1\u306b\u3057\u3066\u63a8\u8ad6\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 --ishape SHAPE \u5165\u529b\u30b7\u30a7\u30a4\u30d7\u3092\u6307\u5b9a\u3057\u305f\u3082\u306e\u306b\u5909\u66f4\u3057\u307e\u3059\u3002(\u4f8b\uff1a 1x224x224x3 ). --keep_img_ar PADDINGCOLOR \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306b\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3055\u305b\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3057\u307e\u305b\u3093\u3002\u30ea\u30b5\u30a4\u30ba\u524d\u5f8c\u3067\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u306e\u9055\u3044\u306b\u3088\u3063\u3066\u751f\u3058\u308b\u30b9\u30da\u30fc\u30b9\u3092\u3001PADDINGCOLOR\u3067\u6307\u5b9a\u3057\u305f\u8272\u3067\u57cb\u3081\u307e\u3059\u3002PADDINGCOLOR\u306f\u4f8b\u3048\u3070 '0, 0, 0' \u306e\u3088\u3046\u306bRGB\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002 --img_resize_mode RESIZEMODE \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306e\u65b9\u5f0f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 'bilinear' \u307e\u305f\u306f\u3000'nearest' \u3092\u6307\u5b9a\u53ef\u80fd\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f 'bilinear' \u3067\u3059\u3002 --thread NTHREADS \u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 \u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u306fCPU\u306e\u30b3\u30a2\u6570\u3068\u306a\u308a\u307e\u3059\u3002 --noboost \u30ef\u30fc\u30ab\u30fc\u30b9\u30ec\u30c3\u30c9\u304c\u30bf\u30b9\u30af\u5f85\u3061\u3092\u3059\u308b\u3068\u304d\u306b cond wait \u3092\u7528\u3044\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f busy wait \u3092\u7528\u3044\u307e\u3059\u3002 --noboost \u304c\u6709\u52b9\u306e\u5834\u5408\u3001SoftNeuro\u306eCPU\u5360\u6709\u7387\u304c\u4e0b\u304c\u308a\u4ed6\u30d7\u30ed\u30bb\u30b9\u304c\u5f71\u97ff\u3055\u308c\u306b\u304f\u304f\u306a\u308a\u307e\u3059\u304c\u3001\u63a8\u8ad6\u901f\u5ea6\u304c\u4f4e\u4e0b\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 MASK \u306f\u30ea\u30c8\u30eb\u30a8\u30f3\u30c7\u30a3\u30a2\u30f3\u306e16\u9032\u6570 (0x..), 2\u9032\u6570 (0b..), \u307e\u305f\u306f10\u9032\u6570\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 -r ROUTINE[@LAYER_INDICES], --routine ROUTINE[@LAYER_INDICES] \u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 \u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u305d\u306e\u74b0\u5883\u3067\u5229\u7528\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u4e2d\u3067\u6700\u3082\u9ad8\u901f\u306a\u3082\u306e\u304c\u9078\u3070\u308c\u307e\u3059\u3002\u30c7\u30a3\u30d5\u30a9\u30eb\u30c8\u306fcpu\u3067\u3059\u3002 tune \u5f8c\u306e\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u306f\u3001\u30eb\u30fc\u30c1\u30f3\u306e\u6307\u5b9a\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u3092\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u306e\u3059\u3079\u3066\u306e\u30ec\u30a4\u30e4\u30fc\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 -R RPARAMS[@LAYER_INDICES], --rparams RPARAMS[@LAYER_INDICES] \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 tune \u5f8c\u306e\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u306f\u3001\u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6307\u5b9a\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u3092\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u306e\u3059\u3079\u3066\u306e\u30ec\u30a4\u30e4\u30fc\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --nobufopt DEVICE \u6307\u5b9a\u3057\u305f\u30c7\u30d0\u30a4\u30b9\u306e\u30eb\u30fc\u30c1\u30f3\u306b\u304a\u3051\u308b\u4f7f\u7528\u30e1\u30e2\u30ea\u306e\u6700\u9069\u5316\u3092\u30aa\u30d5\u306b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --lib LIB \u30aa\u30d5\u30e9\u30a4\u30f3\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u305fOpenCL\u306e\u30d0\u30a4\u30ca\u30ea\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 -l LNUM, --loop LNUM \u6307\u5b9a\u3057\u305f\u56de\u6570\u3060\u3051\u63a8\u8ad6\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u884c\u3057\u307e\u3059\u3002 --detail \u8a73\u7d30\u306a\u51e6\u7406\u6642\u9593\u306e\u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --detail2 \u3088\u308a\u8a73\u7d30\u306a\u51e6\u7406\u6642\u9593\u306e\u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 1\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u304c\u8907\u6570\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306b\u500b\u5225\u306e\u51e6\u7406\u6642\u9593\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --bylayer \u30ec\u30a4\u30e4\u30fc\u3054\u3068\u306b\u51e6\u7406\u6642\u9593\u306e\u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --dump DUMPDIR \u5404\u30ec\u30a4\u30e4\u306e\u51fa\u529b\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3067\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002 --dump2 DUMPDIR \u5404\u30ec\u30a4\u30e4\u306e\u3088\u308a\u8a73\u7d30\u306a\u51fa\u529b\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3067\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002 1\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u304c\u8907\u6570\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306b\u500b\u5225\u306e\u51e6\u7406\u7d50\u679c\u3092npy\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\u3057\u307e\u3059\u3002 -t NTOPS, --top NTOPS \u63a8\u8ad6(\u753b\u50cf\u5206\u985e)\u7d50\u679c\u306e\u30b9\u30b3\u30a2\u304c\u9ad8\u3044\u30e9\u30d9\u30eb\u3092\u6307\u5b9a\u3057\u305f\u6570\u3060\u3051\u8868\u793a\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro run densenet121.dnn --thread 8 --affinity 0xf0@0..3 --affinity 0x0f@4..7 --top 5 --loop 10 shovel.jpg --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9999 shovel 2 0.0001 hatchet 3 0.0000 broom 4 0.0000 swab 5 0.0000 spatula --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 43,070 43,070 43,070 1 Dnn_compile() 28,567 28,567 28,567 1 Dnn_forward() 39,877 39,751 39,983 10 Used memory: 88,403,968 Bytes --------------------------------- Benchmark --------------------------------- preprocess: 81 68 68 69 70 64 71 69 70 68 main: 39872 39698 39710 39679 39896 39884 39770 39801 39908 39824 TOTAL: 39955 39767 39778 39749 39968 39949 39842 39873 39981 39894 \u51e6\u7406\u901f\u5ea6\u306f Dnn_forward \u90e8\u5206\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002 AVE\u3001MIN\u3001MAX\u304c\u305d\u308c\u305e\u308c -loop \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305fCALL\u56de\u6570\u5206\u306e\u5e73\u5747\u3001\u6700\u5c0f\u5024\u3001\u6700\u5927\u5024\u3067\u3001 #RUN \u304c\u51e6\u7406\u3092\u5b9f\u884c\u3057\u305f\u56de\u6570\u3067\u3059\u3002 init \u00b6 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u751f\u6210\u3092\u884c\u3044\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro init [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--help] PROF DNN \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u51fa\u529b\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --thread NTHREADS \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3059\u308b\u969b\u306e\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30b3\u30a2\u6570\u3068\u540c\u3058\u6570\u306b\u306a\u308a\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 MASK \u306f\u30ea\u30c8\u30eb\u30a8\u30f3\u30c7\u30a3\u30a2\u30f3\u306e16\u9032\u6570 (0x..), 2\u9032\u6570 (0b..), \u307e\u305f\u306f10\u9032\u6570\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bmobilenet_prof\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro init mobilenet_prof mobilenet.dnn add \u00b6 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u306e\u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro add [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE[@LAYER_INDICES]]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u8a2d\u5b9a\u306e\u8ffd\u52a0\u3092\u884c\u3046\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 ROUTINE[@LAYER_INDICES] ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u3092 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306b\u8a2d\u5b9a\u3057\u307e\u3059\u3002 LAYER_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 -help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b mobilenet_prof\u306e\u6301\u3064\u30e2\u30c7\u30eb\u306b\u5bfe\u3057\u3066\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u306b cpu:qint8 \u306e\u30eb\u30fc\u30c1\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002(cpu\u306eqint8\u30eb\u30fc\u30c1\u30f3\u304c\u3042\u308b\u30ec\u30a4\u30e4\u30fc\u306e\u307f) $ softneuro add mobilenet_prof cpu:qint8 adding routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu:qint8 (9) 2 conv_dw_1 (depthwise_conv2) cpu:qint8 (3) 3 conv_pw_1 (conv2) cpu:qint8 (9) 4 conv_dw_2 (depthwise_conv2) cpu:qint8 (3) 5 conv_pw_2 (conv2) cpu:qint8 (9) 6 conv_dw_3 (depthwise_conv2) cpu:qint8 (3) 7 conv_pw_3 (conv2) cpu:qint8 (9) 8 conv_dw_4 (depthwise_conv2) cpu:qint8 (3) 9 conv_pw_4 (conv2) cpu:qint8 (9) 10 conv_dw_5 (depthwise_conv2) cpu:qint8 (3) 11 conv_pw_5 (conv2) cpu:qint8 (9) 12 conv_dw_6 (depthwise_conv2) cpu:qint8 (3) 13 conv_pw_6 (conv2) cpu:qint8 (9) 14 conv_dw_7 (depthwise_conv2) cpu:qint8 (3) 15 conv_pw_7 (conv2) cpu:qint8 (9) 16 conv_dw_8 (depthwise_conv2) cpu:qint8 (3) 17 conv_pw_8 (conv2) cpu:qint8 (9) 18 conv_dw_9 (depthwise_conv2) cpu:qint8 (3) 19 conv_pw_9 (conv2) cpu:qint8 (9) 20 conv_dw_10 (depthwise_conv2) cpu:qint8 (3) 21 conv_pw_10 (conv2) cpu:qint8 (9) 22 conv_dw_11 (depthwise_conv2) cpu:qint8 (3) 23 conv_pw_11 (conv2) cpu:qint8 (9) 24 conv_dw_12 (depthwise_conv2) cpu:qint8 (3) 25 conv_pw_12 (conv2) cpu:qint8 (9) 26 conv_dw_13 (depthwise_conv2) cpu:qint8 (3) 27 conv_pw_13 (conv2) cpu:qint8 (9) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) cpu:qint8 (1) 30 conv_preds (conv2) cpu:qint8 (9) 31 act_softmax (softmax) 32 reshape_2 (reshape) cpu:qint8 (1) 33 sink_0 (sink) ? ROUTINES cpu:qint8 TOTAL ? rm \u00b6 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u8a08\u6e2c\u7d50\u679c\u3092\u542b\u3080\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u60c5\u5831\u3092\u524a\u9664\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro rm [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u8a2d\u5b9a\u3092\u524a\u9664\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 ROUTINE[@LAYER_INDICES] ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u3092 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u524a\u9664\u3057\u307e\u3059\u3002 ROUTINE \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u3092\u524a\u9664\u3057\u307e\u3059\u3002 LAYER_INDICES \u306e\u307f\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u304c\u524a\u9664\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b mobilenet_prof\u306e\u30e2\u30c7\u30eb\u304b\u3089\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u304c\u6301\u3064\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a( ROUTINE \u5217)\u3092\u524a\u9664\u3057\u307e\u3059\u3002 $ softneuro rm mobilenet_prof removing routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) 2 conv_dw_1 (depthwise_conv2) 3 conv_pw_1 (conv2) 4 conv_dw_2 (depthwise_conv2) 5 conv_pw_2 (conv2) 6 conv_dw_3 (depthwise_conv2) 7 conv_pw_3 (conv2) 8 conv_dw_4 (depthwise_conv2) 9 conv_pw_4 (conv2) 10 conv_dw_5 (depthwise_conv2) 11 conv_pw_5 (conv2) 12 conv_dw_6 (depthwise_conv2) 13 conv_pw_6 (conv2) 14 conv_dw_7 (depthwise_conv2) 15 conv_pw_7 (conv2) 16 conv_dw_8 (depthwise_conv2) 17 conv_pw_8 (conv2) 18 conv_dw_9 (depthwise_conv2) 19 conv_pw_9 (conv2) 20 conv_dw_10 (depthwise_conv2) 21 conv_pw_10 (conv2) 22 conv_dw_11 (depthwise_conv2) 23 conv_pw_11 (conv2) 24 conv_dw_12 (depthwise_conv2) 25 conv_pw_12 (conv2) 26 conv_dw_13 (depthwise_conv2) 27 conv_pw_13 (conv2) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) 30 conv_preds (conv2) 31 act_softmax (softmax) 32 reshape_2 (reshape) 33 sink_0 (sink) ? TOTAL ? ? reset \u00b6 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u8a08\u6e2c\u7d50\u679c\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro reset [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u6e2c\u5b9a\u7d50\u679c\u3092\u524a\u9664\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 ROUTINE[@LAYER_INDICES] ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u306e\u6e2c\u5b9a\u7d50\u679c\u3092 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u524a\u9664\u3057\u307e\u3059\u3002 ROUTINE \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6e2c\u5b9a\u7d50\u679c\u3092\u524a\u9664\u3057\u307e\u3059\u3002 LAYER_INDICES \u306e\u307f\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u306e\u6e2c\u5b9a\u7d50\u679c\u304c\u524a\u9664\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b mobilenet_prof\u306e\u30e2\u30c7\u30eb\u304b\u3089\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u8a08\u6e2c\u7d50\u679c( TIME \u5217\u4ee5\u964d)\u3092\u524a\u9664\u3057\u307e\u3059\u3002 $ softneuro reset mobilenet_prof resetting routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 2 conv_dw_1 (depthwise_conv2) cpu (3) 3 conv_pw_1 (conv2) cpu (47) 4 conv_dw_2 (depthwise_conv2) cpu (3) 5 conv_pw_2 (conv2) cpu (47) 6 conv_dw_3 (depthwise_conv2) cpu (3) 7 conv_pw_3 (conv2) cpu (47) 8 conv_dw_4 (depthwise_conv2) cpu (3) 9 conv_pw_4 (conv2) cpu (47) 10 conv_dw_5 (depthwise_conv2) cpu (3) 11 conv_pw_5 (conv2) cpu (47) 12 conv_dw_6 (depthwise_conv2) cpu (3) 13 conv_pw_6 (conv2) cpu (47) 14 conv_dw_7 (depthwise_conv2) cpu (3) 15 conv_pw_7 (conv2) cpu (47) 16 conv_dw_8 (depthwise_conv2) cpu (3) 17 conv_pw_8 (conv2) cpu (47) 18 conv_dw_9 (depthwise_conv2) cpu (3) 19 conv_pw_9 (conv2) cpu (47) 20 conv_dw_10 (depthwise_conv2) cpu (3) 21 conv_pw_10 (conv2) cpu (47) 22 conv_dw_11 (depthwise_conv2) cpu (3) 23 conv_pw_11 (conv2) cpu (47) 24 conv_dw_12 (depthwise_conv2) cpu (3) 25 conv_pw_12 (conv2) cpu (47) 26 conv_dw_13 (depthwise_conv2) cpu (3) 27 conv_pw_13 (conv2) cpu (47) 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 29 reshape_1 (reshape) cpu (1) 30 conv_preds (conv2) cpu (47) 31 act_softmax (softmax) cpu (1) 32 reshape_2 (reshape) cpu (1) 33 sink_0 (sink) ? ROUTINES cpu TOTAL ? status \u00b6 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u30fb\u8a08\u6e2c\u7d50\u679c\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro status [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--at INDEX] [--estimate MODE] [--csv] [--help] PROF \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 -@, --at INDEX \u6307\u5b9a\u3057\u305f\u4f4d\u7f6e\u306e\u30ec\u30a4\u30e4\u30fc\u306b\u95a2\u3059\u308b\u60c5\u5831\u306e\u307f\u3092\u8868\u793a\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --estimate MODE \u8868\u793a\u3059\u308b profile \u7d50\u679c\u306e\u51e6\u7406\u6642\u9593(TIME)\u306e\u63a8\u5b9a\u30e2\u30fc\u30c9\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 robust (\u5916\u308c\u5024\u3092\u9664\u3044\u305f\u5e73\u5747), min (\u6700\u5c0f\u5024), ave (\u5168\u4f53\u306e\u5e73\u5747)\u304b\u3089\u9078\u629e\u3067\u304d\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f robust \u3067\u3059\u3002 --csv CSV\u5f62\u5f0f\u3067\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b profile \u30b3\u30de\u30f3\u30c9\u3067\u8a08\u6e2c\u3092\u884c\u3063\u305f\u5f8c\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u8a08\u6e2c\u7d50\u679c\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002 $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 28 cpu/avx {\"ops_in_task\":16384} 2 ? (sink) 28 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 213 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} 2 conv_dw_1 (depthwise_conv2) cpu (3) 110 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 3 conv_pw_1 (conv2) cpu (47) 195 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":144} 4 conv_dw_2 (depthwise_conv2) cpu (3) 60 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 5 conv_pw_2 (conv2) cpu (47) 177 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":72} 6 conv_dw_3 (depthwise_conv2) cpu (3) 113 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 7 conv_pw_3 (conv2) cpu (47) 328 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":36} 8 conv_dw_4 (depthwise_conv2) cpu (3) 40 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 9 conv_pw_4 (conv2) cpu (47) 167 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 10 conv_dw_5 (depthwise_conv2) cpu (3) 68 cpu/owc32_avx {\"cache\":8192,\"task_ops\":131072} 11 conv_pw_5 (conv2) cpu (47) 320 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 12 conv_dw_6 (depthwise_conv2) cpu (3) 23 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 13 conv_pw_6 (conv2) cpu (47) 164 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 14 conv_dw_7 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 15 conv_pw_7 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 16 conv_dw_8 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 17 conv_pw_8 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 18 conv_dw_9 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 19 conv_pw_9 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 20 conv_dw_10 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 21 conv_pw_10 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 22 conv_dw_11 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 23 conv_pw_11 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 24 conv_dw_12 (depthwise_conv2) cpu (3) 14 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 25 conv_pw_12 (conv2) cpu (47) 169 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 26 conv_dw_13 (depthwise_conv2) cpu (3) 19 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 27 conv_pw_13 (conv2) cpu (47) 336 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":8} 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 13 cpu/naive {} 29 reshape_1 (reshape) cpu (1) 0 cpu {} 30 conv_preds (conv2) cpu (47) 23 cpu/owc64_avx {\"cache\":8192,\"task_ops\":32768} 31 act_softmax (softmax) cpu (1) 21 cpu/naive {} 32 reshape_2 (reshape) cpu (1) 0 cpu {} 33 sink_0 (sink) 4,308 ROUTINES cpu TOTAL 4,336 profile \u00b6 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u305f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro profile [--dnn DNN] [--pass PASSWORD] [--help] PROF \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u5b9f\u884c\u306b\u5229\u7528\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b init \u30b3\u30de\u30f3\u30c9\u3067\u751f\u6210\u3057\u305f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3057\u3066\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\u3001\u5404\u30ec\u30a4\u30e4\u30fc\u3067\u5229\u7528\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u51e6\u7406\u6642\u9593\u3092\u6e2c\u5b9a\u3057\u3066\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 $ softneuro prof mobilenet_prof profiling...100.0% [00:01] tune \u00b6 DNN\u30d5\u30a1\u30a4\u30eb\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u5b9f\u884c\u6e08\u307f\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u306e\u5b9f\u884c\u304b\u3089\u51e6\u7406\u3092\u958b\u59cb\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro tune [--prof PROF] [--recipe RECIPE] [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--routine ROUTINE[@IDS]]... [--estimate MODE] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u5165\u529b\u3068\u306a\u308b\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u51fa\u529b\u3055\u308c\u308b\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u5f8c\u306eDNN\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --prof PROF \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u5229\u7528\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 --recipe RECIPE \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u5229\u7528\u3059\u308b\u30ec\u30b7\u30d4\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 --thread NTHREADS \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u5b9f\u884c\u6642\u306e\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 MASK \u306f\u30ea\u30c8\u30eb\u30a8\u30f3\u30c7\u30a3\u30a2\u30f3\u306e16\u9032\u6570 (0x..), 2\u9032\u6570 (0b..), \u307e\u305f\u306f10\u9032\u6570\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 -r, --routine ROUTINE[@LAYER_INDICES] \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u524d\u306b ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u3092\u5229\u7528\u3057\u3066 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 LAYER_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --estimate MODE \u51e6\u7406\u6642\u9593\u306e\u63a8\u5b9a\u30e2\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 robust (\u30c7\u30d5\u30a9\u30eb\u30c8), min , ave \u304b\u3089\u9078\u629e\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_tuned.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 $ softneuro tune vgg16.dnn vgg16_tuned.dnn adding cpu routines...done. profiling...100.0% [00:56] ETA[00:00] [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (permute) cpu (1) 155 cpu/naive {} 2 ? (madd) cpu (3) 29 cpu/avx {\"ops_in_task\":16384} 3 ? (sink) 184 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 block1_conv1 (conv2) cpu (67) 1,239 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} : TOTAL 59,463 OpenCL\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] OpenCL(float16)\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine opencl:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] CUDA\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine cuda/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] CUDA(float16)\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine cuda:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] \u91cf\u5b50\u53168bit\u6574\u6570\u3092\u5229\u7528\u3057\u305fCPU\u3067\u306etune $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00]","title":"\u63a8\u8ad6\u5b9f\u884c\u30fb\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30b3\u30de\u30f3\u30c9"},{"location":"commands/prof-tune/prof-tune.ja.html#_1","text":"","title":"\u63a8\u8ad6\u5b9f\u884c\u30fb\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30b3\u30de\u30f3\u30c9"},{"location":"commands/prof-tune/prof-tune.ja.html#run","text":"DNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3057\u3066\u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067\u3059\u3002 \u63a8\u8ad6\u306e\u7d50\u679c\u3084\u51e6\u7406\u6642\u9593\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro run [-o ONPY]... [-p PASSWORD] [--recipe RECIPE][--batch BATCH] [--ishape SHAPE] [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE] [--thread NTHREADS] [--noboost] [--affinity MASK[@THREAD_INDICES]] [-r ROUTINE[@LAYER_INDICES]] [-R RPARAMS[@LAYER_INDICES]] [-nobufopt DEVICE] [--lib LIB] [-l LNUM] [--detail] [--detail2] [--bylayer] [-dump DUMPDIR] [-dump2 DUMPRID] [-t NTOPS] [-h] DNN [INPUT [INPUT ...]] \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 DNN \u63a8\u8ad6\u3092\u5b9f\u884c\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 INPUT \u63a8\u8ad6\u5b9f\u884c\u306e\u5165\u529b\u3068\u306a\u308b\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u307e\u305f\u306fnumpy\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u672a\u6307\u5b9a\u6642\u306f[-1, 1]\u306e\u4e71\u6570\u304c\u5165\u529b\u3068\u306a\u308a\u307e\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c -p PASSWORD --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002 -o ONPY \u7d50\u679c\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 --recipe RECIPE \u5229\u7528\u3059\u308brecipe\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u3000 --batch BATCH \u5165\u529b\u3092\u6307\u5b9a\u3057\u305f\u30b5\u30a4\u30ba\u306e\u30d0\u30c3\u30c1\u306b\u3057\u3066\u63a8\u8ad6\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 --ishape SHAPE \u5165\u529b\u30b7\u30a7\u30a4\u30d7\u3092\u6307\u5b9a\u3057\u305f\u3082\u306e\u306b\u5909\u66f4\u3057\u307e\u3059\u3002(\u4f8b\uff1a 1x224x224x3 ). --keep_img_ar PADDINGCOLOR \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306b\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3055\u305b\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u3092\u7dad\u6301\u3057\u307e\u305b\u3093\u3002\u30ea\u30b5\u30a4\u30ba\u524d\u5f8c\u3067\u30a2\u30b9\u30da\u30af\u30c8\u6bd4\u306e\u9055\u3044\u306b\u3088\u3063\u3066\u751f\u3058\u308b\u30b9\u30da\u30fc\u30b9\u3092\u3001PADDINGCOLOR\u3067\u6307\u5b9a\u3057\u305f\u8272\u3067\u57cb\u3081\u307e\u3059\u3002PADDINGCOLOR\u306f\u4f8b\u3048\u3070 '0, 0, 0' \u306e\u3088\u3046\u306bRGB\u3067\u6307\u5b9a\u3057\u307e\u3059\u3002 --img_resize_mode RESIZEMODE \u5165\u529b\u753b\u50cf\u3092\u30ea\u30b5\u30a4\u30ba\u3059\u308b\u969b\u306e\u65b9\u5f0f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002 'bilinear' \u307e\u305f\u306f\u3000'nearest' \u3092\u6307\u5b9a\u53ef\u80fd\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f 'bilinear' \u3067\u3059\u3002 --thread NTHREADS \u51e6\u7406\u3092\u5b9f\u884c\u3059\u308b\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 \u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u306fCPU\u306e\u30b3\u30a2\u6570\u3068\u306a\u308a\u307e\u3059\u3002 --noboost \u30ef\u30fc\u30ab\u30fc\u30b9\u30ec\u30c3\u30c9\u304c\u30bf\u30b9\u30af\u5f85\u3061\u3092\u3059\u308b\u3068\u304d\u306b cond wait \u3092\u7528\u3044\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f busy wait \u3092\u7528\u3044\u307e\u3059\u3002 --noboost \u304c\u6709\u52b9\u306e\u5834\u5408\u3001SoftNeuro\u306eCPU\u5360\u6709\u7387\u304c\u4e0b\u304c\u308a\u4ed6\u30d7\u30ed\u30bb\u30b9\u304c\u5f71\u97ff\u3055\u308c\u306b\u304f\u304f\u306a\u308a\u307e\u3059\u304c\u3001\u63a8\u8ad6\u901f\u5ea6\u304c\u4f4e\u4e0b\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 MASK \u306f\u30ea\u30c8\u30eb\u30a8\u30f3\u30c7\u30a3\u30a2\u30f3\u306e16\u9032\u6570 (0x..), 2\u9032\u6570 (0b..), \u307e\u305f\u306f10\u9032\u6570\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 -r ROUTINE[@LAYER_INDICES], --routine ROUTINE[@LAYER_INDICES] \u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 \u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u305d\u306e\u74b0\u5883\u3067\u5229\u7528\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u4e2d\u3067\u6700\u3082\u9ad8\u901f\u306a\u3082\u306e\u304c\u9078\u3070\u308c\u307e\u3059\u3002\u30c7\u30a3\u30d5\u30a9\u30eb\u30c8\u306fcpu\u3067\u3059\u3002 tune \u5f8c\u306e\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u306f\u3001\u30eb\u30fc\u30c1\u30f3\u306e\u6307\u5b9a\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u3092\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u306e\u3059\u3079\u3066\u306e\u30ec\u30a4\u30e4\u30fc\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 -R RPARAMS[@LAYER_INDICES], --rparams RPARAMS[@LAYER_INDICES] \u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002 tune \u5f8c\u306e\u30e2\u30c7\u30eb\u306b\u3064\u3044\u3066\u306f\u3001\u30eb\u30fc\u30c1\u30f3\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u6307\u5b9a\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u3092\u8a2d\u5b9a\u3057\u306a\u3044\u5834\u5408\u3001\u30e1\u30a4\u30f3\u30cd\u30c3\u30c8\u306e\u3059\u3079\u3066\u306e\u30ec\u30a4\u30e4\u30fc\u306b\u9069\u7528\u3055\u308c\u307e\u3059\u3002 LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --nobufopt DEVICE \u6307\u5b9a\u3057\u305f\u30c7\u30d0\u30a4\u30b9\u306e\u30eb\u30fc\u30c1\u30f3\u306b\u304a\u3051\u308b\u4f7f\u7528\u30e1\u30e2\u30ea\u306e\u6700\u9069\u5316\u3092\u30aa\u30d5\u306b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --lib LIB \u30aa\u30d5\u30e9\u30a4\u30f3\u30b3\u30f3\u30d1\u30a4\u30eb\u3057\u305fOpenCL\u306e\u30d0\u30a4\u30ca\u30ea\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 -l LNUM, --loop LNUM \u6307\u5b9a\u3057\u305f\u56de\u6570\u3060\u3051\u63a8\u8ad6\u3092\u7e70\u308a\u8fd4\u3057\u5b9f\u884c\u3057\u307e\u3059\u3002 --detail \u8a73\u7d30\u306a\u51e6\u7406\u6642\u9593\u306e\u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --detail2 \u3088\u308a\u8a73\u7d30\u306a\u51e6\u7406\u6642\u9593\u306e\u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 1\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u304c\u8907\u6570\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306b\u500b\u5225\u306e\u51e6\u7406\u6642\u9593\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --bylayer \u30ec\u30a4\u30e4\u30fc\u3054\u3068\u306b\u51e6\u7406\u6642\u9593\u306e\u7d71\u8a08\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 --dump DUMPDIR \u5404\u30ec\u30a4\u30e4\u306e\u51fa\u529b\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3067\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002 --dump2 DUMPDIR \u5404\u30ec\u30a4\u30e4\u306e\u3088\u308a\u8a73\u7d30\u306a\u51fa\u529b\u3092numpy\u30d5\u30a1\u30a4\u30eb\u3067\u51fa\u529b\u3059\u308b\u969b\u306b\u6307\u5b9a\u3059\u308b\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u3059\u3002 1\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u304c\u8907\u6570\u30ec\u30a4\u30e4\u306e\u51e6\u7406\u3067\u69cb\u6210\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306b\u500b\u5225\u306e\u51e6\u7406\u7d50\u679c\u3092npy\u30d5\u30a1\u30a4\u30eb\u51fa\u529b\u3057\u307e\u3059\u3002 -t NTOPS, --top NTOPS \u63a8\u8ad6(\u753b\u50cf\u5206\u985e)\u7d50\u679c\u306e\u30b9\u30b3\u30a2\u304c\u9ad8\u3044\u30e9\u30d9\u30eb\u3092\u6307\u5b9a\u3057\u305f\u6570\u3060\u3051\u8868\u793a\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b $ softneuro run densenet121.dnn --thread 8 --affinity 0xf0@0..3 --affinity 0x0f@4..7 --top 5 --loop 10 shovel.jpg --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9999 shovel 2 0.0001 hatchet 3 0.0000 broom 4 0.0000 swab 5 0.0000 spatula --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 43,070 43,070 43,070 1 Dnn_compile() 28,567 28,567 28,567 1 Dnn_forward() 39,877 39,751 39,983 10 Used memory: 88,403,968 Bytes --------------------------------- Benchmark --------------------------------- preprocess: 81 68 68 69 70 64 71 69 70 68 main: 39872 39698 39710 39679 39896 39884 39770 39801 39908 39824 TOTAL: 39955 39767 39778 39749 39968 39949 39842 39873 39981 39894 \u51e6\u7406\u901f\u5ea6\u306f Dnn_forward \u90e8\u5206\u3092\u3054\u89a7\u304f\u3060\u3055\u3044\u3002 AVE\u3001MIN\u3001MAX\u304c\u305d\u308c\u305e\u308c -loop \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305fCALL\u56de\u6570\u5206\u306e\u5e73\u5747\u3001\u6700\u5c0f\u5024\u3001\u6700\u5927\u5024\u3067\u3001 #RUN \u304c\u51e6\u7406\u3092\u5b9f\u884c\u3057\u305f\u56de\u6570\u3067\u3059\u3002","title":"run"},{"location":"commands/prof-tune/prof-tune.ja.html#init","text":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u751f\u6210\u3092\u884c\u3044\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro init [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--help] PROF DNN \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u51fa\u529b\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --thread NTHREADS \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3059\u308b\u969b\u306e\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u30b3\u30a2\u6570\u3068\u540c\u3058\u6570\u306b\u306a\u308a\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 MASK \u306f\u30ea\u30c8\u30eb\u30a8\u30f3\u30c7\u30a3\u30a2\u30f3\u306e16\u9032\u6570 (0x..), 2\u9032\u6570 (0b..), \u307e\u305f\u306f10\u9032\u6570\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bmobilenet_prof\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 \u203b\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u4e0a\u3078\u306e\u51fa\u529b\u306f\u3042\u308a\u307e\u305b\u3093 $ softneuro init mobilenet_prof mobilenet.dnn","title":"init"},{"location":"commands/prof-tune/prof-tune.ja.html#add","text":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u306e\u30eb\u30fc\u30c1\u30f3\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro add [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE[@LAYER_INDICES]]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u8a2d\u5b9a\u306e\u8ffd\u52a0\u3092\u884c\u3046\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 ROUTINE[@LAYER_INDICES] ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u3092 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306b\u8a2d\u5b9a\u3057\u307e\u3059\u3002 LAYER_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 -help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b mobilenet_prof\u306e\u6301\u3064\u30e2\u30c7\u30eb\u306b\u5bfe\u3057\u3066\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u306b cpu:qint8 \u306e\u30eb\u30fc\u30c1\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002(cpu\u306eqint8\u30eb\u30fc\u30c1\u30f3\u304c\u3042\u308b\u30ec\u30a4\u30e4\u30fc\u306e\u307f) $ softneuro add mobilenet_prof cpu:qint8 adding routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu:qint8 (9) 2 conv_dw_1 (depthwise_conv2) cpu:qint8 (3) 3 conv_pw_1 (conv2) cpu:qint8 (9) 4 conv_dw_2 (depthwise_conv2) cpu:qint8 (3) 5 conv_pw_2 (conv2) cpu:qint8 (9) 6 conv_dw_3 (depthwise_conv2) cpu:qint8 (3) 7 conv_pw_3 (conv2) cpu:qint8 (9) 8 conv_dw_4 (depthwise_conv2) cpu:qint8 (3) 9 conv_pw_4 (conv2) cpu:qint8 (9) 10 conv_dw_5 (depthwise_conv2) cpu:qint8 (3) 11 conv_pw_5 (conv2) cpu:qint8 (9) 12 conv_dw_6 (depthwise_conv2) cpu:qint8 (3) 13 conv_pw_6 (conv2) cpu:qint8 (9) 14 conv_dw_7 (depthwise_conv2) cpu:qint8 (3) 15 conv_pw_7 (conv2) cpu:qint8 (9) 16 conv_dw_8 (depthwise_conv2) cpu:qint8 (3) 17 conv_pw_8 (conv2) cpu:qint8 (9) 18 conv_dw_9 (depthwise_conv2) cpu:qint8 (3) 19 conv_pw_9 (conv2) cpu:qint8 (9) 20 conv_dw_10 (depthwise_conv2) cpu:qint8 (3) 21 conv_pw_10 (conv2) cpu:qint8 (9) 22 conv_dw_11 (depthwise_conv2) cpu:qint8 (3) 23 conv_pw_11 (conv2) cpu:qint8 (9) 24 conv_dw_12 (depthwise_conv2) cpu:qint8 (3) 25 conv_pw_12 (conv2) cpu:qint8 (9) 26 conv_dw_13 (depthwise_conv2) cpu:qint8 (3) 27 conv_pw_13 (conv2) cpu:qint8 (9) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) cpu:qint8 (1) 30 conv_preds (conv2) cpu:qint8 (9) 31 act_softmax (softmax) 32 reshape_2 (reshape) cpu:qint8 (1) 33 sink_0 (sink) ? ROUTINES cpu:qint8 TOTAL ?","title":"add"},{"location":"commands/prof-tune/prof-tune.ja.html#rm","text":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u8a08\u6e2c\u7d50\u679c\u3092\u542b\u3080\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u60c5\u5831\u3092\u524a\u9664\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro rm [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u8a2d\u5b9a\u3092\u524a\u9664\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 ROUTINE[@LAYER_INDICES] ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u3092 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u524a\u9664\u3057\u307e\u3059\u3002 ROUTINE \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u3092\u524a\u9664\u3057\u307e\u3059\u3002 LAYER_INDICES \u306e\u307f\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u304c\u524a\u9664\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b mobilenet_prof\u306e\u30e2\u30c7\u30eb\u304b\u3089\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u304c\u6301\u3064\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a( ROUTINE \u5217)\u3092\u524a\u9664\u3057\u307e\u3059\u3002 $ softneuro rm mobilenet_prof removing routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) 2 conv_dw_1 (depthwise_conv2) 3 conv_pw_1 (conv2) 4 conv_dw_2 (depthwise_conv2) 5 conv_pw_2 (conv2) 6 conv_dw_3 (depthwise_conv2) 7 conv_pw_3 (conv2) 8 conv_dw_4 (depthwise_conv2) 9 conv_pw_4 (conv2) 10 conv_dw_5 (depthwise_conv2) 11 conv_pw_5 (conv2) 12 conv_dw_6 (depthwise_conv2) 13 conv_pw_6 (conv2) 14 conv_dw_7 (depthwise_conv2) 15 conv_pw_7 (conv2) 16 conv_dw_8 (depthwise_conv2) 17 conv_pw_8 (conv2) 18 conv_dw_9 (depthwise_conv2) 19 conv_pw_9 (conv2) 20 conv_dw_10 (depthwise_conv2) 21 conv_pw_10 (conv2) 22 conv_dw_11 (depthwise_conv2) 23 conv_pw_11 (conv2) 24 conv_dw_12 (depthwise_conv2) 25 conv_pw_12 (conv2) 26 conv_dw_13 (depthwise_conv2) 27 conv_pw_13 (conv2) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) 30 conv_preds (conv2) 31 act_softmax (softmax) 32 reshape_2 (reshape) 33 sink_0 (sink) ? TOTAL ? ?","title":"rm"},{"location":"commands/prof-tune/prof-tune.ja.html#reset","text":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u8a08\u6e2c\u7d50\u679c\u3092\u521d\u671f\u5316\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro reset [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u6e2c\u5b9a\u7d50\u679c\u3092\u524a\u9664\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 ROUTINE[@LAYER_INDICES] ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u306e\u6e2c\u5b9a\u7d50\u679c\u3092 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u524a\u9664\u3057\u307e\u3059\u3002 ROUTINE \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6e2c\u5b9a\u7d50\u679c\u3092\u524a\u9664\u3057\u307e\u3059\u3002 LAYER_INDICES \u306e\u307f\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u304b\u3089\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u306e\u6e2c\u5b9a\u7d50\u679c\u304c\u524a\u9664\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b mobilenet_prof\u306e\u30e2\u30c7\u30eb\u304b\u3089\u3001main\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u8a08\u6e2c\u7d50\u679c( TIME \u5217\u4ee5\u964d)\u3092\u524a\u9664\u3057\u307e\u3059\u3002 $ softneuro reset mobilenet_prof resetting routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 2 conv_dw_1 (depthwise_conv2) cpu (3) 3 conv_pw_1 (conv2) cpu (47) 4 conv_dw_2 (depthwise_conv2) cpu (3) 5 conv_pw_2 (conv2) cpu (47) 6 conv_dw_3 (depthwise_conv2) cpu (3) 7 conv_pw_3 (conv2) cpu (47) 8 conv_dw_4 (depthwise_conv2) cpu (3) 9 conv_pw_4 (conv2) cpu (47) 10 conv_dw_5 (depthwise_conv2) cpu (3) 11 conv_pw_5 (conv2) cpu (47) 12 conv_dw_6 (depthwise_conv2) cpu (3) 13 conv_pw_6 (conv2) cpu (47) 14 conv_dw_7 (depthwise_conv2) cpu (3) 15 conv_pw_7 (conv2) cpu (47) 16 conv_dw_8 (depthwise_conv2) cpu (3) 17 conv_pw_8 (conv2) cpu (47) 18 conv_dw_9 (depthwise_conv2) cpu (3) 19 conv_pw_9 (conv2) cpu (47) 20 conv_dw_10 (depthwise_conv2) cpu (3) 21 conv_pw_10 (conv2) cpu (47) 22 conv_dw_11 (depthwise_conv2) cpu (3) 23 conv_pw_11 (conv2) cpu (47) 24 conv_dw_12 (depthwise_conv2) cpu (3) 25 conv_pw_12 (conv2) cpu (47) 26 conv_dw_13 (depthwise_conv2) cpu (3) 27 conv_pw_13 (conv2) cpu (47) 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 29 reshape_1 (reshape) cpu (1) 30 conv_preds (conv2) cpu (47) 31 act_softmax (softmax) cpu (1) 32 reshape_2 (reshape) cpu (1) 33 sink_0 (sink) ? ROUTINES cpu TOTAL ?","title":"reset"},{"location":"commands/prof-tune/prof-tune.ja.html#status","text":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u3042\u308b\u5404\u30ec\u30a4\u30e4\u30fc\u306e\u30eb\u30fc\u30c1\u30f3\u8a2d\u5b9a\u30fb\u8a08\u6e2c\u7d50\u679c\u306e\u60c5\u5831\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro status [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--at INDEX] [--estimate MODE] [--csv] [--help] PROF \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --ref REF \u3000\u901a\u5e38secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3057\u305fDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3057\u3066\u306f\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\u3057\u304b\u3057secret\u30e2\u30fc\u30c9\u3067\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u306a\u3044DNN\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3059\u308c\u3070\u3001 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u305d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3059\u308b\u3053\u3068\u3067\u3001 LAYER_INDICES \u3092\u6307\u5b9a\u3057\u305f\u64cd\u4f5c\u3092\u884c\u3046\u3053\u3068\u304c\u53ef\u80fd\u3068\u306a\u308a\u307e\u3059\u3002 --ref-pass REF_PASSWORD \u3000 \u3000 --ref \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6307\u5b9a\u3057\u305f\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9\u30ef\u30fc\u30c9\u3067\u3059\u3002\u53c2\u8003\u7528\u306eDNN\u30d5\u30a1\u30a4\u30eb\u304c\u901a\u5e38\u306e(secret\u30e2\u30fc\u30c9\u3067\u306a\u3044)\u6697\u53f7\u5316\u3092\u65bd\u3055\u308c\u3066\u3044\u305f\u5834\u5408\u306b\u5fc5\u8981\u3068\u306a\u308a\u307e\u3059\u3002 -@, --at INDEX \u6307\u5b9a\u3057\u305f\u4f4d\u7f6e\u306e\u30ec\u30a4\u30e4\u30fc\u306b\u95a2\u3059\u308b\u60c5\u5831\u306e\u307f\u3092\u8868\u793a\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --estimate MODE \u8868\u793a\u3059\u308b profile \u7d50\u679c\u306e\u51e6\u7406\u6642\u9593(TIME)\u306e\u63a8\u5b9a\u30e2\u30fc\u30c9\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 robust (\u5916\u308c\u5024\u3092\u9664\u3044\u305f\u5e73\u5747), min (\u6700\u5c0f\u5024), ave (\u5168\u4f53\u306e\u5e73\u5747)\u304b\u3089\u9078\u629e\u3067\u304d\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306f robust \u3067\u3059\u3002 --csv CSV\u5f62\u5f0f\u3067\u60c5\u5831\u3092\u8868\u793a\u3059\u308b\u969b\u306b\u6307\u5b9a\u3057\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b profile \u30b3\u30de\u30f3\u30c9\u3067\u8a08\u6e2c\u3092\u884c\u3063\u305f\u5f8c\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u8a08\u6e2c\u7d50\u679c\u304c\u8868\u793a\u3055\u308c\u307e\u3059\u3002 $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 28 cpu/avx {\"ops_in_task\":16384} 2 ? (sink) 28 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 213 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} 2 conv_dw_1 (depthwise_conv2) cpu (3) 110 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 3 conv_pw_1 (conv2) cpu (47) 195 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":144} 4 conv_dw_2 (depthwise_conv2) cpu (3) 60 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 5 conv_pw_2 (conv2) cpu (47) 177 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":72} 6 conv_dw_3 (depthwise_conv2) cpu (3) 113 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 7 conv_pw_3 (conv2) cpu (47) 328 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":36} 8 conv_dw_4 (depthwise_conv2) cpu (3) 40 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 9 conv_pw_4 (conv2) cpu (47) 167 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 10 conv_dw_5 (depthwise_conv2) cpu (3) 68 cpu/owc32_avx {\"cache\":8192,\"task_ops\":131072} 11 conv_pw_5 (conv2) cpu (47) 320 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 12 conv_dw_6 (depthwise_conv2) cpu (3) 23 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 13 conv_pw_6 (conv2) cpu (47) 164 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 14 conv_dw_7 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 15 conv_pw_7 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 16 conv_dw_8 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 17 conv_pw_8 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 18 conv_dw_9 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 19 conv_pw_9 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 20 conv_dw_10 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 21 conv_pw_10 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 22 conv_dw_11 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 23 conv_pw_11 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 24 conv_dw_12 (depthwise_conv2) cpu (3) 14 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 25 conv_pw_12 (conv2) cpu (47) 169 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 26 conv_dw_13 (depthwise_conv2) cpu (3) 19 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 27 conv_pw_13 (conv2) cpu (47) 336 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":8} 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 13 cpu/naive {} 29 reshape_1 (reshape) cpu (1) 0 cpu {} 30 conv_preds (conv2) cpu (47) 23 cpu/owc64_avx {\"cache\":8192,\"task_ops\":32768} 31 act_softmax (softmax) cpu (1) 21 cpu/naive {} 32 reshape_2 (reshape) cpu (1) 0 cpu {} 33 sink_0 (sink) 4,308 ROUTINES cpu TOTAL 4,336","title":"status"},{"location":"commands/prof-tune/prof-tune.ja.html#profile","text":"\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u305f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro profile [--dnn DNN] [--pass PASSWORD] [--help] PROF \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 PROF \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u5b9f\u884c\u306b\u5229\u7528\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --dnn DNN \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u4f5c\u6210\u306b\u5229\u7528\u3059\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bPROF\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b init \u30b3\u30de\u30f3\u30c9\u3067\u751f\u6210\u3057\u305f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3057\u3066\u5b9f\u884c\u3059\u308b\u3053\u3068\u3067\u3001\u5404\u30ec\u30a4\u30e4\u30fc\u3067\u5229\u7528\u53ef\u80fd\u306a\u30eb\u30fc\u30c1\u30f3\u306e\u51e6\u7406\u6642\u9593\u3092\u6e2c\u5b9a\u3057\u3066\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306b\u4fdd\u5b58\u3057\u307e\u3059\u3002 $ softneuro prof mobilenet_prof profiling...100.0% [00:01]","title":"profile"},{"location":"commands/prof-tune/prof-tune.ja.html#tune","text":"DNN\u30d5\u30a1\u30a4\u30eb\u306e\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u5b9f\u884c\u6e08\u307f\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u3092\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u306e\u5b9f\u884c\u304b\u3089\u51e6\u7406\u3092\u958b\u59cb\u3057\u307e\u3059\u3002 \u4f7f\u3044\u65b9 usage: softneuro tune [--prof PROF] [--recipe RECIPE] [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--routine ROUTINE[@IDS]]... [--estimate MODE] [--help] INPUT OUTPUT \u5f15\u6570 \u5f15\u6570\u540d \u5185\u5bb9 INPUT \u5165\u529b\u3068\u306a\u308b\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u524d\u306eDNN\u30d5\u30a1\u30a4\u30eb\u3067\u3059\u3002 OUTPUT \u51fa\u529b\u3055\u308c\u308b\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u5f8c\u306eDNN\u30d5\u30a1\u30a4\u30eb\u540d\u3067\u3059\u3002 \u30aa\u30d7\u30b7\u30e7\u30f3 \u30aa\u30d7\u30b7\u30e7\u30f3 \u52b9\u679c --prof PROF \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u5229\u7528\u3059\u308b\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 --recipe RECIPE \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306b\u5229\u7528\u3059\u308b\u30ec\u30b7\u30d4\u30c7\u30fc\u30bf\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3067\u3059\u3002 --thread NTHREADS \u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u5b9f\u884c\u6642\u306e\u30b9\u30ec\u30c3\u30c9\u6570\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u30c7\u30fc\u30bf\u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u308b\u5834\u5408\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002 --affinity MASK[@THREAD_INDICES] MASK \u3067\u6307\u5b9a\u3057\u305f\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u3092 THREAD_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30b9\u30ec\u30c3\u30c9\u306b\u9069\u7528\u3057\u307e\u3059\u3002 MASK \u306f\u30ea\u30c8\u30eb\u30a8\u30f3\u30c7\u30a3\u30a2\u30f3\u306e16\u9032\u6570 (0x..), 2\u9032\u6570 (0b..), \u307e\u305f\u306f10\u9032\u6570\u3067\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002 THREAD_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u5168\u30b9\u30ec\u30c3\u30c9\u306b\u30a2\u30d5\u30a3\u30cb\u30c6\u30a3\u30de\u30b9\u30af\u304c\u9069\u7528\u3055\u308c\u307e\u3059\u3002 THREAD_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help thread_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 -p, --pass PASSWORD \u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u3066\u6697\u53f7\u5316\u3055\u308c\u3066\u3044\u308bDNN\u30d5\u30a1\u30a4\u30eb\u3092\u5229\u7528\u3059\u308b\u969b\u306b\u5165\u529b\u3057\u307e\u3059\u3002 -r, --routine ROUTINE[@LAYER_INDICES] \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306e\u524d\u306b ROUTINE \u3067\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u3092\u5229\u7528\u3057\u3066 LAYER_INDICES \u3067\u6307\u5b9a\u3057\u305f\u30ec\u30a4\u30e4\u30fc\u306e\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002 LAYER_INDICES \u304c\u6307\u5b9a\u3055\u308c\u3066\u3044\u306a\u3044\u5834\u5408\u306fmain\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u5168\u30ec\u30a4\u30e4\u30fc\u306b\u6307\u5b9a\u3057\u305f\u30eb\u30fc\u30c1\u30f3\u304c\u8a2d\u5b9a\u3055\u308c\u307e\u3059\u3002 ROUTINE \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help routine_desc , LAYER_INDICES \u306e\u66f8\u5f0f\u306b\u3064\u3044\u3066\u306f softneuro help layer_indices \u3067\u8868\u793a\u3055\u308c\u308b\u30d8\u30eb\u30d7\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002 --estimate MODE \u51e6\u7406\u6642\u9593\u306e\u63a8\u5b9a\u30e2\u30fc\u30c9\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002 robust (\u30c7\u30d5\u30a9\u30eb\u30c8), min , ave \u304b\u3089\u9078\u629e\u3067\u304d\u307e\u3059\u3002 -h, --help \u672c\u30b3\u30de\u30f3\u30c9\u306e\u30d8\u30eb\u30d7\u3092\u8868\u793a\u3057\u307e\u3059\u3002 \u4f7f\u7528\u4f8b \u5b9f\u884c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306bvgg16_tuned.dnn\u304c\u751f\u6210\u3055\u308c\u307e\u3059\u3002 $ softneuro tune vgg16.dnn vgg16_tuned.dnn adding cpu routines...done. profiling...100.0% [00:56] ETA[00:00] [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (permute) cpu (1) 155 cpu/naive {} 2 ? (madd) cpu (3) 29 cpu/avx {\"ops_in_task\":16384} 3 ? (sink) 184 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 block1_conv1 (conv2) cpu (67) 1,239 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} : TOTAL 59,463 OpenCL\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] OpenCL(float16)\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine opencl:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] CUDA\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine cuda/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] CUDA(float16)\u3092\u5229\u7528\u3057\u305fGPU\u3067\u306etune $ softneuro tune --routine cuda:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] \u91cf\u5b50\u53168bit\u6574\u6570\u3092\u5229\u7528\u3057\u305fCPU\u3067\u306etune $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00]","title":"tune"},{"location":"commands/prof-tune/prof-tune.html","text":"Run and Profiling Commands \u00b6 run \u00b6 Runs inference using the DNN file model. It's possible to get inference results and execution times. Usage usage: softneuro run [-o ONPY]... [-p PASSWORD] [--recipe RECIPE][--batch BATCH] [--ishape SHAPE] [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE] [--thread NTHREADS] [--noboost] [--affinity MASK[@THREAD_INDICES]] [-r ROUTINE[@LAYER_INDICES]] [-R RPARAMS[@LAYER_INDICES]] [-nobufopt DEVICE] [--lib LIB] [-l LNUM] [--detail] [--detail2] [--bylayer] [-dump DUMPDIR] [-dump2 DUMPRID] [-t NTOPS] [-h] DNN [INPUT [INPUT ...]] Arguments Argument Description DNN DNN file for inference execution. INPUT Input for inference execution. Can be a numpy file or an image file. If not provided, input will be uniform random numbers from [-1, 1]. Flags Flag Description -p PASSWORD --pass PASSWORD Password to run an encrypted DNN file. -o ONPY File name to output the inference results as a numpy file. --recipe RECIPE Set dnn recipe file.\u3000 --batch BATCH Input batch size. --ishape SHAPE Input shape. (Example: 1x224x224x3 ). --keep_img_ar PADDINGCOLOR Keeps aspect ratio when resizing input image. The aspect ratio is not kept by default. Margin space is filled with the color specified by PADDINGCOLOR. PADDINGCOLOR can be specified by RGB value, for example, '0, 0, 0'. --img_resize_mode RESIZEMODE Specifies the resizing mode. 'bilinear' or 'nearest' can be specified. Default is 'bilinear'. --thread NTHREADS How many threads should be used for execution. Defaults to the number of CPU cores. --noboost Set threads as cond wait when they're waiting for a task. If this isn't set, threads will be set to busy wait. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. -r, --routine ROUTINE[@LAYER_INDICES] Set routines to be used. If not set, the usually best available routines will be chosen (e.g. CUDA if there's CUDA support). The default is cpu. If the model is tuned this setting is ignored. If LAYER_INDICES isn't set all layers in main net will be applied. For more information on LAYER_INDICES use the softneuro help layer_indices command. -R RPARAMS[@LAYER_INDICES], --rparams RPARAMS[@LAYER_INDICES] Set routine parameters to be used. If the model is tuned this setting is ignored. If LAYER_INDICES isn't set all layers in main net will be applied. For more information on LAYER_INDICES use the softneuro help layer_indices command. --nobufopt DEVICE Disable the buffer optimizer for routines that run on the given device. --lib LIB Set an OpenCL binary file when using online compilation. -l, --loop LNUM Run inference LNUM times for benchmarking. --detail Show detailed inference statistics. --detail2 Show even more detailed inference statistics. If a layer is made up of other layers this shows the processing times of the internal layers as well. --bylayer Show detailed inference statistics by layer. --dump DUMPDIR Dump each layer output as a numpy file in the given folder. --dump2 DUMPDIR Dump each layer output and internal layer outputs if they exist in the given folder. -t, --top NTOPS Shows the top TOP scores and labels for image classification models. -h, --help Shows the command help. Example $ softneuro run densenet121.dnn --thread 8 --affinity 0xf0@0..3 --affinity 0x0f@4..7 --top 5 --loop 10 shovel.jpg --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9999 shovel 2 0.0001 hatchet 3 0.0000 broom 4 0.0000 swab 5 0.0000 spatula --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 43,070 43,070 43,070 1 Dnn_compile() 28,567 28,567 28,567 1 Dnn_forward() 39,877 39,751 39,983 10 Used memory: 88,403,968 Bytes --------------------------------- Benchmark --------------------------------- preprocess: 81 68 68 69 70 64 71 69 70 68 main: 39872 39698 39710 39679 39896 39884 39770 39801 39908 39824 TOTAL: 39955 39767 39778 39749 39968 39949 39842 39873 39981 39894 The inference time is given by Dnn_forward . AVE, MIN and MAX are, respectively, the average, minimum and maximum execution times for the number of runs shown under #RUN. init \u00b6 Initializes profiling data. Usage usage: softneuro init [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--help] PROF DNN Arguments Argument Description PROF Directory where the profiling data will be initialized. DNN DNN file to be profiled. Flags Flag Description --thread TNUM How many threads should be used for execution. Defaults to the number of CPU cores. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. --pass PASSWORD Password to profile an encrypted DNN file. -h, --help Shows the command help. Example The command creates the mobilnet_prof directory with profiling data. \u203bThere's no terminal output $ softneuro init mobilenet_prof mobilenet.dnn add \u00b6 Configure routines to layers present in the profiling data. Usage usage: softneuro add [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE[@LAYER_INDICES]]... Arguments Argument Description PROF Directory containing profiling data. ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p, --pass PASSWORD The password required to use the prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -h, --help Shows the command help. Example Set all main network layers to use the cpu:qint8 routine, if supported. $ softneuro add mobilenet_prof cpu:qint8 adding routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu:qint8 (9) 2 conv_dw_1 (depthwise_conv2) cpu:qint8 (3) 3 conv_pw_1 (conv2) cpu:qint8 (9) 4 conv_dw_2 (depthwise_conv2) cpu:qint8 (3) 5 conv_pw_2 (conv2) cpu:qint8 (9) 6 conv_dw_3 (depthwise_conv2) cpu:qint8 (3) 7 conv_pw_3 (conv2) cpu:qint8 (9) 8 conv_dw_4 (depthwise_conv2) cpu:qint8 (3) 9 conv_pw_4 (conv2) cpu:qint8 (9) 10 conv_dw_5 (depthwise_conv2) cpu:qint8 (3) 11 conv_pw_5 (conv2) cpu:qint8 (9) 12 conv_dw_6 (depthwise_conv2) cpu:qint8 (3) 13 conv_pw_6 (conv2) cpu:qint8 (9) 14 conv_dw_7 (depthwise_conv2) cpu:qint8 (3) 15 conv_pw_7 (conv2) cpu:qint8 (9) 16 conv_dw_8 (depthwise_conv2) cpu:qint8 (3) 17 conv_pw_8 (conv2) cpu:qint8 (9) 18 conv_dw_9 (depthwise_conv2) cpu:qint8 (3) 19 conv_pw_9 (conv2) cpu:qint8 (9) 20 conv_dw_10 (depthwise_conv2) cpu:qint8 (3) 21 conv_pw_10 (conv2) cpu:qint8 (9) 22 conv_dw_11 (depthwise_conv2) cpu:qint8 (3) 23 conv_pw_11 (conv2) cpu:qint8 (9) 24 conv_dw_12 (depthwise_conv2) cpu:qint8 (3) 25 conv_pw_12 (conv2) cpu:qint8 (9) 26 conv_dw_13 (depthwise_conv2) cpu:qint8 (3) 27 conv_pw_13 (conv2) cpu:qint8 (9) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) cpu:qint8 (1) 30 conv_preds (conv2) cpu:qint8 (9) 31 act_softmax (softmax) 32 reshape_2 (reshape) cpu:qint8 (1) 33 sink_0 (sink) ? ROUTINES cpu:qint8 TOTAL ? rm \u00b6 Remove profiling information for the given routine. Usage usage: softneuro rm [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... Arguments Argument Description PROF Directory containing profiling data. ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p PASSWORD, --pass PASSWORD The password required to use the prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -h, --help Shows the command help. Example Remove all routine settings from mobilenet_prof. $ softneuro rm mobilenet_prof removing routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) 2 conv_dw_1 (depthwise_conv2) 3 conv_pw_1 (conv2) 4 conv_dw_2 (depthwise_conv2) 5 conv_pw_2 (conv2) 6 conv_dw_3 (depthwise_conv2) 7 conv_pw_3 (conv2) 8 conv_dw_4 (depthwise_conv2) 9 conv_pw_4 (conv2) 10 conv_dw_5 (depthwise_conv2) 11 conv_pw_5 (conv2) 12 conv_dw_6 (depthwise_conv2) 13 conv_pw_6 (conv2) 14 conv_dw_7 (depthwise_conv2) 15 conv_pw_7 (conv2) 16 conv_dw_8 (depthwise_conv2) 17 conv_pw_8 (conv2) 18 conv_dw_9 (depthwise_conv2) 19 conv_pw_9 (conv2) 20 conv_dw_10 (depthwise_conv2) 21 conv_pw_10 (conv2) 22 conv_dw_11 (depthwise_conv2) 23 conv_pw_11 (conv2) 24 conv_dw_12 (depthwise_conv2) 25 conv_pw_12 (conv2) 26 conv_dw_13 (depthwise_conv2) 27 conv_pw_13 (conv2) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) 30 conv_preds (conv2) 31 act_softmax (softmax) 32 reshape_2 (reshape) 33 sink_0 (sink) ? TOTAL ? ? reset \u00b6 Resets profiling data to defaults. Usage usage: softneuro reset [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... Arguments Argument Description PROF Directory containing profiling data. ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p PASSWORD, --pass PASSWORD The password required to use the prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -h, --help Shows the command help. Example Reset the mobilenet_prof profiling data. $ softneuro reset mobilenet_prof resetting routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 2 conv_dw_1 (depthwise_conv2) cpu (3) 3 conv_pw_1 (conv2) cpu (47) 4 conv_dw_2 (depthwise_conv2) cpu (3) 5 conv_pw_2 (conv2) cpu (47) 6 conv_dw_3 (depthwise_conv2) cpu (3) 7 conv_pw_3 (conv2) cpu (47) 8 conv_dw_4 (depthwise_conv2) cpu (3) 9 conv_pw_4 (conv2) cpu (47) 10 conv_dw_5 (depthwise_conv2) cpu (3) 11 conv_pw_5 (conv2) cpu (47) 12 conv_dw_6 (depthwise_conv2) cpu (3) 13 conv_pw_6 (conv2) cpu (47) 14 conv_dw_7 (depthwise_conv2) cpu (3) 15 conv_pw_7 (conv2) cpu (47) 16 conv_dw_8 (depthwise_conv2) cpu (3) 17 conv_pw_8 (conv2) cpu (47) 18 conv_dw_9 (depthwise_conv2) cpu (3) 19 conv_pw_9 (conv2) cpu (47) 20 conv_dw_10 (depthwise_conv2) cpu (3) 21 conv_pw_10 (conv2) cpu (47) 22 conv_dw_11 (depthwise_conv2) cpu (3) 23 conv_pw_11 (conv2) cpu (47) 24 conv_dw_12 (depthwise_conv2) cpu (3) 25 conv_pw_12 (conv2) cpu (47) 26 conv_dw_13 (depthwise_conv2) cpu (3) 27 conv_pw_13 (conv2) cpu (47) 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 29 reshape_1 (reshape) cpu (1) 30 conv_preds (conv2) cpu (47) 31 act_softmax (softmax) cpu (1) 32 reshape_2 (reshape) cpu (1) 33 sink_0 (sink) ? ROUTINES cpu TOTAL ? status \u00b6 Show the routines, parameters and measured profiling times for each layer. Usage usage: softneuro status [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--at INDEX] [--estimate MODE] [--csv] [--help] PROF Arguments Argument Description PROF Directory containing profiling data. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p, --pass PASSWORD The password required to use the encrypted prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -@, --at INDEX Show only the information for the layer at the given index. --estimate MODE Execution time estimation mode. Can be robust (default), min or ave . --csv Output information in CSV format. --help Show the command help. Example The example information is for after running the profile command to measure execution times. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 28 cpu/avx {\"ops_in_task\":16384} 2 ? (sink) 28 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 213 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} 2 conv_dw_1 (depthwise_conv2) cpu (3) 110 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 3 conv_pw_1 (conv2) cpu (47) 195 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":144} 4 conv_dw_2 (depthwise_conv2) cpu (3) 60 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 5 conv_pw_2 (conv2) cpu (47) 177 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":72} 6 conv_dw_3 (depthwise_conv2) cpu (3) 113 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 7 conv_pw_3 (conv2) cpu (47) 328 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":36} 8 conv_dw_4 (depthwise_conv2) cpu (3) 40 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 9 conv_pw_4 (conv2) cpu (47) 167 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 10 conv_dw_5 (depthwise_conv2) cpu (3) 68 cpu/owc32_avx {\"cache\":8192,\"task_ops\":131072} 11 conv_pw_5 (conv2) cpu (47) 320 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 12 conv_dw_6 (depthwise_conv2) cpu (3) 23 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 13 conv_pw_6 (conv2) cpu (47) 164 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 14 conv_dw_7 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 15 conv_pw_7 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 16 conv_dw_8 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 17 conv_pw_8 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 18 conv_dw_9 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 19 conv_pw_9 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 20 conv_dw_10 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 21 conv_pw_10 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 22 conv_dw_11 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 23 conv_pw_11 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 24 conv_dw_12 (depthwise_conv2) cpu (3) 14 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 25 conv_pw_12 (conv2) cpu (47) 169 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 26 conv_dw_13 (depthwise_conv2) cpu (3) 19 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 27 conv_pw_13 (conv2) cpu (47) 336 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":8} 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 13 cpu/naive {} 29 reshape_1 (reshape) cpu (1) 0 cpu {} 30 conv_preds (conv2) cpu (47) 23 cpu/owc64_avx {\"cache\":8192,\"task_ops\":32768} 31 act_softmax (softmax) cpu (1) 21 cpu/naive {} 32 reshape_2 (reshape) cpu (1) 0 cpu {} 33 sink_0 (sink) 4,308 ROUTINES cpu TOTAL 4,336 profile \u00b6 Run profiling based on profiling data. Usage usage: softneuro profile [--dnn DNN] [--pass PASSWORD] [--help] PROF Arguments Argument Description PROF Directory containing profiling data. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p, --pass PASSWORD The password required to use the encrypted prof file. --help Shows the command help. Example After using the init command to generate profiling data, the profile command measures execution times and saves the profiling information into the profiling data directory. $ softneuro prof mobilenet_prof profiling...100.0% [00:01] tune \u00b6 Tune a DNN file for faster inference times. If profiling data isn't provided, the command automatically runs profiling. Usage usage: softneuro tune [--prof PROF] [--recipe RECIPE] [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--routine ROUTINE[@IDS]]... [--estimate MODE] [--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be tuned. OUTPUT Output tuned DNN file. Flags Flag Description --prof PROF Directory containing profiling data. --recipe RECIPE Directory containing recipe data. --thread NTHREADS How many threads to be used on execution. Defaults to the amount of CPU cores. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. -p, --pass PASSWORD Password if the DNN file is encrypted. -r, --routine ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. --estimate MODE Execution time estimation mode. Can be robust (default), min or ave . -h, --help Shows the command help. Example After tuning the vgg16_tuned.dnn file will be created. $ softneuro tune vgg16.dnn vgg16_tuned.dnn adding cpu routines...done. profiling...100.0% [00:56] ETA[00:00] [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (permute) cpu (1) 155 cpu/naive {} 2 ? (madd) cpu (3) 29 cpu/avx {\"ops_in_task\":16384} 3 ? (sink) 184 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 block1_conv1 (conv2) cpu (67) 1,239 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} : TOTAL 59,463 Tuning for OpenCL usage: $ softneuro tune --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for OpenCL(float16) usage: $ softneuro tune --routine opencl:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for CUDA usage: $ softneuro tune --routine cuda/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for CUDA(float16) usage: $ softneuro tune --routine cuda:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for 8bit quantization mode: $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00]","title":"Run and Profiling Commands"},{"location":"commands/prof-tune/prof-tune.html#run-and-profiling-commands","text":"","title":"Run and Profiling Commands"},{"location":"commands/prof-tune/prof-tune.html#run","text":"Runs inference using the DNN file model. It's possible to get inference results and execution times. Usage usage: softneuro run [-o ONPY]... [-p PASSWORD] [--recipe RECIPE][--batch BATCH] [--ishape SHAPE] [--keep_img_ar PADDINGCOLOR] [--img_resize_mode RESIZEMODE] [--thread NTHREADS] [--noboost] [--affinity MASK[@THREAD_INDICES]] [-r ROUTINE[@LAYER_INDICES]] [-R RPARAMS[@LAYER_INDICES]] [-nobufopt DEVICE] [--lib LIB] [-l LNUM] [--detail] [--detail2] [--bylayer] [-dump DUMPDIR] [-dump2 DUMPRID] [-t NTOPS] [-h] DNN [INPUT [INPUT ...]] Arguments Argument Description DNN DNN file for inference execution. INPUT Input for inference execution. Can be a numpy file or an image file. If not provided, input will be uniform random numbers from [-1, 1]. Flags Flag Description -p PASSWORD --pass PASSWORD Password to run an encrypted DNN file. -o ONPY File name to output the inference results as a numpy file. --recipe RECIPE Set dnn recipe file.\u3000 --batch BATCH Input batch size. --ishape SHAPE Input shape. (Example: 1x224x224x3 ). --keep_img_ar PADDINGCOLOR Keeps aspect ratio when resizing input image. The aspect ratio is not kept by default. Margin space is filled with the color specified by PADDINGCOLOR. PADDINGCOLOR can be specified by RGB value, for example, '0, 0, 0'. --img_resize_mode RESIZEMODE Specifies the resizing mode. 'bilinear' or 'nearest' can be specified. Default is 'bilinear'. --thread NTHREADS How many threads should be used for execution. Defaults to the number of CPU cores. --noboost Set threads as cond wait when they're waiting for a task. If this isn't set, threads will be set to busy wait. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. -r, --routine ROUTINE[@LAYER_INDICES] Set routines to be used. If not set, the usually best available routines will be chosen (e.g. CUDA if there's CUDA support). The default is cpu. If the model is tuned this setting is ignored. If LAYER_INDICES isn't set all layers in main net will be applied. For more information on LAYER_INDICES use the softneuro help layer_indices command. -R RPARAMS[@LAYER_INDICES], --rparams RPARAMS[@LAYER_INDICES] Set routine parameters to be used. If the model is tuned this setting is ignored. If LAYER_INDICES isn't set all layers in main net will be applied. For more information on LAYER_INDICES use the softneuro help layer_indices command. --nobufopt DEVICE Disable the buffer optimizer for routines that run on the given device. --lib LIB Set an OpenCL binary file when using online compilation. -l, --loop LNUM Run inference LNUM times for benchmarking. --detail Show detailed inference statistics. --detail2 Show even more detailed inference statistics. If a layer is made up of other layers this shows the processing times of the internal layers as well. --bylayer Show detailed inference statistics by layer. --dump DUMPDIR Dump each layer output as a numpy file in the given folder. --dump2 DUMPDIR Dump each layer output and internal layer outputs if they exist in the given folder. -t, --top NTOPS Shows the top TOP scores and labels for image classification models. -h, --help Shows the command help. Example $ softneuro run densenet121.dnn --thread 8 --affinity 0xf0@0..3 --affinity 0x0f@4..7 --top 5 --loop 10 shovel.jpg --------------------------------- Top 5 Labels --------------------------------- # SCORE LABEL 1 0.9999 shovel 2 0.0001 hatchet 3 0.0000 broom 4 0.0000 swab 5 0.0000 spatula --------------------------------- Statistics --------------------------------- FUNCTION AVE(us) MIN(us) MAX(us) #RUN Dnn_load() 43,070 43,070 43,070 1 Dnn_compile() 28,567 28,567 28,567 1 Dnn_forward() 39,877 39,751 39,983 10 Used memory: 88,403,968 Bytes --------------------------------- Benchmark --------------------------------- preprocess: 81 68 68 69 70 64 71 69 70 68 main: 39872 39698 39710 39679 39896 39884 39770 39801 39908 39824 TOTAL: 39955 39767 39778 39749 39968 39949 39842 39873 39981 39894 The inference time is given by Dnn_forward . AVE, MIN and MAX are, respectively, the average, minimum and maximum execution times for the number of runs shown under #RUN.","title":"run"},{"location":"commands/prof-tune/prof-tune.html#init","text":"Initializes profiling data. Usage usage: softneuro init [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--help] PROF DNN Arguments Argument Description PROF Directory where the profiling data will be initialized. DNN DNN file to be profiled. Flags Flag Description --thread TNUM How many threads should be used for execution. Defaults to the number of CPU cores. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. --pass PASSWORD Password to profile an encrypted DNN file. -h, --help Shows the command help. Example The command creates the mobilnet_prof directory with profiling data. \u203bThere's no terminal output $ softneuro init mobilenet_prof mobilenet.dnn","title":"init"},{"location":"commands/prof-tune/prof-tune.html#add","text":"Configure routines to layers present in the profiling data. Usage usage: softneuro add [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE[@LAYER_INDICES]]... Arguments Argument Description PROF Directory containing profiling data. ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p, --pass PASSWORD The password required to use the prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -h, --help Shows the command help. Example Set all main network layers to use the cpu:qint8 routine, if supported. $ softneuro add mobilenet_prof cpu:qint8 adding routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu:qint8 (9) 2 conv_dw_1 (depthwise_conv2) cpu:qint8 (3) 3 conv_pw_1 (conv2) cpu:qint8 (9) 4 conv_dw_2 (depthwise_conv2) cpu:qint8 (3) 5 conv_pw_2 (conv2) cpu:qint8 (9) 6 conv_dw_3 (depthwise_conv2) cpu:qint8 (3) 7 conv_pw_3 (conv2) cpu:qint8 (9) 8 conv_dw_4 (depthwise_conv2) cpu:qint8 (3) 9 conv_pw_4 (conv2) cpu:qint8 (9) 10 conv_dw_5 (depthwise_conv2) cpu:qint8 (3) 11 conv_pw_5 (conv2) cpu:qint8 (9) 12 conv_dw_6 (depthwise_conv2) cpu:qint8 (3) 13 conv_pw_6 (conv2) cpu:qint8 (9) 14 conv_dw_7 (depthwise_conv2) cpu:qint8 (3) 15 conv_pw_7 (conv2) cpu:qint8 (9) 16 conv_dw_8 (depthwise_conv2) cpu:qint8 (3) 17 conv_pw_8 (conv2) cpu:qint8 (9) 18 conv_dw_9 (depthwise_conv2) cpu:qint8 (3) 19 conv_pw_9 (conv2) cpu:qint8 (9) 20 conv_dw_10 (depthwise_conv2) cpu:qint8 (3) 21 conv_pw_10 (conv2) cpu:qint8 (9) 22 conv_dw_11 (depthwise_conv2) cpu:qint8 (3) 23 conv_pw_11 (conv2) cpu:qint8 (9) 24 conv_dw_12 (depthwise_conv2) cpu:qint8 (3) 25 conv_pw_12 (conv2) cpu:qint8 (9) 26 conv_dw_13 (depthwise_conv2) cpu:qint8 (3) 27 conv_pw_13 (conv2) cpu:qint8 (9) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) cpu:qint8 (1) 30 conv_preds (conv2) cpu:qint8 (9) 31 act_softmax (softmax) 32 reshape_2 (reshape) cpu:qint8 (1) 33 sink_0 (sink) ? ROUTINES cpu:qint8 TOTAL ?","title":"add"},{"location":"commands/prof-tune/prof-tune.html#rm","text":"Remove profiling information for the given routine. Usage usage: softneuro rm [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... Arguments Argument Description PROF Directory containing profiling data. ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p PASSWORD, --pass PASSWORD The password required to use the prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -h, --help Shows the command help. Example Remove all routine settings from mobilenet_prof. $ softneuro rm mobilenet_prof removing routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) 2 conv_dw_1 (depthwise_conv2) 3 conv_pw_1 (conv2) 4 conv_dw_2 (depthwise_conv2) 5 conv_pw_2 (conv2) 6 conv_dw_3 (depthwise_conv2) 7 conv_pw_3 (conv2) 8 conv_dw_4 (depthwise_conv2) 9 conv_pw_4 (conv2) 10 conv_dw_5 (depthwise_conv2) 11 conv_pw_5 (conv2) 12 conv_dw_6 (depthwise_conv2) 13 conv_pw_6 (conv2) 14 conv_dw_7 (depthwise_conv2) 15 conv_pw_7 (conv2) 16 conv_dw_8 (depthwise_conv2) 17 conv_pw_8 (conv2) 18 conv_dw_9 (depthwise_conv2) 19 conv_pw_9 (conv2) 20 conv_dw_10 (depthwise_conv2) 21 conv_pw_10 (conv2) 22 conv_dw_11 (depthwise_conv2) 23 conv_pw_11 (conv2) 24 conv_dw_12 (depthwise_conv2) 25 conv_pw_12 (conv2) 26 conv_dw_13 (depthwise_conv2) 27 conv_pw_13 (conv2) 28 global_average_pooling2d_1 (global_average_pool) 29 reshape_1 (reshape) 30 conv_preds (conv2) 31 act_softmax (softmax) 32 reshape_2 (reshape) 33 sink_0 (sink) ? TOTAL ? ?","title":"rm"},{"location":"commands/prof-tune/prof-tune.html#reset","text":"Resets profiling data to defaults. Usage usage: softneuro reset [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--help] PROF [ROUTINE@IDS]... Arguments Argument Description PROF Directory containing profiling data. ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p PASSWORD, --pass PASSWORD The password required to use the prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -h, --help Shows the command help. Example Reset the mobilenet_prof profiling data. $ softneuro reset mobilenet_prof resetting routines...done. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 2 ? (sink) ? [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 2 conv_dw_1 (depthwise_conv2) cpu (3) 3 conv_pw_1 (conv2) cpu (47) 4 conv_dw_2 (depthwise_conv2) cpu (3) 5 conv_pw_2 (conv2) cpu (47) 6 conv_dw_3 (depthwise_conv2) cpu (3) 7 conv_pw_3 (conv2) cpu (47) 8 conv_dw_4 (depthwise_conv2) cpu (3) 9 conv_pw_4 (conv2) cpu (47) 10 conv_dw_5 (depthwise_conv2) cpu (3) 11 conv_pw_5 (conv2) cpu (47) 12 conv_dw_6 (depthwise_conv2) cpu (3) 13 conv_pw_6 (conv2) cpu (47) 14 conv_dw_7 (depthwise_conv2) cpu (3) 15 conv_pw_7 (conv2) cpu (47) 16 conv_dw_8 (depthwise_conv2) cpu (3) 17 conv_pw_8 (conv2) cpu (47) 18 conv_dw_9 (depthwise_conv2) cpu (3) 19 conv_pw_9 (conv2) cpu (47) 20 conv_dw_10 (depthwise_conv2) cpu (3) 21 conv_pw_10 (conv2) cpu (47) 22 conv_dw_11 (depthwise_conv2) cpu (3) 23 conv_pw_11 (conv2) cpu (47) 24 conv_dw_12 (depthwise_conv2) cpu (3) 25 conv_pw_12 (conv2) cpu (47) 26 conv_dw_13 (depthwise_conv2) cpu (3) 27 conv_pw_13 (conv2) cpu (47) 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 29 reshape_1 (reshape) cpu (1) 30 conv_preds (conv2) cpu (47) 31 act_softmax (softmax) cpu (1) 32 reshape_2 (reshape) cpu (1) 33 sink_0 (sink) ? ROUTINES cpu TOTAL ?","title":"reset"},{"location":"commands/prof-tune/prof-tune.html#status","text":"Show the routines, parameters and measured profiling times for each layer. Usage usage: softneuro status [--dnn DNN] [--pass PASSWORD] [--ref REF] [--ref-pass REF_PASSWORD] [--at INDEX] [--estimate MODE] [--csv] [--help] PROF Arguments Argument Description PROF Directory containing profiling data. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p, --pass PASSWORD The password required to use the encrypted prof file. --ref REF the reference dnn file when profiling a secret dnn. --ref-pass REF_PASSWORD the password for REF. -@, --at INDEX Show only the information for the layer at the given index. --estimate MODE Execution time estimation mode. Can be robust (default), min or ave . --csv Output information in CSV format. --help Show the command help. Example The example information is for after running the profile command to measure execution times. $ softneuro status mobilenet_prof [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (madd) cpu (3) 28 cpu/avx {\"ops_in_task\":16384} 2 ? (sink) 28 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 conv1 (conv2) cpu (15) 213 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} 2 conv_dw_1 (depthwise_conv2) cpu (3) 110 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 3 conv_pw_1 (conv2) cpu (47) 195 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":144} 4 conv_dw_2 (depthwise_conv2) cpu (3) 60 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 5 conv_pw_2 (conv2) cpu (47) 177 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":72} 6 conv_dw_3 (depthwise_conv2) cpu (3) 113 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 7 conv_pw_3 (conv2) cpu (47) 328 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":36} 8 conv_dw_4 (depthwise_conv2) cpu (3) 40 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 9 conv_pw_4 (conv2) cpu (47) 167 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 10 conv_dw_5 (depthwise_conv2) cpu (3) 68 cpu/owc32_avx {\"cache\":8192,\"task_ops\":131072} 11 conv_pw_5 (conv2) cpu (47) 320 cpu/m1x1l_avx {\"cache\":1048576,\"oxynum_in_task\":96} 12 conv_dw_6 (depthwise_conv2) cpu (3) 23 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 13 conv_pw_6 (conv2) cpu (47) 164 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 14 conv_dw_7 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 15 conv_pw_7 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 16 conv_dw_8 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 17 conv_pw_8 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 18 conv_dw_9 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 19 conv_pw_9 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 20 conv_dw_10 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 21 conv_pw_10 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 22 conv_dw_11 (depthwise_conv2) cpu (3) 34 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 23 conv_pw_11 (conv2) cpu (47) 313 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 24 conv_dw_12 (depthwise_conv2) cpu (3) 14 cpu/owc32_avx {\"cache\":8192,\"task_ops\":65536} 25 conv_pw_12 (conv2) cpu (47) 169 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":16} 26 conv_dw_13 (depthwise_conv2) cpu (3) 19 cpu/owc32_avx {\"cache\":8192,\"task_ops\":32768} 27 conv_pw_13 (conv2) cpu (47) 336 cpu/m1x1l2_avx {\"cache\":1048576,\"oxynum_in_task\":8} 28 global_average_pooling2d_1 (global_average_pool) cpu (1) 13 cpu/naive {} 29 reshape_1 (reshape) cpu (1) 0 cpu {} 30 conv_preds (conv2) cpu (47) 23 cpu/owc64_avx {\"cache\":8192,\"task_ops\":32768} 31 act_softmax (softmax) cpu (1) 21 cpu/naive {} 32 reshape_2 (reshape) cpu (1) 0 cpu {} 33 sink_0 (sink) 4,308 ROUTINES cpu TOTAL 4,336","title":"status"},{"location":"commands/prof-tune/prof-tune.html#profile","text":"Run profiling based on profiling data. Usage usage: softneuro profile [--dnn DNN] [--pass PASSWORD] [--help] PROF Arguments Argument Description PROF Directory containing profiling data. Flags Flag Description --dnn DNN A DNN file used to create profiling data. -p, --pass PASSWORD The password required to use the encrypted prof file. --help Shows the command help. Example After using the init command to generate profiling data, the profile command measures execution times and saves the profiling information into the profiling data directory. $ softneuro prof mobilenet_prof profiling...100.0% [00:01]","title":"profile"},{"location":"commands/prof-tune/prof-tune.html#tune","text":"Tune a DNN file for faster inference times. If profiling data isn't provided, the command automatically runs profiling. Usage usage: softneuro tune [--prof PROF] [--recipe RECIPE] [--thread NTHREADS] [--affinity MASK[@THREAD_INDICES]] [--pass PASSWORD] [--routine ROUTINE[@IDS]]... [--estimate MODE] [--help] INPUT OUTPUT Arguments Argument Description INPUT DNN file to be tuned. OUTPUT Output tuned DNN file. Flags Flag Description --prof PROF Directory containing profiling data. --recipe RECIPE Directory containing recipe data. --thread NTHREADS How many threads to be used on execution. Defaults to the amount of CPU cores. --affinity MASK[@THREAD_INDICES] Use the affinity mask given by MASK on the threads given by THREAD_INDICES . MASK should be a little endian hexadecimal (0x..), binary (0b..), or decimal number. If THREAD_INDICES isn't set all threads will use the given mask. For more information on THREAD_INDICES use the softneuro help thread_indices command. -p, --pass PASSWORD Password if the DNN file is encrypted. -r, --routine ROUTINE[@LAYER_INDICES] Set the routine given by ROUTINE to the layers given by LAYER_INDICES . If LAYER_INDICES isn't set, the routine will be set to all layers in the main network. The ROUTINE format can be checked with the softneuro help routine_desc command, and the LAYER_INDICES format can be checked with the softneuro help layer_indices command. --estimate MODE Execution time estimation mode. Can be robust (default), min or ave . -h, --help Shows the command help. Example After tuning the vgg16_tuned.dnn file will be created. $ softneuro tune vgg16.dnn vgg16_tuned.dnn adding cpu routines...done. profiling...100.0% [00:56] ETA[00:00] [preprocess] # NAME ROUTINE TIME DESC PARAMS 0 ? (source) 1 ? (permute) cpu (1) 155 cpu/naive {} 2 ? (madd) cpu (3) 29 cpu/avx {\"ops_in_task\":16384} 3 ? (sink) 184 [main] # NAME ROUTINE TIME DESC PARAMS 0 input_1 (source) 1 block1_conv1 (conv2) cpu (67) 1,239 cpu/owc64_avx {\"cache\":8192,\"task_ops\":131072} : TOTAL 59,463 Tuning for OpenCL usage: $ softneuro tune --routine opencl/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for OpenCL(float16) usage: $ softneuro tune --routine opencl:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for CUDA usage: $ softneuro tune --routine cuda/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for CUDA(float16) usage: $ softneuro tune --routine cuda:float16/fast@2..23 --routine cpu@1,24 vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00] Tuning for 8bit quantization mode: $ softneuro tune --routine cpu:qint8/fast vgg16.dnn vgg16_tuned.dnn profiling..100.0% [01:23] ETR[00:00]","title":"tune"}]}