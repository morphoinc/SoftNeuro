{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"SoftNeuro Python API documents This document describes the usage of SoftNeuro API.","title":"Top"},{"location":"index.html#softneuro-python-api-documents","text":"This document describes the usage of SoftNeuro API.","title":"SoftNeuro Python API documents"},{"location":"device.html","text":"Device softneuro . core . Device ( * args , ** kwargs ) Device class which holds device specific information such as memory model, thread model, cache line size and so on. This is a private class of softneuro, instance can not be constructed directly,users can get device instance using softneuro.get_devices() . Attributes cache_line_size : Cache line size. features : Features. index : Device index. memory_model : Device memory model. name : Device name. thread_model : Device thread model.","title":"Device"},{"location":"device.html#device","text":"softneuro . core . Device ( * args , ** kwargs ) Device class which holds device specific information such as memory model, thread model, cache line size and so on. This is a private class of softneuro, instance can not be constructed directly,users can get device instance using softneuro.get_devices() . Attributes cache_line_size : Cache line size. features : Features. index : Device index. memory_model : Device memory model. name : Device name. thread_model : Device thread model.","title":"Device"},{"location":"dnn.html","text":"Dnn Dnn (deep neural network) class consists of DnnNet. softneuro . Dnn ( filename , password , is_lazy ) Arguments filename : The path of input dnn file to open. password : Password for decrypting an encrypted dnn file. is_lazy : Load the dnn file in lazy mode to save memory. Attributes affinity_masks : An affinity mask represented in hex (\"0x..\") or binary (\"0b..\") form. batch_size : The number of batch size to execute forward propagation. inputs : A series of DnnInput which consist of inputs of the Dnn . is_dump_enabled : A flag that shows whether dumping all the tensors inside the Dnn object during forward propagation. is_empty : Whether the dnn is empty or not. is_lazy : Whether the dnn is lazy loaded or not. is_password_protected : Whether the dnn is password-protected or not. is_secret : Whether secret or not. In addition to crypto, it is hold for keeping non-secret after secret save. is_tuned : Whether the dnn is tuned or not. nets : A series of DnnNet objects which consist of the neural network. outputs : A series of DnnOutput which consist of output of the Dnn . state : The internal state of Dnn object that goes from STATE_NONE through STATE_INITIALIZED and STATE_PARSED to STATE_COMPILED. tensors : A series of Tensors stored in the Dnn object. thread_num : Number of threads to be used,default value is the number of cpu cores. tune_params : Tuning parameters. Examples dnn = softneuro . Dnn ( 'model.dnn' , password ) dnn . compile () dnn . inputs [ 0 ] . set_blob ( input_tensor ) dnn . forward () output = dnn . outputs [ 0 ] . blob . data clear Dnn . clear () Removes all tensors and nets. compile Dnn . compile () Compiles the dnn to run forward propagation. forward Dnn . forward () Executes the forward propagation once on the network. load Dnn . load ( filename , password = b \"\" , is_lazy = False ) Reads the dnn from a file. Arguments filename : The path to the dnn file. password : A password to decrypt an encrypted dnn file. is_lazy : Load the dnn file in lazy mode to save memory. parse Dnn . parse () Parses the dnn. recycle Dnn . recycle () Recycles the dnn by decompiling and unparsing. save Dnn . save ( filename , password = b \"\" , is_secret = False ) Saves the dnn to a file. Arguments filename : The path to the dnn file. is_secret : Save the dnn file in secret mode. password : A password to encrypt the dnn file. tune Dnn . tune ( i_recipe ) Tunes the Dnn according to DnnRecipe. Arguments i_recipe : DnnRecipe used for tuning the dnn. Examples import softneuro import sys # load a dnn. dnn = softneuro . Dnn ( sys . argv [ 1 ]) # profile. prof = softneuro . DnnProf ( dnn ) prof . add ( 'cpu' ) prof . add ( 'cpu:qint8' ) prof . profile () prof . save ( 'model.prof' ) # optimize. optimizer = softneuro . DnnOptimizer ( prof ) optimizer . optimize () # make recipe. recipe = softneuro . DnnRecipe ( optimizer . plan ) recipe . strip () recipe . save ( 'model.recipe' ) # tune. dnn . tune ( recipe ) dnn . save ( 'model_tuned.dnn' )","title":"Dnn Object & Basic commands"},{"location":"dnn.html#dnn","text":"Dnn (deep neural network) class consists of DnnNet. softneuro . Dnn ( filename , password , is_lazy ) Arguments filename : The path of input dnn file to open. password : Password for decrypting an encrypted dnn file. is_lazy : Load the dnn file in lazy mode to save memory. Attributes affinity_masks : An affinity mask represented in hex (\"0x..\") or binary (\"0b..\") form. batch_size : The number of batch size to execute forward propagation. inputs : A series of DnnInput which consist of inputs of the Dnn . is_dump_enabled : A flag that shows whether dumping all the tensors inside the Dnn object during forward propagation. is_empty : Whether the dnn is empty or not. is_lazy : Whether the dnn is lazy loaded or not. is_password_protected : Whether the dnn is password-protected or not. is_secret : Whether secret or not. In addition to crypto, it is hold for keeping non-secret after secret save. is_tuned : Whether the dnn is tuned or not. nets : A series of DnnNet objects which consist of the neural network. outputs : A series of DnnOutput which consist of output of the Dnn . state : The internal state of Dnn object that goes from STATE_NONE through STATE_INITIALIZED and STATE_PARSED to STATE_COMPILED. tensors : A series of Tensors stored in the Dnn object. thread_num : Number of threads to be used,default value is the number of cpu cores. tune_params : Tuning parameters. Examples dnn = softneuro . Dnn ( 'model.dnn' , password ) dnn . compile () dnn . inputs [ 0 ] . set_blob ( input_tensor ) dnn . forward () output = dnn . outputs [ 0 ] . blob . data","title":"Dnn"},{"location":"dnn.html#clear","text":"Dnn . clear () Removes all tensors and nets.","title":"clear"},{"location":"dnn.html#compile","text":"Dnn . compile () Compiles the dnn to run forward propagation.","title":"compile"},{"location":"dnn.html#forward","text":"Dnn . forward () Executes the forward propagation once on the network.","title":"forward"},{"location":"dnn.html#load","text":"Dnn . load ( filename , password = b \"\" , is_lazy = False ) Reads the dnn from a file. Arguments filename : The path to the dnn file. password : A password to decrypt an encrypted dnn file. is_lazy : Load the dnn file in lazy mode to save memory.","title":"load"},{"location":"dnn.html#parse","text":"Dnn . parse () Parses the dnn.","title":"parse"},{"location":"dnn.html#recycle","text":"Dnn . recycle () Recycles the dnn by decompiling and unparsing.","title":"recycle"},{"location":"dnn.html#save","text":"Dnn . save ( filename , password = b \"\" , is_secret = False ) Saves the dnn to a file. Arguments filename : The path to the dnn file. is_secret : Save the dnn file in secret mode. password : A password to encrypt the dnn file.","title":"save"},{"location":"dnn.html#tune","text":"Dnn . tune ( i_recipe ) Tunes the Dnn according to DnnRecipe. Arguments i_recipe : DnnRecipe used for tuning the dnn. Examples import softneuro import sys # load a dnn. dnn = softneuro . Dnn ( sys . argv [ 1 ]) # profile. prof = softneuro . DnnProf ( dnn ) prof . add ( 'cpu' ) prof . add ( 'cpu:qint8' ) prof . profile () prof . save ( 'model.prof' ) # optimize. optimizer = softneuro . DnnOptimizer ( prof ) optimizer . optimize () # make recipe. recipe = softneuro . DnnRecipe ( optimizer . plan ) recipe . strip () recipe . save ( 'model.recipe' ) # tune. dnn . tune ( recipe ) dnn . save ( 'model_tuned.dnn' )","title":"tune"},{"location":"dnn_io.html","text":"DnnInput DnnInput class that consists of input array of Dnn . This is a private class of softneuro, instance can not be constructed directly,users can get DnnInput instance using Dnn.get_input() . Attributes tensor : A Tensor object that represents input tensor. blob : A Tensor object that stores entity of tensor depending on dtype of routines. Available after Dnn.compile() . attrs : A Params object as the attributes of the input. Note If blob is accessed before Dnn.compile() , Dnn.compile() is automatically called so that blob gets available. Examples import softneuro from PIL import Image # Load dnn file and compile dnn = softneuro . Dnn ( 'model.dnn' ) dnn . compile () # Set image data to the input image = Image . open ( 'image001.jpg' ) input = dnn . input [ 0 ] input . set_blob ( image ) set_blob DnnInput . set_blob ( data , batch = 0 ) Set input blob to DnnInput. Arguments data : A tensor as an input data. batch : Batch size. DnnOutput DnnOutput class that consists of output array of Dnn . This is a private class of softneuro, instance can not be constructed directly,users can get DnnOutput instance using Dnn.get_output() . Attributes tensor : A Tensor object that represents output tensor. blob : A Tensor object that stores entity of tensor depending on dtype of routines. Available after Dnn.compile() . attrs : A Params object as the attributes of the output. Note If blob is accessed before Dnn.compile() , Dnn.compile() is automatically called so that blob gets available. Examples # Run inference dnn . forward () # Get output data output = dnn . output [ 0 ] params = output . attrs labels_param = params [ 'labels' ] data = output . blob . data","title":"Dnn Input & Output"},{"location":"dnn_io.html#dnninput","text":"DnnInput class that consists of input array of Dnn . This is a private class of softneuro, instance can not be constructed directly,users can get DnnInput instance using Dnn.get_input() . Attributes tensor : A Tensor object that represents input tensor. blob : A Tensor object that stores entity of tensor depending on dtype of routines. Available after Dnn.compile() . attrs : A Params object as the attributes of the input. Note If blob is accessed before Dnn.compile() , Dnn.compile() is automatically called so that blob gets available. Examples import softneuro from PIL import Image # Load dnn file and compile dnn = softneuro . Dnn ( 'model.dnn' ) dnn . compile () # Set image data to the input image = Image . open ( 'image001.jpg' ) input = dnn . input [ 0 ] input . set_blob ( image )","title":"DnnInput"},{"location":"dnn_io.html#set_blob","text":"DnnInput . set_blob ( data , batch = 0 ) Set input blob to DnnInput. Arguments data : A tensor as an input data. batch : Batch size.","title":"set_blob"},{"location":"dnn_io.html#dnnoutput","text":"DnnOutput class that consists of output array of Dnn . This is a private class of softneuro, instance can not be constructed directly,users can get DnnOutput instance using Dnn.get_output() . Attributes tensor : A Tensor object that represents output tensor. blob : A Tensor object that stores entity of tensor depending on dtype of routines. Available after Dnn.compile() . attrs : A Params object as the attributes of the output. Note If blob is accessed before Dnn.compile() , Dnn.compile() is automatically called so that blob gets available. Examples # Run inference dnn . forward () # Get output data output = dnn . output [ 0 ] params = output . attrs labels_param = params [ 'labels' ] data = output . blob . data","title":"DnnOutput"},{"location":"dnn_layer.html","text":"DnnLayer softneuro . core . DnnLayer ( * args , ** kwargs ) DnnLayer class is the basic element of DnnNet. This is a private class of softneuro, instance can not be constructed directly,users can get DnnLayer instance using DnnNet.add_layer() , DnnNet.get_input_layer() , DnnNet.get_output_layer() , etc. Attributes attrs : Attribuites of the layer. child_net : child net. compiled_routine_desc : Routine descriptor of the compiled routine. compiled_routine_params : Parameters of the compiled routine. index : index of the layer in the owner DnnNet. inputs : A series of DnnLayerInput objects of the layer. is_constant : whether the layer is constant or not. is_failed : whether the layer is failed to parse, routinize, precompile or compile. is_immutable : whether the layer is immutable or not. is_mutable : whether the layer is immutable or not. name : Name of the layer. owner : DnnNet that the layer belongs to. params : Parameters of the layer. parsed_params : Parsed parameters of the layer . routine_desc : Routine descriptor of the layer such as cpu/naive, cpu/neon. routine_params : Parameters of the routine. state : State of dnn layer. type : Type of the layer. outputs : A series of DnnLayerOutput objects of the layer. weights : A series of weights in the layer. connect DnnLayer . connect ( i_output_index , i_next_layer , i_input_index =- 1 ) Connect an output of the layer to an input of another succeeding layer. Arguments i_output_index : The index of output to connect. i_next_layer : A succeeding DnnLayer object to be connected. i_input_index : The index of input on the succeeding layer. disconnect DnnLayer . disconnect ( i_output_index , i_next_layer , i_input_index ) Disconnect an output of the layer from an input of another succeeding layer. Arguments i_output_index : The index of output to disconnect. i_next_layer : A succeeding DnnLayer object to be disconnected. i_input_index : The index of input on the succeeding layer. disconnect_all DnnLayer . disconnect_all () Disconnects the layer from other layers. get_input DnnLayer . get_input ( input_index ) Gets input object DnnLayerInput of the layer. Arguments input_index : The input index of the interest. Returns Type : DnnLayerInput,input of the layer. get_output DnnLayer . get_output ( output_index ) Gets output object DnnLayerOutput of the layer. Arguments output_index : The input index of the interest. Returns Type : DnnLayerOutput,output of the layer. set_weight DnnLayer . set_weight ( key , val ) Sets weight to the layer. Arguments key : A string for the name of the weight. val : An object for the weight values, any of the following data types. Data types for val int float numpy.float numpy.ndarray Tensor","title":"DnnLayer"},{"location":"dnn_layer.html#dnnlayer","text":"softneuro . core . DnnLayer ( * args , ** kwargs ) DnnLayer class is the basic element of DnnNet. This is a private class of softneuro, instance can not be constructed directly,users can get DnnLayer instance using DnnNet.add_layer() , DnnNet.get_input_layer() , DnnNet.get_output_layer() , etc. Attributes attrs : Attribuites of the layer. child_net : child net. compiled_routine_desc : Routine descriptor of the compiled routine. compiled_routine_params : Parameters of the compiled routine. index : index of the layer in the owner DnnNet. inputs : A series of DnnLayerInput objects of the layer. is_constant : whether the layer is constant or not. is_failed : whether the layer is failed to parse, routinize, precompile or compile. is_immutable : whether the layer is immutable or not. is_mutable : whether the layer is immutable or not. name : Name of the layer. owner : DnnNet that the layer belongs to. params : Parameters of the layer. parsed_params : Parsed parameters of the layer . routine_desc : Routine descriptor of the layer such as cpu/naive, cpu/neon. routine_params : Parameters of the routine. state : State of dnn layer. type : Type of the layer. outputs : A series of DnnLayerOutput objects of the layer. weights : A series of weights in the layer.","title":"DnnLayer"},{"location":"dnn_layer.html#connect","text":"DnnLayer . connect ( i_output_index , i_next_layer , i_input_index =- 1 ) Connect an output of the layer to an input of another succeeding layer. Arguments i_output_index : The index of output to connect. i_next_layer : A succeeding DnnLayer object to be connected. i_input_index : The index of input on the succeeding layer.","title":"connect"},{"location":"dnn_layer.html#disconnect","text":"DnnLayer . disconnect ( i_output_index , i_next_layer , i_input_index ) Disconnect an output of the layer from an input of another succeeding layer. Arguments i_output_index : The index of output to disconnect. i_next_layer : A succeeding DnnLayer object to be disconnected. i_input_index : The index of input on the succeeding layer.","title":"disconnect"},{"location":"dnn_layer.html#disconnect_all","text":"DnnLayer . disconnect_all () Disconnects the layer from other layers.","title":"disconnect_all"},{"location":"dnn_layer.html#get_input","text":"DnnLayer . get_input ( input_index ) Gets input object DnnLayerInput of the layer. Arguments input_index : The input index of the interest. Returns Type : DnnLayerInput,input of the layer.","title":"get_input"},{"location":"dnn_layer.html#get_output","text":"DnnLayer . get_output ( output_index ) Gets output object DnnLayerOutput of the layer. Arguments output_index : The input index of the interest. Returns Type : DnnLayerOutput,output of the layer.","title":"get_output"},{"location":"dnn_layer.html#set_weight","text":"DnnLayer . set_weight ( key , val ) Sets weight to the layer. Arguments key : A string for the name of the weight. val : An object for the weight values, any of the following data types. Data types for val int float numpy.float numpy.ndarray Tensor","title":"set_weight"},{"location":"dnn_layer_io.html","text":"DnnLayerInput softneuro . core . DnnLayerInput ( layer , input_index ) Input class that consists of input of a layer. Attributes prev_layer : The preceding DnnLayer object of the input. prev_layer_output_index : Output index in the preceding DnnLayer object. tensor : The Tensor object of the input. Examples dnn = softneuro . Dnn () net = dnn . add_net ( 'test' ) layer0 = net . add_layer ( 'source0' , 'source' ) layer1 = net . add_layer ( 'source1' , 'source' ) layer2 = net . add_layer ( 'add0' , 'add' ) layer3 = net . add_layer ( 'add1' , 'add' ) layer0 . connect ( 0 , layer2 , 0 ) layer0 . connect ( 0 , layer3 , 0 ) layer1 . connect ( 0 , layer2 , 1 ) layer1 . connect ( 0 , layer3 , 1 ) dnn_layer_input0 = layer2 . inputs [ 0 ] print ( dnn_layer_input0 . prev_layer ) # Results in DnnLayer(name='source0', type='source', outputs=[..]) print ( dnn_layer_input0 . prev_layer_output_index ) # Results in 0 DnnLayerOutput Output class that consists of output of a layer. Attributes next_layers : A series of DnnLayer objects those are connected to the layer. next_layer_input_indices : A series of input indices of succeeding layers. tensor : The Tensor object of output. Examples dnn = softneuro . Dnn () net = dnn . add_net ( 'test' ) layer0 = net . add_layer ( 'source0' , 'source' ) layer1 = net . add_layer ( 'source1' , 'source' ) layer2 = net . add_layer ( 'add0' , 'add' ) layer3 = net . add_layer ( 'add1' , 'add' ) # Connect between layers layer0 . connect ( 0 , layer2 , 0 ) layer0 . connect ( 0 , layer3 , 0 ) layer1 . connect ( 0 , layer2 , 1 ) layer1 . connect ( 0 , layer3 , 1 ) # next_layers output0 = layer0 . outputs [ 0 ] output1 = layer1 . outputs [ 0 ] layer = output0 . next_layers [ 0 ] print ( layer ) # Results in DnnLayer(name='add0', type='add', inputs=[..], outputs=[..]) # next_layer_input_indices indices0 = output0 . next_layer_input_indices print ( indices0 ) # Results in [0, 0] indices1 = output1 . next_layer_input_indices print ( indices1 ) # Results in [1, 1]","title":"DnnLayer Input & Output"},{"location":"dnn_layer_io.html#dnnlayerinput","text":"softneuro . core . DnnLayerInput ( layer , input_index ) Input class that consists of input of a layer. Attributes prev_layer : The preceding DnnLayer object of the input. prev_layer_output_index : Output index in the preceding DnnLayer object. tensor : The Tensor object of the input. Examples dnn = softneuro . Dnn () net = dnn . add_net ( 'test' ) layer0 = net . add_layer ( 'source0' , 'source' ) layer1 = net . add_layer ( 'source1' , 'source' ) layer2 = net . add_layer ( 'add0' , 'add' ) layer3 = net . add_layer ( 'add1' , 'add' ) layer0 . connect ( 0 , layer2 , 0 ) layer0 . connect ( 0 , layer3 , 0 ) layer1 . connect ( 0 , layer2 , 1 ) layer1 . connect ( 0 , layer3 , 1 ) dnn_layer_input0 = layer2 . inputs [ 0 ] print ( dnn_layer_input0 . prev_layer ) # Results in DnnLayer(name='source0', type='source', outputs=[..]) print ( dnn_layer_input0 . prev_layer_output_index ) # Results in 0","title":"DnnLayerInput"},{"location":"dnn_layer_io.html#dnnlayeroutput","text":"Output class that consists of output of a layer. Attributes next_layers : A series of DnnLayer objects those are connected to the layer. next_layer_input_indices : A series of input indices of succeeding layers. tensor : The Tensor object of output. Examples dnn = softneuro . Dnn () net = dnn . add_net ( 'test' ) layer0 = net . add_layer ( 'source0' , 'source' ) layer1 = net . add_layer ( 'source1' , 'source' ) layer2 = net . add_layer ( 'add0' , 'add' ) layer3 = net . add_layer ( 'add1' , 'add' ) # Connect between layers layer0 . connect ( 0 , layer2 , 0 ) layer0 . connect ( 0 , layer3 , 0 ) layer1 . connect ( 0 , layer2 , 1 ) layer1 . connect ( 0 , layer3 , 1 ) # next_layers output0 = layer0 . outputs [ 0 ] output1 = layer1 . outputs [ 0 ] layer = output0 . next_layers [ 0 ] print ( layer ) # Results in DnnLayer(name='add0', type='add', inputs=[..], outputs=[..]) # next_layer_input_indices indices0 = output0 . next_layer_input_indices print ( indices0 ) # Results in [0, 0] indices1 = output1 . next_layer_input_indices print ( indices1 ) # Results in [1, 1]","title":"DnnLayerOutput"},{"location":"dnn_layer_plan.html","text":"DnnLayerPlan softneuro . core . DnnLayerPlan ( * args , ** kwargs ) DnnLayerPlan class, composes DnnNetPlan. This is a private class of softneuro, instance can not be constructed directly, users can get DnnLayerPlan instance using DnnPlan.find_layer_plan() . Attributes adapt_usec : Processing time for adapt routines (usec). name : Layer name. routine_desc : Optimal routine descriptor. routine_params : Optimal routine parameters. schemas : Routine schema plans. type : Layer type. usec : Forward time (usec).","title":"DnnLayerPlan"},{"location":"dnn_layer_plan.html#dnnlayerplan","text":"softneuro . core . DnnLayerPlan ( * args , ** kwargs ) DnnLayerPlan class, composes DnnNetPlan. This is a private class of softneuro, instance can not be constructed directly, users can get DnnLayerPlan instance using DnnPlan.find_layer_plan() . Attributes adapt_usec : Processing time for adapt routines (usec). name : Layer name. routine_desc : Optimal routine descriptor. routine_params : Optimal routine parameters. schemas : Routine schema plans. type : Layer type. usec : Forward time (usec).","title":"DnnLayerPlan"},{"location":"dnn_manipulations.html","text":"add_net Dnn . add_net ( name ) Adds another DnnNet to Dnn . Arguments name : A string to specify the name of the added DnnNet like 'preprocess', 'main' etc. Returns Type : DnnNet,DnnNet added. add_tensor Dnn . add_tensor ( name ) Adds a Tensor to Dnn . Arguments name : A string to specify the name of the Tensor to be added. Returns Type : Tensor,Tensor added. decompose Dnn . decompose ( i_net_name , i_parts ) Decomposes the Dnn according to given DnnNetPartition. The main purpose of decompose operation is to make a part of net be calculated by different inference engine. To make the decomposed net be calculated by different inference engine, the decomposed net need to be squashed (see squash_net ). Arguments i_net_name : The net name to be decomposed. i_parts : The DnnNetPartition, partitioning position where dnn is decomposed. Examples import softneuro import sys # load a dnn. dnn = softneuro . Dnn ( sys . argv [ 1 ]) # make partitions. parts = softneuro . DnnNetPartition () parts . add_interval ( 'input' , 'conv2_1' ) # make subnet-0 parts . add_interval ( 'conv2_2' , 'output' ) # make subnet-1 # decompose dnn . decompose ( 'main' , parts ) # If the main-net is fully represented by sub-nets, # the main-net is no longer needed. dnn . removeNet ( dnn . findNet ( 'main' )) find_main_net Dnn . find_main_net () Finds the main DnnNet from Dnn . Returns Type : DnnNet,DnnNet if found else NULL. find_net Dnn . find_net ( name ) Finds a DnnNet with a specific name from Dnn . Arguments name : A string to specify the name of the DnnNet to find. Returns Type : DnnNet,DnnNet if found else NULL. find_tensor Dnn . find_tensor ( name ) Finds a Tensor object with a specific name from Dnn . Arguments name : A string to specify the name of the Tensor to be found. Returns Type : Tensor,Tensor if found else NULL. get_input Dnn . get_input ( input_index ) Gets input object DnnInput of the Dnn . Arguments input_index : The input index of the interest. Returns Type : DnnInput, DnnInput of the Dnn . get_output Dnn . get_output ( output_index ) Gets output object DnnOutput of the Dnn . Arguments output_index : The output index of the interest. Returns Type : DnnOutput, DnnOutput of the Dnn . get_model Dnn . get_model () Gets a model as a json string. Returns Type : str,json string of model. is_buf_opt_enabled Dnn . is_buf_opt_enabled ( device ) Returns a boolean whether buffer optimization is enabled (true) or disabled (false). Arguments device : The Device of the interest. Returns Type : bool,true if optimization is enabled else false. remove_net Dnn . remove_net ( net ) Removes a DnnNet from Dnn . Arguments net : A DnnNet object to be removed. remove_tensor Dnn . remove_tensor ( tensor ) Removes a Tensor from Dnn . Arguments tensor : A Tensor object to be removed from Dnn . set_model Dnn . set_model ( model ) Sets a model from json string. Arguments model : A json string to be set as model. set_buf_opt_enabled Dnn . set_buf_opt_enabled ( device , is_enabled ) Enables or disables buffer optimization. Arguments device : Device for which buffer optimization will be enabled/disabled. is_enabled : Boolean indicating whether it will be enabled (true) or disabled (false). squash_net Dnn . squash_net ( net_name ) Squashes the net. The squashed net becomes a pseudo single layer of type complex. The squashed complex layer can be calculated by external inference engine. Arguments net_name : The net to be squashed.","title":"Dnn Manipulations"},{"location":"dnn_manipulations.html#add_net","text":"Dnn . add_net ( name ) Adds another DnnNet to Dnn . Arguments name : A string to specify the name of the added DnnNet like 'preprocess', 'main' etc. Returns Type : DnnNet,DnnNet added.","title":"add_net"},{"location":"dnn_manipulations.html#add_tensor","text":"Dnn . add_tensor ( name ) Adds a Tensor to Dnn . Arguments name : A string to specify the name of the Tensor to be added. Returns Type : Tensor,Tensor added.","title":"add_tensor"},{"location":"dnn_manipulations.html#decompose","text":"Dnn . decompose ( i_net_name , i_parts ) Decomposes the Dnn according to given DnnNetPartition. The main purpose of decompose operation is to make a part of net be calculated by different inference engine. To make the decomposed net be calculated by different inference engine, the decomposed net need to be squashed (see squash_net ). Arguments i_net_name : The net name to be decomposed. i_parts : The DnnNetPartition, partitioning position where dnn is decomposed. Examples import softneuro import sys # load a dnn. dnn = softneuro . Dnn ( sys . argv [ 1 ]) # make partitions. parts = softneuro . DnnNetPartition () parts . add_interval ( 'input' , 'conv2_1' ) # make subnet-0 parts . add_interval ( 'conv2_2' , 'output' ) # make subnet-1 # decompose dnn . decompose ( 'main' , parts ) # If the main-net is fully represented by sub-nets, # the main-net is no longer needed. dnn . removeNet ( dnn . findNet ( 'main' ))","title":"decompose"},{"location":"dnn_manipulations.html#find_main_net","text":"Dnn . find_main_net () Finds the main DnnNet from Dnn . Returns Type : DnnNet,DnnNet if found else NULL.","title":"find_main_net"},{"location":"dnn_manipulations.html#find_net","text":"Dnn . find_net ( name ) Finds a DnnNet with a specific name from Dnn . Arguments name : A string to specify the name of the DnnNet to find. Returns Type : DnnNet,DnnNet if found else NULL.","title":"find_net"},{"location":"dnn_manipulations.html#find_tensor","text":"Dnn . find_tensor ( name ) Finds a Tensor object with a specific name from Dnn . Arguments name : A string to specify the name of the Tensor to be found. Returns Type : Tensor,Tensor if found else NULL.","title":"find_tensor"},{"location":"dnn_manipulations.html#get_input","text":"Dnn . get_input ( input_index ) Gets input object DnnInput of the Dnn . Arguments input_index : The input index of the interest. Returns Type : DnnInput, DnnInput of the Dnn .","title":"get_input"},{"location":"dnn_manipulations.html#get_output","text":"Dnn . get_output ( output_index ) Gets output object DnnOutput of the Dnn . Arguments output_index : The output index of the interest. Returns Type : DnnOutput, DnnOutput of the Dnn .","title":"get_output"},{"location":"dnn_manipulations.html#get_model","text":"Dnn . get_model () Gets a model as a json string. Returns Type : str,json string of model.","title":"get_model"},{"location":"dnn_manipulations.html#is_buf_opt_enabled","text":"Dnn . is_buf_opt_enabled ( device ) Returns a boolean whether buffer optimization is enabled (true) or disabled (false). Arguments device : The Device of the interest. Returns Type : bool,true if optimization is enabled else false.","title":"is_buf_opt_enabled"},{"location":"dnn_manipulations.html#remove_net","text":"Dnn . remove_net ( net ) Removes a DnnNet from Dnn . Arguments net : A DnnNet object to be removed.","title":"remove_net"},{"location":"dnn_manipulations.html#remove_tensor","text":"Dnn . remove_tensor ( tensor ) Removes a Tensor from Dnn . Arguments tensor : A Tensor object to be removed from Dnn .","title":"remove_tensor"},{"location":"dnn_manipulations.html#set_model","text":"Dnn . set_model ( model ) Sets a model from json string. Arguments model : A json string to be set as model.","title":"set_model"},{"location":"dnn_manipulations.html#set_buf_opt_enabled","text":"Dnn . set_buf_opt_enabled ( device , is_enabled ) Enables or disables buffer optimization. Arguments device : Device for which buffer optimization will be enabled/disabled. is_enabled : Boolean indicating whether it will be enabled (true) or disabled (false).","title":"set_buf_opt_enabled"},{"location":"dnn_manipulations.html#squash_net","text":"Dnn . squash_net ( net_name ) Squashes the net. The squashed net becomes a pseudo single layer of type complex. The squashed complex layer can be calculated by external inference engine. Arguments net_name : The net to be squashed.","title":"squash_net"},{"location":"dnn_net.html","text":"DnnNet softneuro . core . DnnNet ( * args , ** kwargs ) Dnn network class consists of DnnLayer. This is a private class of softneuro, instance can not be constructed directly,users can get DnnNet instance using Dnn.add_net() , Dnn.find_net() , etc. Attributes inputs : A series of DnnNetInput objects that consist of input of the network. input_layers : A series of DnnLayer objects that consit of input of the network. layers : A series of DnnLayer objects that consist of the network. name : Name of the network. outputs : A series of DnnNetOutput objects that consist of output of the network. output_layers : A series of DnnLayer objects that consist of output of the network. add_layer DnnNet . add_layer ( name , type_ ) Adds a layer to the network. Arguments name : The name of the layer. __type___: The type name of the layer. Supported layer types are availabe by softneuro.core.get_layers() . Returns Type : DnnLayer,Dnnlayer added. clear DnnNet . clear () Clears all layers in the network. get_input DnnNet . get_input ( input_index ) Returns the input_index-th input of the network. Arguments input_index : index of the input. Returns Type : DnnNetInput,input_index-th input of the network. Examples net = dnn . nets [ 0 ] input = net . get_input ( 1 ) # equivalent to : # input = net.inputs[1] get_input_layer DnnNet . get_input_layer ( input_index ) Returns the input_index-th layer of the network. Arguments input_index : Index of the input. Returns Type : DnnLayer,input_index-th layer of the network Examples net = dnn . nets [ 0 ] input_layer = net . get_input_layer ( 1 ) get_output DnnNet . get_output ( output_index ) Returns the output_index-th output of the network. Arguments output_index : Index of the output. Returns Type : DnnNetOutput,output_index-th output of the network. get_output_layer DnnNet . get_output_layer ( output_index ) Returns the output_index-th layer of the network. Arguments output_index : Index of the output. Returns Type : DnnLayer,output_index-th layer of the network. Examples net = dnn . nets [ 0 ] output_layer = net . get_output_layer ( 1 ) pipe DnnNet . pipe ( i_output_index , io_next_net , i_input_index ) Pipes an output of the network to an input of another network. Arguments i_output_index : The output index of the current network. io_next_net : The succeeding network to the current network. i_input_index : The input index of the succeeding network. Examples See DnnNetInput examples. remove_layer DnnNet . remove_layer ( layer ) Removes a layer from the network. Arguments i_layer : The DnnLayer object to be removed from the network. unpipe DnnNet . unpipe ( i_output_index , io_next_net , i_input_index ) Unpipes an output of the network from an input of another network. Arguments i_output_index : The output index of the current network where a succeeding network is attached. io_next_net : The succeeding network to the current network. i_input_index : The input index of the succeeding network.","title":"DnnNet"},{"location":"dnn_net.html#dnnnet","text":"softneuro . core . DnnNet ( * args , ** kwargs ) Dnn network class consists of DnnLayer. This is a private class of softneuro, instance can not be constructed directly,users can get DnnNet instance using Dnn.add_net() , Dnn.find_net() , etc. Attributes inputs : A series of DnnNetInput objects that consist of input of the network. input_layers : A series of DnnLayer objects that consit of input of the network. layers : A series of DnnLayer objects that consist of the network. name : Name of the network. outputs : A series of DnnNetOutput objects that consist of output of the network. output_layers : A series of DnnLayer objects that consist of output of the network.","title":"DnnNet"},{"location":"dnn_net.html#add_layer","text":"DnnNet . add_layer ( name , type_ ) Adds a layer to the network. Arguments name : The name of the layer. __type___: The type name of the layer. Supported layer types are availabe by softneuro.core.get_layers() . Returns Type : DnnLayer,Dnnlayer added.","title":"add_layer"},{"location":"dnn_net.html#clear","text":"DnnNet . clear () Clears all layers in the network.","title":"clear"},{"location":"dnn_net.html#get_input","text":"DnnNet . get_input ( input_index ) Returns the input_index-th input of the network. Arguments input_index : index of the input. Returns Type : DnnNetInput,input_index-th input of the network. Examples net = dnn . nets [ 0 ] input = net . get_input ( 1 ) # equivalent to : # input = net.inputs[1]","title":"get_input"},{"location":"dnn_net.html#get_input_layer","text":"DnnNet . get_input_layer ( input_index ) Returns the input_index-th layer of the network. Arguments input_index : Index of the input. Returns Type : DnnLayer,input_index-th layer of the network Examples net = dnn . nets [ 0 ] input_layer = net . get_input_layer ( 1 )","title":"get_input_layer"},{"location":"dnn_net.html#get_output","text":"DnnNet . get_output ( output_index ) Returns the output_index-th output of the network. Arguments output_index : Index of the output. Returns Type : DnnNetOutput,output_index-th output of the network.","title":"get_output"},{"location":"dnn_net.html#get_output_layer","text":"DnnNet . get_output_layer ( output_index ) Returns the output_index-th layer of the network. Arguments output_index : Index of the output. Returns Type : DnnLayer,output_index-th layer of the network. Examples net = dnn . nets [ 0 ] output_layer = net . get_output_layer ( 1 )","title":"get_output_layer"},{"location":"dnn_net.html#pipe","text":"DnnNet . pipe ( i_output_index , io_next_net , i_input_index ) Pipes an output of the network to an input of another network. Arguments i_output_index : The output index of the current network. io_next_net : The succeeding network to the current network. i_input_index : The input index of the succeeding network. Examples See DnnNetInput examples.","title":"pipe"},{"location":"dnn_net.html#remove_layer","text":"DnnNet . remove_layer ( layer ) Removes a layer from the network. Arguments i_layer : The DnnLayer object to be removed from the network.","title":"remove_layer"},{"location":"dnn_net.html#unpipe","text":"DnnNet . unpipe ( i_output_index , io_next_net , i_input_index ) Unpipes an output of the network from an input of another network. Arguments i_output_index : The output index of the current network where a succeeding network is attached. io_next_net : The succeeding network to the current network. i_input_index : The input index of the succeeding network.","title":"unpipe"},{"location":"dnn_net_io.html","text":"DnnNetInput DnnNetInput class that consists of Dnn . Attributes prev_net : The preceding DnnNet object of the input. prev_net_output_index : Output index in the preceding DnnNet object. tensor : The Tensor object of the input. Examples # --- main0 --- # | | # prenet --+ +-- postnet # | | # --- main1 --- # def create_pre_network ( dnn ): net = dnn . add_net ( 'preprocess' ) net . add_layer ( 'source0' , 'source' ) : net . add_layer ( 'sink0' , 'sink' ) return net def create_main_network ( dnn , name ): net = dnn . add_net ( name ) net . add_layer ( 'source0' , 'source' ) : net . add_layer ( 'sink0' , 'sink' ) return net def create_post_network ( dnn ): # network with two inputs net = dnn . add_net ( 'postprocess' ) net . add_layer ( 'source0' , 'source' ) net . add_layer ( 'source1' , 'source' ) : net . add_layer ( 'sink0' , 'sink' ) return net dnn = softneuro . Dnn () # Create networks prenet = create_pre_network ( dnn ) main0 = create_main_network ( dnn , 'main0' ) main1 = create_main_network ( dnn , 'main1' ) postnet = create_post_network ( dnn ) # Connect networks prenet . pipe ( 0 , main0 , 0 ) prenet . pipe ( 0 , main1 , 0 ) main0 . pipe ( 0 , postnet , 0 ) main1 . pipe ( 0 , postnet , 1 ) # Get DnnNetInput object dnn_net_input1 = postnet . inputs [ 1 ] # postnet has two inputs print ( dnn_net_input1 ) # Results in DnnNetInput(tensor=Tensor(..), prev_net=DnnNet(..), prev_net_output_index=0) print ( dnn_net_input1 . prev_net ) # Results in DnnNet(name='main1', layers=[..], inputs=[..], outputs=[..]) print ( dnn_net_input1 . prev_net_output_index ) # Results in 0 DnnNetOutput DnnNetOutput class that consists of Dnn . Attributes next_nets : A series of DnnNet objects those are connected to the network. next_net_input_indices : A series of input indices of succeeding networks. tensor : The Tensor object of output. Examples # Given the Example in DnnNetInput... net = dnn . nets [ 0 ] print ( net . name ) # Results in 'preprocess' output = net . outputs [ 0 ] # prenet's output is connected to two different networks print ( output0 . next_nets ) # Results in '[0: DnnNet(name='main0' ... ), 1: DnnNet(name='main1' ...)] print ( output0 . next_net_input_indices ) # Results in [0, 0]","title":"DnnNet Input & Output"},{"location":"dnn_net_io.html#dnnnetinput","text":"DnnNetInput class that consists of Dnn . Attributes prev_net : The preceding DnnNet object of the input. prev_net_output_index : Output index in the preceding DnnNet object. tensor : The Tensor object of the input. Examples # --- main0 --- # | | # prenet --+ +-- postnet # | | # --- main1 --- # def create_pre_network ( dnn ): net = dnn . add_net ( 'preprocess' ) net . add_layer ( 'source0' , 'source' ) : net . add_layer ( 'sink0' , 'sink' ) return net def create_main_network ( dnn , name ): net = dnn . add_net ( name ) net . add_layer ( 'source0' , 'source' ) : net . add_layer ( 'sink0' , 'sink' ) return net def create_post_network ( dnn ): # network with two inputs net = dnn . add_net ( 'postprocess' ) net . add_layer ( 'source0' , 'source' ) net . add_layer ( 'source1' , 'source' ) : net . add_layer ( 'sink0' , 'sink' ) return net dnn = softneuro . Dnn () # Create networks prenet = create_pre_network ( dnn ) main0 = create_main_network ( dnn , 'main0' ) main1 = create_main_network ( dnn , 'main1' ) postnet = create_post_network ( dnn ) # Connect networks prenet . pipe ( 0 , main0 , 0 ) prenet . pipe ( 0 , main1 , 0 ) main0 . pipe ( 0 , postnet , 0 ) main1 . pipe ( 0 , postnet , 1 ) # Get DnnNetInput object dnn_net_input1 = postnet . inputs [ 1 ] # postnet has two inputs print ( dnn_net_input1 ) # Results in DnnNetInput(tensor=Tensor(..), prev_net=DnnNet(..), prev_net_output_index=0) print ( dnn_net_input1 . prev_net ) # Results in DnnNet(name='main1', layers=[..], inputs=[..], outputs=[..]) print ( dnn_net_input1 . prev_net_output_index ) # Results in 0","title":"DnnNetInput"},{"location":"dnn_net_io.html#dnnnetoutput","text":"DnnNetOutput class that consists of Dnn . Attributes next_nets : A series of DnnNet objects those are connected to the network. next_net_input_indices : A series of input indices of succeeding networks. tensor : The Tensor object of output. Examples # Given the Example in DnnNetInput... net = dnn . nets [ 0 ] print ( net . name ) # Results in 'preprocess' output = net . outputs [ 0 ] # prenet's output is connected to two different networks print ( output0 . next_nets ) # Results in '[0: DnnNet(name='main0' ... ), 1: DnnNet(name='main1' ...)] print ( output0 . next_net_input_indices ) # Results in [0, 0]","title":"DnnNetOutput"},{"location":"dnn_net_partition.html","text":"DnnNetPartition softneuro . core . DnnNetPartition () DnnNetPartition class used for decomposing Dnn (see decompose ). add_interval DnnNetPartition . add_interval ( i_from , i_to ) Adds interval. Arguments i_from : Start layer index. i_to : End layer index.","title":"DnnNetPartition"},{"location":"dnn_net_partition.html#dnnnetpartition","text":"softneuro . core . DnnNetPartition () DnnNetPartition class used for decomposing Dnn (see decompose ).","title":"DnnNetPartition"},{"location":"dnn_net_partition.html#add_interval","text":"DnnNetPartition . add_interval ( i_from , i_to ) Adds interval. Arguments i_from : Start layer index. i_to : End layer index.","title":"add_interval"},{"location":"dnn_net_plan.html","text":"DnnNetPlan softneuro . core . DnnNetPlan ( * args , ** kwargs ) DnnNetPlan class, composes DnnPlan. This is a private class of softneuro, instance can not be constructed directly, users can get DnnNetPlan instance using DnnPlan.find_net_plan() . Attributes layers : Layer plans. name : Net name. usec : Forward time (usec).","title":"DnnNetPlan"},{"location":"dnn_net_plan.html#dnnnetplan","text":"softneuro . core . DnnNetPlan ( * args , ** kwargs ) DnnNetPlan class, composes DnnPlan. This is a private class of softneuro, instance can not be constructed directly, users can get DnnNetPlan instance using DnnPlan.find_net_plan() . Attributes layers : Layer plans. name : Net name. usec : Forward time (usec).","title":"DnnNetPlan"},{"location":"dnn_optimizer.html","text":"DnnOptimizer softneuro . core . DnnOptimizer ( prof = None ) DnnOptimizer class which searches for the optimal routines and parameters from the profiling data (DnnProf), and creates DnnPlan. Attributes prof : DnnProf object required for optimization. plan : DnnPlan object created by optimization. optimize DnnOptimizer . optimize () Optimizes the Dnn and creats the DnnPlan.","title":"DnnOptimizer"},{"location":"dnn_optimizer.html#dnnoptimizer","text":"softneuro . core . DnnOptimizer ( prof = None ) DnnOptimizer class which searches for the optimal routines and parameters from the profiling data (DnnProf), and creates DnnPlan. Attributes prof : DnnProf object required for optimization. plan : DnnPlan object created by optimization.","title":"DnnOptimizer"},{"location":"dnn_optimizer.html#optimize","text":"DnnOptimizer . optimize () Optimizes the Dnn and creats the DnnPlan.","title":"optimize"},{"location":"dnn_plan.html","text":"DnnPlan softneuro . core . DnnPlan ( * args , ** kwargs ) DnnPlan class created by DnnOptimizer. DnnPlan composes DnnRecipe. This is a private class of softneuro, instance can not be constructed directly. Attributes usec : Processing time (usec). find_layer_plan DnnPlan . find_layer_plan ( layer ) Finds the layer plan. Arguments layer : DnnLayer object to be planned. Returns Type : DnnLayerPlan,if found else NULL. find_net_plan DnnPlan . find_net_plan ( net ) Finds the net plan. Arguments net : DnnNet object to be planned. Returns Type : DnnNetPlan,if found else NULL.","title":"DnnPlan"},{"location":"dnn_plan.html#dnnplan","text":"softneuro . core . DnnPlan ( * args , ** kwargs ) DnnPlan class created by DnnOptimizer. DnnPlan composes DnnRecipe. This is a private class of softneuro, instance can not be constructed directly. Attributes usec : Processing time (usec).","title":"DnnPlan"},{"location":"dnn_plan.html#find_layer_plan","text":"DnnPlan . find_layer_plan ( layer ) Finds the layer plan. Arguments layer : DnnLayer object to be planned. Returns Type : DnnLayerPlan,if found else NULL.","title":"find_layer_plan"},{"location":"dnn_plan.html#find_net_plan","text":"DnnPlan . find_net_plan ( net ) Finds the net plan. Arguments net : DnnNet object to be planned. Returns Type : DnnNetPlan,if found else NULL.","title":"find_net_plan"},{"location":"dnn_prof.html","text":"DnnProf softneuro . core . DnnProf ( dnn = None ) DnnProf class used for optimizing Dnn (see DnnOptimizer ). Attributes affinity_masks : Affinity masks for profiling. dnn : Target dnn to be profiled. elapsed_sec : Elapsed seconds of the profiling. estimate_mode : Estimation mode of profiling data. is_canceled : Whether profiling is canceled or not. is_preparing : Whether preparing or not. progress : Progress of the profiling. run_num : The number of routine profiler runs. schemas : Schemas (routine groups) to be profiled. thread_num : Number of threads for profiling. add DnnProf . add ( i_routine , i_layer = None ) Adds a profiling routine to a layer. Arguments i_routine : The profiling routine. i_layer : The layer to which the profiling routine is added. If NULL is given, the profiling routine is added to all layers in a main net. cancel DnnProf . cancel () Cancels profiling. load DnnProf . load ( * args ) Loads from a file. Arguments i_filename : Profiling file name. i_dnn_filename : Dnn file name. i_pass : The password of the dnn file, use NULL for the dnn file without password. profile DnnProf . profile () Profiles with a callback function for progress. progressed DnnProf . progressed () Default callback function for profiling progress. Returns Type : func,Default callback function for profiling progress. remove DnnProf . remove ( i_routine = None , i_layer = None ) Removes a profiling routine from a layer. Arguments i_routine : The profiling routine. If NULL or an empty string () is given, all profiling routines are removed from the layer. i_layer : The layer from which the profiling routine is removed. If NULL is given, the profiling routine is removed from all layers. reset DnnProf . reset ( i_routine = None , i_layer = None ) Resets profiling data. Arguments i_routine : The profiling routine to be reset. If NULL or an empty string () is given, all profiling routines are reset. i_layer : The layer to be reset. If NULL is given, the routines in all layers are reset. save DnnProf . save ( * args ) Saves to a file. Arguments i_filename : Profiling file name. i_is_ascii : Save as ascii form. set_affinity_mask DnnProf . set_affinity_mask ( index , value ) Sets an affinity mask. Arguments index : Thread index for which affinity mask will be set. value : An affinity mask represented in hex (\"0x..\") or binary (\"0b..\") form.","title":"DnnProf"},{"location":"dnn_prof.html#dnnprof","text":"softneuro . core . DnnProf ( dnn = None ) DnnProf class used for optimizing Dnn (see DnnOptimizer ). Attributes affinity_masks : Affinity masks for profiling. dnn : Target dnn to be profiled. elapsed_sec : Elapsed seconds of the profiling. estimate_mode : Estimation mode of profiling data. is_canceled : Whether profiling is canceled or not. is_preparing : Whether preparing or not. progress : Progress of the profiling. run_num : The number of routine profiler runs. schemas : Schemas (routine groups) to be profiled. thread_num : Number of threads for profiling.","title":"DnnProf"},{"location":"dnn_prof.html#add","text":"DnnProf . add ( i_routine , i_layer = None ) Adds a profiling routine to a layer. Arguments i_routine : The profiling routine. i_layer : The layer to which the profiling routine is added. If NULL is given, the profiling routine is added to all layers in a main net.","title":"add"},{"location":"dnn_prof.html#cancel","text":"DnnProf . cancel () Cancels profiling.","title":"cancel"},{"location":"dnn_prof.html#load","text":"DnnProf . load ( * args ) Loads from a file. Arguments i_filename : Profiling file name. i_dnn_filename : Dnn file name. i_pass : The password of the dnn file, use NULL for the dnn file without password.","title":"load"},{"location":"dnn_prof.html#profile","text":"DnnProf . profile () Profiles with a callback function for progress.","title":"profile"},{"location":"dnn_prof.html#progressed","text":"DnnProf . progressed () Default callback function for profiling progress. Returns Type : func,Default callback function for profiling progress.","title":"progressed"},{"location":"dnn_prof.html#remove","text":"DnnProf . remove ( i_routine = None , i_layer = None ) Removes a profiling routine from a layer. Arguments i_routine : The profiling routine. If NULL or an empty string () is given, all profiling routines are removed from the layer. i_layer : The layer from which the profiling routine is removed. If NULL is given, the profiling routine is removed from all layers.","title":"remove"},{"location":"dnn_prof.html#reset","text":"DnnProf . reset ( i_routine = None , i_layer = None ) Resets profiling data. Arguments i_routine : The profiling routine to be reset. If NULL or an empty string () is given, all profiling routines are reset. i_layer : The layer to be reset. If NULL is given, the routines in all layers are reset.","title":"reset"},{"location":"dnn_prof.html#save","text":"DnnProf . save ( * args ) Saves to a file. Arguments i_filename : Profiling file name. i_is_ascii : Save as ascii form.","title":"save"},{"location":"dnn_prof.html#set_affinity_mask","text":"DnnProf . set_affinity_mask ( index , value ) Sets an affinity mask. Arguments index : Thread index for which affinity mask will be set. value : An affinity mask represented in hex (\"0x..\") or binary (\"0b..\") form.","title":"set_affinity_mask"},{"location":"dnn_recipe.html","text":"DnnRecipe softneuro . core . DnnRecipe ( plan = None ) DnnRecipe class used for tuning Dnn (see tune ). Arguments plan : DnnPlan composing the recipe. Attributes is_stripped : Whether stripped or not. load DnnRecipe . load ( * args ) Loads from a file. Arguments i_filename : Recipe file name. i_pass : Password of the recipe file. save DnnRecipe . save ( i_filename ) Saves to a file. Arguments i_filename : Recipe file name. strip DnnRecipe . strip () Strips the dnn recipe.","title":"DnnRecipe"},{"location":"dnn_recipe.html#dnnrecipe","text":"softneuro . core . DnnRecipe ( plan = None ) DnnRecipe class used for tuning Dnn (see tune ). Arguments plan : DnnPlan composing the recipe. Attributes is_stripped : Whether stripped or not.","title":"DnnRecipe"},{"location":"dnn_recipe.html#load","text":"DnnRecipe . load ( * args ) Loads from a file. Arguments i_filename : Recipe file name. i_pass : Password of the recipe file.","title":"load"},{"location":"dnn_recipe.html#save","text":"DnnRecipe . save ( i_filename ) Saves to a file. Arguments i_filename : Recipe file name.","title":"save"},{"location":"dnn_recipe.html#strip","text":"DnnRecipe . strip () Strips the dnn recipe.","title":"strip"},{"location":"dnn_routine_plan.html","text":"DnnRoutinePlan softneuro . core . DnnRoutinePlan ( * args , ** kwargs ) DnnRoutinePlan class. This is a private class of softneuro, instance can not be constructed directly. Attributes child : Child net plan. desc : Routine descriptor. params : Routine params. usec : Forward time (usec). usecs : Measured forward times (usec).","title":"DnnRoutinePlan"},{"location":"dnn_routine_plan.html#dnnroutineplan","text":"softneuro . core . DnnRoutinePlan ( * args , ** kwargs ) DnnRoutinePlan class. This is a private class of softneuro, instance can not be constructed directly. Attributes child : Child net plan. desc : Routine descriptor. params : Routine params. usec : Forward time (usec). usecs : Measured forward times (usec).","title":"DnnRoutinePlan"},{"location":"dnn_schema_plan.html","text":"DnnSchemaPlan softneuro . core . DnnSchemaPlan ( * args , ** kwargs ) DnnSchemaPlan class. This is a private class of softneuro, instance can not be constructed directly. Attributes adapts : Adapt routine plans. adapt_usec : Processing time for adapt routines (usec). is_optimal : Whether self is optimal or not. has_adapt : Whether self has an adapt routine plan or not. name : The routine schema name. optimal_routine : The optimal routine plan. routines : Routine plans. usec : Forward time (usec).","title":"DnnSchemaPlan"},{"location":"dnn_schema_plan.html#dnnschemaplan","text":"softneuro . core . DnnSchemaPlan ( * args , ** kwargs ) DnnSchemaPlan class. This is a private class of softneuro, instance can not be constructed directly. Attributes adapts : Adapt routine plans. adapt_usec : Processing time for adapt routines (usec). is_optimal : Whether self is optimal or not. has_adapt : Whether self has an adapt routine plan or not. name : The routine schema name. optimal_routine : The optimal routine plan. routines : Routine plans. usec : Forward time (usec).","title":"DnnSchemaPlan"},{"location":"enums.html","text":"LogLevel Enum Enum Description LOG_LEVEL_DEBUG Debug log starting with 'MOR(D):' LOG_LEVEL_INFO Information log starting with 'MOR(I):' LOG_LEVEL_WARN Warning log starting with 'MOR(W):' LOG_LEVEL_ERROR Error log starting with 'MOR(E):' LOG_LEVEL_MSG Message log without header LOG_LEVEL_None None DType Enum Enum Description DTYPE_NONE None DTYPE_UINT8 Uint8 DTYPE_UINT16 Uint16 DTYPE_UINT32 Uint32 DTYPE_UINT64 Uint64 DTYPE_INT8 Int8 DTYPE_INT16 Int16 DTYPE_INT32 Int32 DTYPE_INT64 Int64 DTYPE_FLOAT16 Float16 DTYPE_FLOAT32 Float32 DTYPE_FLOAT64 Float64 DTYPE_QUINT8 Quint8 DTYPE_QINT8 Qint8 DTYPE_QINT32 Qint32 DTYPE_CHAR Char DTYPE_BOOL Bool DTYPE_GENERIC Generic (Float32)","title":"Enums"},{"location":"enums.html#loglevel-enum","text":"Enum Description LOG_LEVEL_DEBUG Debug log starting with 'MOR(D):' LOG_LEVEL_INFO Information log starting with 'MOR(I):' LOG_LEVEL_WARN Warning log starting with 'MOR(W):' LOG_LEVEL_ERROR Error log starting with 'MOR(E):' LOG_LEVEL_MSG Message log without header LOG_LEVEL_None None","title":"LogLevel Enum"},{"location":"enums.html#dtype-enum","text":"Enum Description DTYPE_NONE None DTYPE_UINT8 Uint8 DTYPE_UINT16 Uint16 DTYPE_UINT32 Uint32 DTYPE_UINT64 Uint64 DTYPE_INT8 Int8 DTYPE_INT16 Int16 DTYPE_INT32 Int32 DTYPE_INT64 Int64 DTYPE_FLOAT16 Float16 DTYPE_FLOAT32 Float32 DTYPE_FLOAT64 Float64 DTYPE_QUINT8 Quint8 DTYPE_QINT8 Qint8 DTYPE_QINT32 Qint32 DTYPE_CHAR Char DTYPE_BOOL Bool DTYPE_GENERIC Generic (Float32)","title":"DType Enum"},{"location":"params.html","text":"Params softneuro . core . Params ( * args , ** kwargs ) A special dictionary class that stores parameters. This is a private class of softneuro, instance can not be constructed directly. This object is pairs of key and value to provide parameters to layers, routines, and inputs/outputs in the network. Although it is quite similar to Dictionary of Python, it allows only string for keys and only bool , int etc. for values. Complete list of the available types for value is shown below. List of available types for value None bool bool list int int list float float list str str list Params Example layer . params [ 'padding' ] = 'same' layer . params [ 'dilations' ] = [ 2 , 2 ]","title":"Parameters"},{"location":"params.html#params","text":"softneuro . core . Params ( * args , ** kwargs ) A special dictionary class that stores parameters. This is a private class of softneuro, instance can not be constructed directly. This object is pairs of key and value to provide parameters to layers, routines, and inputs/outputs in the network. Although it is quite similar to Dictionary of Python, it allows only string for keys and only bool , int etc. for values. Complete list of the available types for value is shown below. List of available types for value None bool bool list int int list float float list str str list Params Example layer . params [ 'padding' ] = 'same' layer . params [ 'dilations' ] = [ 2 , 2 ]","title":"Params"},{"location":"softneuro_common.html","text":"get_devices softneuro . get_devices () Returns all supported devices as a dictionary. Returns Type : dict,a dictionary of all supported devices. Examples >>> devices = softneuro . get_devices () >>> devices { 'cpu' : Device ( name = 'cpu' )} get_layers softneuro . get_layers () Returns all supported layer names in the API. Returns Type : list,a list of all supported layer names. Examples >>> layers = softneuro . get_layers () >>> layers ( 'abs' , 'acos' , 'acosh' , ... , 'where' , 'zero_padding2' ) get_plugins softneuro . get_plugins () Returns all installed plugin names and their description as a Dictionary. Returns Type : dict,a dictionary of all installed plugin names and their description. Examples >>> plugins = softneuro . get_plugins () >>> plugins { 'plugin_avx2' : 'AVX routines.' } get_routines softneuro . get_routines () Returns all supported routine names for each layer as a Dictionary. Returns Type : dict,a dictionary of all supported routine names for each layer. Examples >>> routines = softneuro . get_routines () >>> routines { 'abs' : ( 'cpu:chf/naive' , 'cpu/naive' ), 'acos' : ( 'cpu:chf/naive' , 'cpu/naive' ), ... , 'where' : ( 'cpu/naive' ,), 'zero_padding2' : ( 'cpu/naive' ,)} >>> conv2_routines = routines [ 'conv2' ] >>> conv2_routines ( 'cpu/naive' , 'cpu/naive/wg2' , 'cpu:chf/naive' , ... , 'cpu:qint8:pt_asym/woc64_avx' ) get_routine_schemas softneuro . get_routine_schemas () Returns all supported routine schemas. Returns Type : list,a list of all supported routine schemas. Examples >>> schemas = softneuro . get_routine_schemas () >>> schemas ( 'cpu' , 'cpu:qint8' ) set_log_level softneuro . set_log_level ( log_level ) Sets level of logging. Arguments log_level : Level of logging, defined by LogLevel.","title":"Common Functions"},{"location":"softneuro_common.html#get_devices","text":"softneuro . get_devices () Returns all supported devices as a dictionary. Returns Type : dict,a dictionary of all supported devices. Examples >>> devices = softneuro . get_devices () >>> devices { 'cpu' : Device ( name = 'cpu' )}","title":"get_devices"},{"location":"softneuro_common.html#get_layers","text":"softneuro . get_layers () Returns all supported layer names in the API. Returns Type : list,a list of all supported layer names. Examples >>> layers = softneuro . get_layers () >>> layers ( 'abs' , 'acos' , 'acosh' , ... , 'where' , 'zero_padding2' )","title":"get_layers"},{"location":"softneuro_common.html#get_plugins","text":"softneuro . get_plugins () Returns all installed plugin names and their description as a Dictionary. Returns Type : dict,a dictionary of all installed plugin names and their description. Examples >>> plugins = softneuro . get_plugins () >>> plugins { 'plugin_avx2' : 'AVX routines.' }","title":"get_plugins"},{"location":"softneuro_common.html#get_routines","text":"softneuro . get_routines () Returns all supported routine names for each layer as a Dictionary. Returns Type : dict,a dictionary of all supported routine names for each layer. Examples >>> routines = softneuro . get_routines () >>> routines { 'abs' : ( 'cpu:chf/naive' , 'cpu/naive' ), 'acos' : ( 'cpu:chf/naive' , 'cpu/naive' ), ... , 'where' : ( 'cpu/naive' ,), 'zero_padding2' : ( 'cpu/naive' ,)} >>> conv2_routines = routines [ 'conv2' ] >>> conv2_routines ( 'cpu/naive' , 'cpu/naive/wg2' , 'cpu:chf/naive' , ... , 'cpu:qint8:pt_asym/woc64_avx' )","title":"get_routines"},{"location":"softneuro_common.html#get_routine_schemas","text":"softneuro . get_routine_schemas () Returns all supported routine schemas. Returns Type : list,a list of all supported routine schemas. Examples >>> schemas = softneuro . get_routine_schemas () >>> schemas ( 'cpu' , 'cpu:qint8' )","title":"get_routine_schemas"},{"location":"softneuro_common.html#set_log_level","text":"softneuro . set_log_level ( log_level ) Sets level of logging. Arguments log_level : Level of logging, defined by LogLevel.","title":"set_log_level"},{"location":"tensor.html","text":"Tensor softneuro . core . Tensor ( * args , ** kwargs ) Tensor class.Tensors are n-dimensional arrays. This is a private class of softneuro, instance can not be constructed directly, users can get Tensor instance using Dnn.find_tensor() . Attributes data : Pointer to the tensor data in memory whose data type is numpy.ndarray. dtype : Tensor data type, one of float32, uint8, int8, int32, int64, qint8, qint32. name : Tensor name. qaxis : Quantization axis. quants : Quantizers whose data type is softneuro.core.DnnList. rank : Tensor rank (how many dimensions). shape : Tensor shape. areDTypeAndBatchShapeOf Tensor . areDTypeAndBatchShapeOf ( i_dtype , i_shape ) Verifies if the tensor dtype and shape per batch match the arguments. Returns True if DType and shape per batch match, False otherwise. Arguments i_dtype (softneuro.DType) : DType to be matched. i_shape (tuple) : Shape to be matched. Returns type : bool, true if the tensor dtype and shape per batch match the arguments else false. areDTypeAndShapeOf Tensor . areDTypeAndShapeOf ( i_dtype , i_shape ) Verifies if the tensor dtype and shape match the arguments. Returns True if DType and shape match, False otherwise. Arguments i_dtype (softneuro.DType) : DType to be matched. i_shape (tuple) : Shape to be matched. Returns type : bool, true if the tensor dtype and shape match the arguments else false. copy Tensor . copy ( val ) Copy data into the tensor. Arguments val (numpy.ndarray or list) : Data to be copied. copy_batch Tensor . copy_batch ( val , batch ) Copy data into the given batch index. Arguments val (numpy.ndarray or list) : Data to be copied. batch (int) : Batch index. format Tensor . format ( dtype , shape ) Sets the tensor dtype and shape. Arguments dtype (Softneuro.DType) : Target data type. shape (tuple) : Target tensor shape. getDType Tensor . getDType () Returns the tensor DType. Returns type : DType, DType of tensor. getHash Tensor . getHash () Returns hash of tensor. Returns type : int, hash of tensor. getName Tensor . getName () Returns name of tensor. Returns type : string, name of tensor. getRank Tensor . getRank () Returns the tensor rank. Returns type : int, rank of tensor. getShape Tensor . getShape () Returns the tensor shape. Returns type : tuple , int, shape of tensor. getQAxis Tensor . getQAxis () Returns the quantization axis. Returns type : int, QAxis of tensor. getQuant Tensor . getQuant ( i_index ) Returns the quant at the given index. Arguments i_index (int) : Index of the quant to be return. Returns type : Quant, quants of tensor. getQuantNum Tensor . getQuantNum () Returns the number of quants. Returns type : int, number of quants of tensor. init_quant Tensor . init_quant ( qmode , qaxis ) Initializes the quantizers with qmode over qaxis. Returns an error if the tensor dtype isn't qint8 (not supported yet). Arguments i_qmode (Softneuro.qmode) : Quantization mode. i_qaxis (int) : Quantization axis. isFormatted Tensor . isFormatted () Returns True if the tensor was formatted, False otherwise. normalize Tensor . normalize () Normalizes the tensor. Returns True if the tensor was normalized, False otherwise. Returns type : bool, true if success else false.","title":"Tensor"},{"location":"tensor.html#tensor","text":"softneuro . core . Tensor ( * args , ** kwargs ) Tensor class.Tensors are n-dimensional arrays. This is a private class of softneuro, instance can not be constructed directly, users can get Tensor instance using Dnn.find_tensor() . Attributes data : Pointer to the tensor data in memory whose data type is numpy.ndarray. dtype : Tensor data type, one of float32, uint8, int8, int32, int64, qint8, qint32. name : Tensor name. qaxis : Quantization axis. quants : Quantizers whose data type is softneuro.core.DnnList. rank : Tensor rank (how many dimensions). shape : Tensor shape.","title":"Tensor"},{"location":"tensor.html#aredtypeandbatchshapeof","text":"Tensor . areDTypeAndBatchShapeOf ( i_dtype , i_shape ) Verifies if the tensor dtype and shape per batch match the arguments. Returns True if DType and shape per batch match, False otherwise. Arguments i_dtype (softneuro.DType) : DType to be matched. i_shape (tuple) : Shape to be matched. Returns type : bool, true if the tensor dtype and shape per batch match the arguments else false.","title":"areDTypeAndBatchShapeOf"},{"location":"tensor.html#aredtypeandshapeof","text":"Tensor . areDTypeAndShapeOf ( i_dtype , i_shape ) Verifies if the tensor dtype and shape match the arguments. Returns True if DType and shape match, False otherwise. Arguments i_dtype (softneuro.DType) : DType to be matched. i_shape (tuple) : Shape to be matched. Returns type : bool, true if the tensor dtype and shape match the arguments else false.","title":"areDTypeAndShapeOf"},{"location":"tensor.html#copy","text":"Tensor . copy ( val ) Copy data into the tensor. Arguments val (numpy.ndarray or list) : Data to be copied.","title":"copy"},{"location":"tensor.html#copy_batch","text":"Tensor . copy_batch ( val , batch ) Copy data into the given batch index. Arguments val (numpy.ndarray or list) : Data to be copied. batch (int) : Batch index.","title":"copy_batch"},{"location":"tensor.html#format","text":"Tensor . format ( dtype , shape ) Sets the tensor dtype and shape. Arguments dtype (Softneuro.DType) : Target data type. shape (tuple) : Target tensor shape.","title":"format"},{"location":"tensor.html#getdtype","text":"Tensor . getDType () Returns the tensor DType. Returns type : DType, DType of tensor.","title":"getDType"},{"location":"tensor.html#gethash","text":"Tensor . getHash () Returns hash of tensor. Returns type : int, hash of tensor.","title":"getHash"},{"location":"tensor.html#getname","text":"Tensor . getName () Returns name of tensor. Returns type : string, name of tensor.","title":"getName"},{"location":"tensor.html#getrank","text":"Tensor . getRank () Returns the tensor rank. Returns type : int, rank of tensor.","title":"getRank"},{"location":"tensor.html#getshape","text":"Tensor . getShape () Returns the tensor shape. Returns type : tuple , int, shape of tensor.","title":"getShape"},{"location":"tensor.html#getqaxis","text":"Tensor . getQAxis () Returns the quantization axis. Returns type : int, QAxis of tensor.","title":"getQAxis"},{"location":"tensor.html#getquant","text":"Tensor . getQuant ( i_index ) Returns the quant at the given index. Arguments i_index (int) : Index of the quant to be return. Returns type : Quant, quants of tensor.","title":"getQuant"},{"location":"tensor.html#getquantnum","text":"Tensor . getQuantNum () Returns the number of quants. Returns type : int, number of quants of tensor.","title":"getQuantNum"},{"location":"tensor.html#init_quant","text":"Tensor . init_quant ( qmode , qaxis ) Initializes the quantizers with qmode over qaxis. Returns an error if the tensor dtype isn't qint8 (not supported yet). Arguments i_qmode (Softneuro.qmode) : Quantization mode. i_qaxis (int) : Quantization axis.","title":"init_quant"},{"location":"tensor.html#isformatted","text":"Tensor . isFormatted () Returns True if the tensor was formatted, False otherwise.","title":"isFormatted"},{"location":"tensor.html#normalize","text":"Tensor . normalize () Normalizes the tensor. Returns True if the tensor was normalized, False otherwise. Returns type : bool, true if success else false.","title":"normalize"}]}